<!DOCTYPE html><html lang="en-US" class="js"><head>
<link rel="icon" data-savepage-href="" href=""><script type="text/javascript" async="" data-savepage-src="https://app.rightmessage.com/adminvisitor?t=1871593262"></script><script type="text/javascript" async="" data-savepage-src="https://loginchecker.rightmessage.com"></script><script class="w-json-ld" type="application/ld+json" id="w-json-ldwistia_40"></script><script class="w-json-ld" type="application/ld+json" id="w-json-ldwistia_107"></script><script async="" data-savepage-src="https://connect.facebook.net/en_US/fbevents.js"></script><script type="text/javascript" data-savepage-src="https://api.getdrip.com/client/events/visit?drip_account_id=4768429&referrer=&url=https%3A%2F%2Fpyimagesearch.com%2F2014%2F09%2F29%2Ffinding-brightest-spot-image-using-python-opencv%2F&domain=pyimagesearch.com&time_zone=America%2FChicago&enable_third_party_cookies=t&callback=Drip_482460956"></script>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">

	<!-- This site is optimized with the Yoast SEO plugin v16.0.2 - https://yoast.com/wordpress/plugins/seo/ -->
	<title>Finding the Brightest Spot in an Image using OpenCV</title><style id="avlabs-lazy-load-bg"></style><style id="avlabs-custom-critical-css-before-rocket">:root{--wp-admin-theme-color:#007cba;--wp-admin-theme-color-darker-10:#006ba1;--wp-admin-theme-color-darker-20:#005a87}.enlighter-t-pyis-enlighter-theme .enlighter-codegroup-wrapper .enlighter-raw{background-color:#fff;font-size:12px;color:#000;line-height:16px}.enlighter-t-pyis-enlighter-theme .enlighter-codegroup-wrapper .enlighter-toolbar .enlighter-btn{border-radius:0}.enlighter-t-pyis-enlighter-theme .enlighter-codegroup-wrapper .enlighter-toolbar{display:none!important}.enlighter-t-pyis-enlighter-theme .enlighter-codegroup-wrapper .enlighter-toolbar .enlighter-btn{background-color:#fff;color:#717171;font-size:12px;padding:0;border:1px solid #e0e0e0;margin:0 0 0 8px;text-decoration:none;width:23px;height:23px;background-position:0 0;background-size:contain}.foundation-mq{font-family:"small=0em&medium=40em&large=64em&xlarge=75em&xxlarge=90em"}.sticky-container{position:relative}.sticky{position:relative;z-index:0;-webkit-transform:translate3d(0,0,0);transform:translate3d(0,0,0)}.sticky.is-anchored{position:relative;right:auto;left:auto}#pyis-cta-modal-sticky-bar{margin:1.25rem 0}#pyis-cta-modal-sticky-bar .grid-container{padding-right:.625rem;padding-left:.625rem;max-width:75rem;margin-left:auto;margin-right:auto}@media print,screen and (min-width:40em){#pyis-cta-modal-sticky-bar .grid-container{padding-right:.9375rem;padding-left:.9375rem}}#pyis-cta-modal-sticky-bar .grid-x{display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-flow:row wrap;-ms-flex-flow:row wrap;flex-flow:row wrap}#pyis-cta-modal-sticky-bar .cell{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;min-height:0;min-width:0;width:100%}#pyis-cta-modal-sticky-bar .grid-margin-x{margin-left:-.625rem;margin-right:-.625rem}@media print,screen and (min-width:40em){#pyis-cta-modal-sticky-bar .grid-margin-x{margin-left:-.9375rem;margin-right:-.9375rem}}#pyis-cta-modal-sticky-bar .grid-margin-x>.cell{width:calc(100% - 1.25rem);margin-left:.625rem;margin-right:.625rem}@media print,screen and (min-width:40em){#pyis-cta-modal-sticky-bar .grid-margin-x>.cell{width:calc(100% - 1.875rem);margin-left:.9375rem;margin-right:.9375rem}}#pyis-cta-modal-sticky-bar .text-center{text-align:center}#pyis-cta-modal-sticky-bar .sticky{background-color:#051e50;color:#fefefe;padding:1.625rem 1rem 1.25rem 1.625rem}#pyis-cta-modal-sticky-bar .sticky a{background:0 0;outline:0;font-size:1.2rem;padding:0;border-bottom:none;color:#fefefe;text-decoration:underline;position:relative}#pyis-cta-modal-sticky-bar .sticky a:before{position:absolute;top:-.5625rem;left:-3.75rem;display:block;width:2.5rem;height:2.5rem;content:'';background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/source_code_mini_image.png*/url();background-size:contain}#pyis-cta-modal .modal-content{margin-top:1.5rem}#pyis-cta-modal .optin-modal-content .pyuni-logo{padding-bottom:20px;max-width:400px}#pyis-cta-modal .optin-modal-content h3{margin-bottom:20px;font-size:24px}#pyis-cta-modal .optin-modal-content .is-style-list-checks li{font-weight:400}@font-face{font-family:proxima-nova;src:/*savepage-url=https://use.typekit.net/af/949f99/00000000000000003b9b3068/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3*/url() format("woff2"),/*savepage-url=https://use.typekit.net/af/949f99/00000000000000003b9b3068/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3*/url() format("woff"),/*savepage-url=https://use.typekit.net/af/949f99/00000000000000003b9b3068/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3*/url() format("opentype");/*savepage-font-display=swap*/font-style:normal;font-weight:700}@font-face{font-family:proxima-nova;src:/*savepage-url=https://use.typekit.net/af/4c4052/00000000000000003b9b3069/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3*/url() format("woff2"),/*savepage-url=https://use.typekit.net/af/4c4052/00000000000000003b9b3069/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3*/url() format("woff"),/*savepage-url=https://use.typekit.net/af/4c4052/00000000000000003b9b3069/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3*/url() format("opentype");/*savepage-font-display=swap*/font-style:italic;font-weight:700}@font-face{font-family:proxima-nova;src:/*savepage-url=https://use.typekit.net/af/576d53/00000000000000003b9b3066/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3*/url() format("woff2"),/*savepage-url=https://use.typekit.net/af/576d53/00000000000000003b9b3066/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3*/url() format("woff"),/*savepage-url=https://use.typekit.net/af/576d53/00000000000000003b9b3066/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3*/url() format("opentype");/*savepage-font-display=swap*/font-style:normal;font-weight:600}@font-face{font-family:proxima-nova;src:/*savepage-url=https://use.typekit.net/af/705e94/00000000000000003b9b3062/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3*/url() format("woff2"),/*savepage-url=https://use.typekit.net/af/705e94/00000000000000003b9b3062/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3*/url() format("woff"),/*savepage-url=https://use.typekit.net/af/705e94/00000000000000003b9b3062/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3*/url() format("opentype");/*savepage-font-display=swap*/font-style:normal;font-weight:400}@font-face{font-family:proxima-nova;src:/*savepage-url=https://use.typekit.net/af/5c70f2/00000000000000003b9b3063/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3*/url() format("woff2"),/*savepage-url=https://use.typekit.net/af/5c70f2/00000000000000003b9b3063/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3*/url() format("woff"),/*savepage-url=https://use.typekit.net/af/5c70f2/00000000000000003b9b3063/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3*/url() format("opentype");/*savepage-font-display=swap*/font-style:italic;font-weight:400}button,input{overflow:visible}html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}h1{margin:.67em 0;font-size:2em}code,pre{font-family:monospace;font-size:1em}a{background-color:transparent}strong{font-weight:bolder}img{border-style:none}button,input,textarea{margin:0;font-family:inherit;font-size:100%;line-height:1.15}button{text-transform:none}[type=submit],button{-webkit-appearance:button}[type=submit]::-moz-focus-inner,button::-moz-focus-inner{padding:0;border-style:none}[type=submit]:-moz-focusring,button:-moz-focusring{outline:ButtonText dotted 1px}textarea{overflow:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}html{box-sizing:border-box}*,:after{box-sizing:inherit}.entry-content::before,.entry::before,.nav-primary::before,.nav-secondary::before,.site-container::before,.site-header::before,.site-inner::before,.widget::before,.wrap::before{display:table;content:" "}.entry-content::after,.entry::after,.nav-primary::after,.nav-secondary::after,.site-container::after,.site-header::after,.site-inner::after,.widget::after,.wrap::after{display:table;clear:both;content:""}html,input[type=search]{box-sizing:border-box}*,:after,:before{box-sizing:inherit}html{overflow-y:scroll;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}body{margin:0;font-family:proxima-nova,sans-serif;font-weight:400;line-height:1.472;color:#051e50;font-size:17px}@media (min-width:640px){body{line-height:1.52}}@media (min-width:880px){body{line-height:1.568}}@media (min-width:1200px){body{line-height:1.6}}@media (min-width:640px){body{font-size:19px}}@media (min-width:880px){body{font-size:20px}}body a{font-weight:700;color:#169fe6;text-decoration:none}.entry-content a{border-bottom:1px solid #169fe6}:focus{outline:0}ul{padding:0;margin:0}li{list-style-type:none}em{font-style:italic}cite{font-style:normal}iframe,img{max-width:100%}img{display:block;height:auto}p{padding:0;margin:0 0 24px}@media (min-width:640px){p{margin:0 0 32px}}h1,h2,h3,h4{margin:0 0 30px;font-family:proxima-nova,sans-serif;font-weight:700}h4 a{color:#169fe6}h1{line-height:1.06;letter-spacing:-.5px;font-size:40px}@media (min-width:640px){h1{font-size:48px}}@media (min-width:880px){h1{font-size:54px}}@media (min-width:1200px){h1{font-size:62px}}@media (min-width:880px){h1{letter-spacing:-1.5px}}@media (min-width:1200px){h1{letter-spacing:-2.5px}}h2{line-height:1.5;letter-spacing:-.5px;font-size:28px}@media (min-width:640px){h2{font-size:32px}}@media (min-width:880px){h2{font-size:36px}}@media (min-width:1200px){h2{font-size:40px}}@media (min-width:880px){h2{letter-spacing:-1px}}h3{line-height:1.25;font-size:26px}@media (min-width:640px){h3{font-size:28px}}@media (min-width:880px){h3{font-size:30px}}@media (min-width:1200px){h3{font-size:32px}}h4{line-height:1.25;font-size:20px}@media (min-width:640px){h4{font-size:22px}}@media (min-width:880px){h4{font-size:22px}}@media (min-width:1200px){h4{font-size:24px}}.site-container{overflow-x:hidden;word-wrap:break-word}.site-inner{padding:24px 0;margin:0 auto;clear:both}@media (min-width:640px){.site-inner{padding:30px 0}}@media (min-width:880px){.site-inner{padding:48px 0}}@media (min-width:1200px){.site-inner{padding:60px 0}}.wrap{width:auto;max-width:100%;margin:0 16px}.wrap::before{display:table;content:" "}.wrap::after{display:table;clear:both;content:""}@media (min-width:640px){.wrap{margin:0 24px}}@media (min-width:880px){.wrap{margin:0 50px}}@media (min-width:1200px){body .wrap{max-width:1110px;margin:0 auto}}@media (min-width:920px){.site-header{width:100%;padding:20px 0 10px}}@media (max-width:920px){.site-header>.wrap{margin:0 10px}}.title-area{position:relative;z-index:99999;float:left;padding:14px 0}@media (min-width:880px){.title-area{padding:8px 0}}.site-title{margin-bottom:0;font-weight:900;line-height:1;text-indent:-9999px;text-transform:uppercase;letter-spacing:2px;font-size:24px}@media (min-width:640px){.site-title{font-size:24px}}@media (min-width:880px){.site-title{font-size:30px}}@media (min-width:1200px){.site-title{font-size:30px}}.site-title a{display:block;width:140px;height:30px;background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/logo-mobile.png*/url() no-repeat center center;background-size:contain}@media (min-width:400px){.site-title a{width:173px;height:36px}}@media (min-width:920px){.site-title a{width:220px;height:47px;margin-top:21px}}@media (min-width:1058px){.site-title a{width:348px;height:64px;margin-top:0;background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/logo.png*/url() no-repeat center center;background-size:contain}}.site-title a{color:#484848;text-decoration:none}.site-description{position:absolute!important;width:1px;height:1px;overflow:hidden;clip:rect(0,0,0,0);word-wrap:normal!important;border:0}.content{max-width:100%;margin:0 auto}@media (min-width:880px){.content{float:left;width:72%;max-width:730px}}.sidebar{max-width:730px;margin:0 auto}@media (min-width:880px){.sidebar{float:right;width:25%}}.sidebar{font-size:16px;line-height:1.5}.sidebar p{margin-bottom:20px}.sidebar__block-title{font-size:20px;line-height:28px}.sidebar__block-content{margin-top:10px;margin-bottom:10px;font-size:14px;line-height:24px}.sidebar .widget{padding:24px;margin-bottom:10px;background-color:#f4f6fa}.sidebar__block{display:flex;flex-direction:column;align-items:center;justify-content:center;text-align:center}.sidebar__block h4{padding:0;margin:0}.sidebar__block h4 a{font-weight:700;color:#051e50;text-decoration:none}.sidebar__block img{margin-bottom:22px;box-shadow:0 15px 30px rgba(0,0,0,.08),0 10px 15px rgba(0,0,0,.12)}.sidebar__block a img{margin-bottom:0}.sidebar__block>:first-child{margin-bottom:20px}.entry-content>*{max-width:100%;margin:16px 0}@media (min-width:880px){.entry-content>*{margin:22px 0}}@media (min-width:1200px){.entry-content>*{margin:24px 0}}.entry-content>:first-child{margin-top:0}.entry-content>:last-child{margin-bottom:0}.pyi-page-hero{position:relative;padding:20px 0 50px}@media (min-width:880px){.pyi-page-hero{padding:60px 0 80px}}.pyi-page-hero::after{position:absolute;bottom:0;width:100%;height:100px;content:'';background-image:/*savepage-url=https://929687.smushcdn.com/2633864/wp-content/themes/pyi/assets/images/wave.png?lossy=1&strip=1&webp=1*/url();background-repeat:repeat-x;background-position:top center;background-size:cover}.single-post .pyi-page-hero::after{display:none;content:none}.pyi-page-hero>.wrap{position:relative}.pyi-page-hero .pyi-hero-left{position:absolute;top:20px;left:-290px;z-index:-1;width:250px;height:250px;background-image:/*savepage-url=https://929687.smushcdn.com/2633864/wp-content/themes/pyi/assets/images/hero_bg_left.png?lossy=1&strip=1&webp=1*/url();background-repeat:no-repeat;background-position:top center;background-size:contain}.pyi-page-hero .pyi-hero-right{position:absolute;top:-80px;right:-200px;z-index:-1;z-index:-1;width:400px;height:500px;background-image:/*savepage-url=https://929687.smushcdn.com/2633864/wp-content/themes/pyi/assets/images/hero_bg_right.png?lossy=1&strip=1&webp=1*/url();background-repeat:no-repeat;background-position:top center;background-size:contain}@media (max-width:879px){.pyi-page-hero .pyi-hero-right{display:none}}.pyi-page-hero .entry-title{max-width:730px}@media (min-width:640px){.footer-cta{display:flex;align-items:center}}.footer-cta input{width:100%;margin-bottom:5px;line-height:1.5;text-align:center;border:2px #6dc713 solid}@media (min-width:640px){.footer-cta input{width:52%;margin-bottom:0;line-height:1.15;text-align:left}}.footer-cta button{width:100%;padding:16px 14px 14px;font-weight:600;line-height:30px;color:#fff;text-align:center;text-transform:uppercase;letter-spacing:1.5px;background-color:#6dc713;border:none;font-size:16px}@media (min-width:640px){.footer-cta button{width:48%}}@media (min-width:1023px){.footer-cta button{padding:17px 14px 16px}}@media (min-width:640px){.footer-cta button{font-size:18px}}@media (min-width:880px){.footer-cta button{font-size:16px}}@media (min-width:1200px){.footer-cta button{font-size:16px}}::-moz-placeholder{color:#4d5a75;opacity:1}::-webkit-input-placeholder{color:#4d5a75}input,textarea{width:100%;padding:20px 24px 16px;font-weight:400;color:#051e50;background-color:#fff;border:2px solid #f4f6fa;font-size:16px}@media (min-width:640px){input,textarea{font-size:18px}}@media (min-width:880px){input,textarea{font-size:20px}}@media (min-width:1200px){input,textarea{font-size:20px}}input[type=search]::-webkit-search-cancel-button,input[type=search]::-webkit-search-results-button{display:none}.search-form{position:relative;max-width:400px;overflow:hidden;border:1px solid #f4f6fa}.search-form .search-field{padding-right:32px;border:none}.search-form .search-submit{position:absolute;top:51%;right:32px;width:24px;min-width:0;height:24px;padding:0;margin:0;margin-top:-12px;text-align:center;background:0 0;border:none}.search-form .search-submit svg{fill:#169fe6}.nav-primary ul{width:100%;margin:0;clear:both;line-height:1}.nav-primary .menu-item{position:relative;float:left;list-style:none}.nav-primary .menu-item a{position:relative;display:block;font-weight:600;line-height:1;color:#051e50;text-decoration:none;border:none;font-size:18px}@media (min-width:640px){.nav-primary .menu-item a{font-size:18px}}@media (min-width:880px){.nav-primary .menu-item a{font-size:14px}}@media (min-width:1200px){.nav-primary .menu-item a{font-size:16px}}@media (max-width:920px){.nav-primary{position:absolute;right:10px;left:10px;z-index:999999;display:none;width:calc(100% - 20px);height:100%;padding:0;clear:both;background:#f4f6fa}.nav-primary .menu-primary{background-color:#051e50}}@media (min-width:921px){.nav-primary{float:right;width:auto}.nav-primary .menu>.menu-item.menu-item-has-children>a{padding-right:26px}.nav-primary .menu>.menu-item>a{padding:24px 12px;border-bottom:2px solid transparent}.nav-primary .menu>.menu-item>a span{padding-bottom:10px;border-bottom:2px solid transparent}.nav-primary .submenu-expand{position:absolute;top:50%;right:8px;margin-top:-5px;line-height:0}.nav-primary .submenu-expand svg{width:10px;height:10px}.nav-primary .sub-menu{position:absolute;left:-9999px;z-index:99;width:180px;background:#fff;box-shadow:0 15px 30px rgba(0,0,0,.08),0 10px 15px rgba(0,0,0,.12);opacity:0}.nav-primary .sub-menu .menu-item{float:none}.nav-primary .sub-menu .menu-item>a{padding:18px 16px 14px 16px;font-size:14px;border-bottom:1px solid #eceff5}}@media (min-width:1200px){.nav-primary .menu>.menu-item>a{padding:24px 16px}}.main-nav-wrap{display:block;float:right;width:auto}@media (min-width:920px){.main-nav-wrap{display:flex}}.nav-primary .is-topics>.sub-menu{width:auto;margin:0 32px 0 42px}@media (min-width:920px){.nav-primary .is-topics>.sub-menu{width:335px;margin-left:16px}}.nav-primary .is-topics .has-icon a{position:relative;padding-left:0}@media (min-width:920px){.nav-primary .is-topics .has-icon a{padding-left:42px}}.nav-primary .is-topics .has-icon a::before{position:absolute;top:13px;left:0;width:16px;height:16px;content:'';filter:brightness(0) invert(1)}@media (min-width:920px){.nav-primary .is-topics .has-icon a::before{top:16px;left:12px;width:16px;height:16px;filter:grayscale(1)}}.nav-primary .is-topics .has-icon.has-icon--deep-learning a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-deeplearning.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--dlib a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-dlib.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--iot a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-iot.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--face a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-face.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--image a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-image.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--interviews a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-interviews.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--keras a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-keras.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--ml a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-ml.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--medical a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-medical.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--ocr a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-ocr.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--object-detection a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-object_detection.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--object-tracking a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-object_tracking.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--opencv a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-opencv.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--pi a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-pi.png*/url() no-repeat center center;background-size:contain}.nav-secondary{display:none;float:right;margin-top:10px}@media (min-width:920px){.nav-secondary{display:block}}.nav-secondary .wrap{margin:0}.nav-secondary ul{width:100%;margin:0;clear:both;line-height:1}.nav-secondary .menu-item{position:relative;float:left;margin-left:28px;list-style:none}@media (min-width:1200px){.nav-secondary .menu-item{margin-left:36px}}.nav-secondary .menu-item a{position:relative;display:block;font-size:16px;font-weight:400;color:#4d5a75;text-decoration:none;border:none;font-size:14px}@media (min-width:640px){.nav-secondary .menu-item a{font-size:14px}}@media (min-width:880px){.nav-secondary .menu-item a{font-size:15px 16px}}.nav-mobile{float:right;width:auto}@media (min-width:921px){.nav-mobile{display:none}}.mobile-menu-toggle{display:block;width:100%;padding:12px 20px 10px;margin-top:14px;font-size:13px;font-weight:700;text-transform:uppercase;letter-spacing:1px;background-color:#eceff5;border:none}.mobile-menu-toggle svg{margin:-2px 10px 0 0;fill:#051e50}.mobile-menu-toggle svg{vertical-align:middle}.mobile-menu-toggle .menu-close,.mobile-menu-toggle .mobile-menu-close{display:none}.header-search{position:relative;display:block;float:right;width:auto;margin:0 auto}@media (max-width:919px){.header-search ::-moz-placeholder{color:#4d5a75;opacity:1}.header-search ::-webkit-input-placeholder{color:#4d5a75}}.header-search input{margin-bottom:0}.header-search ::-moz-placeholder{color:#4d5a75;opacity:1}.header-search ::-webkit-input-placeholder{color:#4d5a75}.header-search .search-form{position:relative;z-index:99999;display:none;display:none;width:100%;margin:0 auto}.header-search .search-submit svg{fill:#169fe6}@media (min-width:920px){.header-search .search-submit svg{fill:#169fe6}}.header-search .mobile-search-toggle{display:block;padding:8px 11px 8px;margin:14px 0 0 4px;background-color:#169fe6;border:none;opacity:1}@media (min-width:920px){.header-search .mobile-search-toggle{position:relative;display:block;float:right;padding:11px 14px 7px;margin:6px -6px 0 16px;background-color:#169fe6}}@media (min-width:1200px){.header-search .mobile-search-toggle{padding:10px 19px 5px 17px;margin:12px 0 0 16px}}.header-search .mobile-search-toggle svg{fill:#fff;width:14px;height:14px;margin-top:calc((14px - 14px)/ 2)}@media (min-width:920px){.header-search .mobile-search-toggle svg{fill:#fff;width:16px;height:16px;margin-top:calc((16px - 16px)/ 2)}}.header-search .mobile-search-toggle .search-close{display:none}.nav-primary .mobile-only{display:block}@media (min-width:920px){.nav-primary .mobile-only{display:none}}.entry-content code{background-color:#f5f5f5}blockquote{font-style:italic;text-align:left;background:0 0}blockquote p{font-weight:400;line-height:1.5;color:#051e50}blockquote cite{display:block;margin-top:20px;font-weight:700;color:#4d5a75;font-size:16px}@media (min-width:640px){blockquote cite{font-size:18px}}blockquote cite .cite-title{display:block;font-weight:400}blockquote p:last-of-type{margin-bottom:0}blockquote::before{position:relative;top:-37px;left:-51px;display:block;height:0;font-size:90px;color:#169fe6;content:'\201C'}@media (min-width:640px){blockquote::before{top:-48px;left:-61px;font-size:110px}}@media (min-width:880px){blockquote::before{top:-48px;left:-55px;font-size:110px}}@media (min-width:1200px){blockquote::before{top:-58px;left:-71px;font-size:120px}}p.entry-meta{margin-bottom:0;font-size:14px}@media (min-width:640px){p.entry-meta{font-size:15px}}@media (min-width:880px){p.entry-meta{font-size:16px}}@media (min-width:1200px){p.entry-meta{font-size:16px}}.entry-categories{display:block}.widget{margin-bottom:60px}.widget a{font-weight:400;color:#4d5a75;text-decoration:underline}.modal{position:relative;z-index:2;box-sizing:border-box;display:none;width:90%;max-width:500px;padding:15px 30px;text-align:left;vertical-align:middle;background:#fff;border-radius:8px;box-shadow:0 0 10px #000;-webkit-border-radius:8px;-moz-border-radius:8px;-o-border-radius:8px;-ms-border-radius:8px;-webkit-box-shadow:0 0 10px #000;-moz-box-shadow:0 0 10px #000;-o-box-shadow:0 0 10px #000;-ms-box-shadow:0 0 10px #000}.modal a.close-modal{position:absolute;top:-12.5px;right:-12.5px;display:block;width:30px;height:30px;text-indent:-9999px;background-repeat:no-repeat;background-position:center center;background-size:contain}.front-page-modal.modal{width:96%;max-width:1110px;padding:20px 20px;border-radius:0}@media (min-width:640px){.front-page-modal.modal{padding:40px 40px}}@media (min-width:880px){.front-page-modal.modal{padding:50px 60px}}@media (min-width:1200px){.front-page-modal.modal{padding:60px 80px}}.front-page-modal.modal p{margin-bottom:24px;font-size:16px}@media (min-width:640px){.front-page-modal.modal p{font-size:18px}}@media (min-width:880px){.front-page-modal.modal p{font-size:18px}}.front-page-modal.modal .front-modal-top{text-align:center}.front-page-modal.modal .front-modal-top h3{margin-bottom:20px;line-height:1.4;font-size:24px}@media (min-width:640px){.front-page-modal.modal .front-modal-top h3{font-size:28px}}@media (min-width:880px){.front-page-modal.modal .front-modal-top h3{font-size:32px}}@media (min-width:1200px){.front-page-modal.modal .front-modal-top h3{font-size:40px}}@media (min-width:880px){.front-page-modal.modal .front-modal-top h3{margin-bottom:40px}}.front-page-modal.modal .front-modal-action{max-width:730px;margin:20px auto}@media (min-width:880px){.front-page-modal.modal .front-modal-action{margin:40px auto}}.front-page-modal.modal .front-modal-action .footer-cta{display:block}@media (min-width:880px){.front-page-modal.modal .front-modal-action .footer-cta{display:flex}}@media (max-width:879px){.front-page-modal.modal .front-modal-action .footer-cta button,.front-page-modal.modal .front-modal-action .footer-cta input{width:100%;margin-bottom:4px;text-align:center}}.front-page-modal.modal .front-modal-video{display:grid;margin:30px auto 30px;grid-gap:30px;grid-template-columns:1fr}@media (min-width:880px){.front-page-modal.modal .front-modal-video{max-width:920px;margin:50px auto 60px;grid-template-columns:1fr 1fr;grid-gap:50px}}@media (min-width:1200px){.front-page-modal.modal .front-modal-video{margin:60px auto 80px;grid-gap:80px}}.front-page-modal.modal .front-modal-testimonial{padding:24px 30px;margin:0 -20px -24px -20px;background-color:#f4f6fa}@media (min-width:640px){.front-page-modal.modal .front-modal-testimonial{padding:40px 50px;margin:0 -40px -40px -40px}}@media (min-width:880px){.front-page-modal.modal .front-modal-testimonial{padding:50px 60px;margin:0 -60px -50px -60px}}@media (min-width:1200px){.front-page-modal.modal .front-modal-testimonial{padding:66px 80px;margin:0 -80px -60px -80px}}.front-page-modal.modal .front-modal-testimonial blockquote{max-width:730px;margin:0 auto 0 40px}@media (min-width:880px){.front-page-modal.modal .front-modal-testimonial blockquote{margin:0 auto}}.front-page-modal.modal .front-modal-testimonial blockquote p{font-size:16px}@media (min-width:640px){.front-page-modal.modal .front-modal-testimonial blockquote p{font-size:18px}}@media (min-width:880px){.front-page-modal.modal .front-modal-testimonial blockquote p{font-size:18px}}.front-page-modal.modal .front-modal-testimonial blockquote cite{margin-top:30px}.front-page-modal ul.is-style-list-checks li{position:relative;padding-left:40px;margin-bottom:15px;font-size:18px;font-weight:600;list-style-type:none}.front-page-modal ul.is-style-list-checks li::before{position:absolute;top:4px;left:0;width:20px;height:20px;content:'';background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/checks_blue.png*/url() no-repeat center center;background-size:contain}.front-page-modal a.close-modal{background-color:#000}.single-post .pyi-page-hero .entry-meta{font-style:italic;color:#4d5a75}.single-post .pyi-page-hero .entry-meta .entry-author,.single-post .pyi-page-hero .entry-meta .entry-time{font-style:normal;font-weight:600}.single-post .pyi-page-hero .entry-meta .entry-categories{font-style:normal}.single-post .pyi-page-hero{padding-bottom:0}.single-post .pyi-page-hero .entry-title{max-width:730px;margin-bottom:20px}.single-post .entry-categories{margin-bottom:20px}.single-post .entry-categories a{display:inline-block;padding:6px 8px;margin-bottom:4px;font-size:13px;line-height:1;color:#4d5a75;text-transform:uppercase;letter-spacing:1px;background-color:#f4f6fa}@media (min-width:880px){.single-post .entry-categories a{margin-bottom:0}}.single-post .site-inner{padding-top:30px}.screen-reader-shortcut,.screen-reader-text{position:absolute!important;width:1px;height:1px;overflow:hidden;clip:rect(0,0,0,0);word-wrap:normal!important;border:0}.genesis-skip-link{margin:0}.genesis-skip-link li{width:0;height:0;list-style:none}.grecaptcha-badge{display:none!important}.enlighter-default .enlighter-raw{display:none;min-width:100%;line-height:inherit;font-size:1em;font-family:inherit;margin:0;padding:0;white-space:pre-wrap;word-wrap:break-word;border:none;box-shadow:none}.enlighter-default .enlighter-btn{display:inline-block;margin:0 5px 0 5px;padding:3px 5px 3px 5px;border:solid 1px #333;background-color:#f0f0f0;font-family:inherit}.enlighter-default .enlighter-toolbar .enlighter-btn-raw{background-image:url(data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22utf-8%22%3F%3E%0D%0A%3C!DOCTYPE%20svg%20PUBLIC%20%22-%2F%2FW3C%2F%2FDTD%20SVG%201.1%2F%2FEN%22%20%22http%3A%2F%2Fwww.w3.org%2FGraphics%2FSVG%2F1.1%2FDTD%2Fsvg11.dtd%22%3E%0D%0A%3Csvg%20version%3D%221.1%22%20id%3D%22Ebene_2%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20xmlns%3Axlink%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxlink%22%20x%3D%220px%22%20y%3D%220px%22%0D%0A%09%20width%3D%2246px%22%20height%3D%2246px%22%20viewBox%3D%220%200%2046%2046%22%20enable-background%3D%22new%200%200%2046%2046%22%20xml%3Aspace%3D%22preserve%22%3E%0D%0A%3Cg%3E%0D%0A%09%3Cpath%20d%3D%22M19.436%2C36.875L6.568%2C25.002v-3.863L19.436%2C9.267v5.041l-9.583%2C8.668v0.188l9.583%2C8.669V36.875z%22%2F%3E%0D%0A%09%3Cpath%20d%3D%22M26.343%2C36.875v-5.041l9.583-8.669v-0.188l-9.583-8.668V9.267l12.868%2C11.872v3.863L26.343%2C36.875z%22%2F%3E%0D%0A%3C%2Fg%3E%0D%0A%3C%2Fsvg%3E%0D%0A)}.enlighter-default .enlighter-toolbar .enlighter-btn-copy{background-image:url(data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22utf-8%22%3F%3E%0D%0A%3C!DOCTYPE%20svg%20PUBLIC%20%22-%2F%2FW3C%2F%2FDTD%20SVG%201.1%2F%2FEN%22%20%22http%3A%2F%2Fwww.w3.org%2FGraphics%2FSVG%2F1.1%2FDTD%2Fsvg11.dtd%22%3E%0D%0A%3Csvg%20version%3D%221.1%22%20id%3D%22Ebene_2%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20xmlns%3Axlink%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxlink%22%20x%3D%220px%22%20y%3D%220px%22%0D%0A%09%20width%3D%2246px%22%20height%3D%2246px%22%20viewBox%3D%220%200%2046%2046%22%20enable-background%3D%22new%200%200%2046%2046%22%20xml%3Aspace%3D%22preserve%22%3E%0D%0A%3Cline%20fill%3D%22none%22%20stroke%3D%22%23000000%22%20stroke-width%3D%224%22%20stroke-miterlimit%3D%2210%22%20x1%3D%2253.75%22%20y1%3D%2239.353%22%20x2%3D%2286.375%22%20y2%3D%2239.353%22%2F%3E%0D%0A%3Cline%20fill%3D%22none%22%20stroke%3D%22%23000000%22%20stroke-width%3D%224%22%20stroke-miterlimit%3D%2210%22%20x1%3D%2251.711%22%20y1%3D%2230.534%22%20x2%3D%2284.336%22%20y2%3D%2230.534%22%2F%3E%0D%0A%3Crect%20x%3D%228.932%22%20y%3D%227.334%22%20fill%3D%22%23FFFFFF%22%20stroke%3D%22%23000000%22%20stroke-width%3D%223%22%20stroke-miterlimit%3D%2210%22%20width%3D%2221.097%22%20height%3D%2224.952%22%2F%3E%0D%0A%3Crect%20x%3D%2218.942%22%20y%3D%2215.424%22%20fill%3D%22%23FFFFFF%22%20stroke%3D%22%23000000%22%20stroke-width%3D%223%22%20stroke-miterlimit%3D%2210%22%20width%3D%2221.096%22%20height%3D%2224.953%22%2F%3E%0D%0A%3C%2Fsvg%3E%0D%0A)}.enlighter-default .enlighter-toolbar .enlighter-btn-window{background-image:url(data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22utf-8%22%3F%3E%0D%0A%3C!DOCTYPE%20svg%20PUBLIC%20%22-%2F%2FW3C%2F%2FDTD%20SVG%201.1%2F%2FEN%22%20%22http%3A%2F%2Fwww.w3.org%2FGraphics%2FSVG%2F1.1%2FDTD%2Fsvg11.dtd%22%3E%0D%0A%3Csvg%20version%3D%221.1%22%20id%3D%22Ebene_2%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20xmlns%3Axlink%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxlink%22%20x%3D%220px%22%20y%3D%220px%22%0D%0A%09%20width%3D%2246px%22%20height%3D%2246px%22%20viewBox%3D%220%200%2046%2046%22%20enable-background%3D%22new%200%200%2046%2046%22%20xml%3Aspace%3D%22preserve%22%3E%0D%0A%3Cline%20fill%3D%22none%22%20stroke%3D%22%23000000%22%20stroke-width%3D%224%22%20stroke-miterlimit%3D%2210%22%20x1%3D%227.125%22%20y1%3D%229.25%22%20x2%3D%2239.75%22%20y2%3D%229.25%22%2F%3E%0D%0A%3Cline%20fill%3D%22none%22%20stroke%3D%22%23000000%22%20stroke-width%3D%224%22%20stroke-miterlimit%3D%2210%22%20x1%3D%227.125%22%20y1%3D%2218.167%22%20x2%3D%2239.75%22%20y2%3D%2218.167%22%2F%3E%0D%0A%3Cline%20fill%3D%22none%22%20stroke%3D%22%23000000%22%20stroke-width%3D%224%22%20stroke-miterlimit%3D%2210%22%20x1%3D%227.125%22%20y1%3D%2227.083%22%20x2%3D%2239.75%22%20y2%3D%2227.083%22%2F%3E%0D%0A%3Cline%20fill%3D%22none%22%20stroke%3D%22%23000000%22%20stroke-width%3D%224%22%20stroke-miterlimit%3D%2210%22%20x1%3D%227.125%22%20y1%3D%2236%22%20x2%3D%2229.809%22%20y2%3D%2236%22%2F%3E%0D%0A%3C%2Fsvg%3E%0D%0A)}.enlighter-default .enlighter-toolbar .enlighter-btn-website{background-image:url(data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22utf-8%22%3F%3E%0D%0A%3C!DOCTYPE%20svg%20PUBLIC%20%22-%2F%2FW3C%2F%2FDTD%20SVG%201.1%2F%2FEN%22%20%22http%3A%2F%2Fwww.w3.org%2FGraphics%2FSVG%2F1.1%2FDTD%2Fsvg11.dtd%22%3E%0D%0A%3Csvg%20version%3D%221.1%22%20id%3D%22E%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20xmlns%3Axlink%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxlink%22%20x%3D%220px%22%20y%3D%220px%22%0D%0A%09%20width%3D%2246px%22%20height%3D%2246px%22%20viewBox%3D%220%200%2046%2046%22%20enable-background%3D%22new%200%200%2046%2046%22%20xml%3Aspace%3D%22preserve%22%3E%0D%0A%3Cg%3E%0D%0A%09%3Cpath%20fill%3D%22%23202F65%22%20d%3D%22M32.48%2C25.614H19.64l-4.933%2C9.826l17.746%2C0.037l-6.173%2C5.358L8.167%2C40.912L16.29%2C6.055h22.974l-5.734%2C5.354%0D%0A%09%09l-13.306-0.027l0.672%2C8.797h12.841L32.48%2C25.614z%22%2F%3E%0D%0A%3C%2Fg%3E%0D%0A%3C%2Fsvg%3E%0D%0A)}.enlighter-origin{display:none!important}.enlighter-toolbar{display:none;position:absolute;right:10px;top:10px;z-index:10}.enlighter-toolbar-bottom{top:unset;bottom:0}html body { opacity: 1 !important; } 

@font-face {
font-family:"proxima-nova";
src:/*savepage-url=https://use.typekit.net/af/705e94/00000000000000003b9b3062/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3*/url() format("woff2"),/*savepage-url=https://use.typekit.net/af/705e94/00000000000000003b9b3062/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3*/url() format("woff"),/*savepage-url=https://use.typekit.net/af/705e94/00000000000000003b9b3062/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3*/url() format("opentype");
/*savepage-font-display=swap*/font-style:normal;font-weight:400;
}
@font-face {
font-family:"proxima-nova";
src:/*savepage-url=https://use.typekit.net/af/576d53/00000000000000003b9b3066/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3*/url() format("woff2"),/*savepage-url=https://use.typekit.net/af/576d53/00000000000000003b9b3066/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3*/url() format("woff"),/*savepage-url=https://use.typekit.net/af/576d53/00000000000000003b9b3066/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3*/url() format("opentype");
/*savepage-font-display=swap*/font-style:normal;font-weight:600;
}
@font-face {
font-family:"proxima-nova";
src:/*savepage-url=https://use.typekit.net/af/949f99/00000000000000003b9b3068/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3*/url() format("woff2"),/*savepage-url=https://use.typekit.net/af/949f99/00000000000000003b9b3068/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3*/url() format("woff"),/*savepage-url=https://use.typekit.net/af/949f99/00000000000000003b9b3068/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3*/url() format("opentype");
/*savepage-font-display=swap*/font-style:normal;font-weight:700;
}
@font-face {
  font-family: 'Bree Serif';
  font-style: normal;
  font-weight: 400;
  src: /*savepage-url=https://fonts.gstatic.com/s/breeserif/v10/4UaHrEJCrhhnVA3DgluA96rp5w.woff2*/ url() format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
@font-face {
  font-family: 'Open Sans';
  font-style: normal;
  font-weight: 300;
  src: /*savepage-url=https://fonts.gstatic.com/s/opensans/v20/mem5YaGs126MiZpBA-UN_r8OUuhp.woff2*/ url() format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
@font-face {
  font-family: 'Open Sans';
  font-style: normal;
  font-weight: 400;
  src: /*savepage-url=https://fonts.gstatic.com/s/opensans/v20/mem8YaGs126MiZpBA-UFVZ0b.woff2*/ url() format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
@font-face {
  font-family: 'Open Sans';
  font-style: normal;
  font-weight: 700;
  src: /*savepage-url=https://fonts.gstatic.com/s/opensans/v20/mem5YaGs126MiZpBA-UN7rgOUuhp.woff2*/ url() format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
@font-face {
  font-family: 'Muli';
  font-style: normal;
  font-weight: 700;
  /*savepage-font-display=swap*/
  src: /*savepage-url=https://fonts.gstatic.com/s/muli/v22/7Auwp_0qiz-afTLGLQ.woff2*/ url() format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 700;
  /*savepage-font-display=swap*/
  src: /*savepage-url=https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmWUlfBBc4.woff2*/ url() format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 300;
  /*savepage-font-display=swap*/
  src: /*savepage-url=https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmSU5fBBc4.woff2*/ url() format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 400;
  /*savepage-font-display=swap*/
  src: /*savepage-url=https://fonts.gstatic.com/s/roboto/v27/KFOmCnqEu92Fr1Mu4mxK.woff2*/ url() format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
.nav-mobile { float: right; width: auto; }</style><style id="avlabs-rocket-critical-css">:root{--wp-admin-theme-color:#007cba;--wp-admin-theme-color-darker-10:#006ba1;--wp-admin-theme-color-darker-20:#005a87}.sticky{position:relative;z-index:0;-webkit-transform:translate3d(0,0,0);transform:translate3d(0,0,0)}.sticky.is-anchored{position:relative;right:auto;left:auto}#pyis-cta-modal-sticky-bar{margin:1.25rem 0}#pyis-cta-modal-sticky-bar .grid-container{padding-right:.625rem;padding-left:.625rem;max-width:75rem;margin-left:auto;margin-right:auto}@media print,screen and (min-width:40em){#pyis-cta-modal-sticky-bar .grid-container{padding-right:.9375rem;padding-left:.9375rem}}#pyis-cta-modal-sticky-bar .grid-x{display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-flow:row wrap;-ms-flex-flow:row wrap;flex-flow:row wrap}#pyis-cta-modal-sticky-bar .cell{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;min-height:0;min-width:0;width:100%}#pyis-cta-modal-sticky-bar .grid-margin-x{margin-left:-.625rem;margin-right:-.625rem}@media print,screen and (min-width:40em){#pyis-cta-modal-sticky-bar .grid-margin-x{margin-left:-.9375rem;margin-right:-.9375rem}}#pyis-cta-modal-sticky-bar .grid-margin-x>.cell{width:calc(100% - 1.25rem);margin-left:.625rem;margin-right:.625rem}@media print,screen and (min-width:40em){#pyis-cta-modal-sticky-bar .grid-margin-x>.cell{width:calc(100% - 1.875rem);margin-left:.9375rem;margin-right:.9375rem}}#pyis-cta-modal-sticky-bar .text-center{text-align:center}#pyis-cta-modal-sticky-bar .sticky{background-color:#051e50;color:#fefefe;padding:1.625rem 1rem 1.25rem 1.625rem}#pyis-cta-modal-sticky-bar .sticky a{background:0 0;outline:0;font-size:1.2rem;padding:0;border-bottom:none;color:#fefefe;text-decoration:underline;position:relative}#pyis-cta-modal-sticky-bar .sticky a:before{position:absolute;top:-.5625rem;left:-3.75rem;display:block;width:2.5rem;height:2.5rem;content:'';background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/source_code_mini_image.png*/url();background-size:contain}#pyis-cta-modal .modal-content{margin-top:1.5rem}#pyis-cta-modal .optin-modal-content .pyuni-logo{padding-bottom:20px;max-width:400px}#pyis-cta-modal .optin-modal-content h3{margin-bottom:20px;font-size:24px}#pyis-cta-modal .optin-modal-content .is-style-list-checks li{font-weight:400}button,input{overflow:visible}html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}h1{margin:0.67em 0;font-size:2em}a{background-color:transparent}strong{font-weight:bolder}img{border-style:none}button,input{margin:0;font-family:inherit;font-size:100%;line-height:1.15}button{text-transform:none}[type='submit'],button{-webkit-appearance:button}[type='submit']::-moz-focus-inner,button::-moz-focus-inner{padding:0;border-style:none}[type='submit']:-moz-focusring,button:-moz-focusring{outline:ButtonText dotted 1px}[type='search']{outline-offset:-2px;-webkit-appearance:textfield}[type='search']::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}html{box-sizing:border-box}*,*,*:after{box-sizing:inherit}.entry::before,.entry-content::before,.nav-primary::before,.nav-secondary::before,.site-container::before,.site-header::before,.site-inner::before,.widget::before,.wrap::before{display:table;content:" "}.entry::after,.entry-content::after,.nav-primary::after,.nav-secondary::after,.site-container::after,.site-header::after,.site-inner::after,.widget::after,.wrap::after{display:table;clear:both;content:""}html,input[type='search']{box-sizing:border-box}*,*:before,*:after{box-sizing:inherit}html{overflow-y:scroll;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}body{margin:0;font-family:proxima-nova,sans-serif;font-weight:400;line-height:1.472;color:#051e50;font-size:17px}@media (min-width:640px){body{line-height:1.52}}@media (min-width:880px){body{line-height:1.568}}@media (min-width:1200px){body{line-height:1.6}}@media (min-width:640px){body{font-size:19px}}@media (min-width:880px){body{font-size:20px}}a{font-weight:700;color:#169fe6;text-decoration:none}.entry-content a{border-bottom:1px solid #169fe6}:focus{outline:none}ul{padding:0;margin:0}li{list-style-type:none}em{font-style:italic}cite{font-style:normal}img{max-width:100%}img{display:block;height:auto}p{padding:0;margin:0 0 24px}@media (min-width:640px){p{margin:0 0 32px}}h1,h2,h3,h4{margin:0 0 30px;font-family:proxima-nova,sans-serif;font-weight:700}h4 a{color:#169fe6}h1{line-height:1.06;letter-spacing:-0.5px;font-size:40px}@media (min-width:640px){h1{font-size:48px}}@media (min-width:880px){h1{font-size:54px}}@media (min-width:1200px){h1{font-size:62px}}@media (min-width:880px){h1{letter-spacing:-1.5px}}@media (min-width:1200px){h1{letter-spacing:-2.5px}}h2{line-height:1.5;letter-spacing:-0.5px;font-size:28px}@media (min-width:640px){h2{font-size:32px}}@media (min-width:880px){h2{font-size:36px}}@media (min-width:1200px){h2{font-size:40px}}@media (min-width:880px){h2{letter-spacing:-1px}}h3{line-height:1.25;font-size:26px}@media (min-width:640px){h3{font-size:28px}}@media (min-width:880px){h3{font-size:30px}}@media (min-width:1200px){h3{font-size:32px}}h4{line-height:1.25;font-size:20px}@media (min-width:640px){h4{font-size:22px}}@media (min-width:880px){h4{font-size:22px}}@media (min-width:1200px){h4{font-size:24px}}.site-container{overflow-x:hidden;word-wrap:break-word}.site-inner{padding:24px 0;margin:0 auto;clear:both}@media (min-width:640px){.site-inner{padding:30px 0}}@media (min-width:880px){.site-inner{padding:48px 0}}@media (min-width:1200px){.site-inner{padding:60px 0}}.wrap{width:auto;max-width:100%;margin:0 16px}.wrap::before{display:table;content:" "}.wrap::after{display:table;clear:both;content:""}@media (min-width:640px){.wrap{margin:0 24px}}@media (min-width:880px){.wrap{margin:0 50px}}@media (min-width:1200px){.wrap{max-width:1110px;margin:0 auto}}@media (min-width:920px){.site-header{width:100%;padding:20px 0 10px}}@media (max-width:920px){.site-header>.wrap{margin:0 10px}}.title-area{position:relative;z-index:99999;float:left;padding:14px 0}@media (min-width:880px){.title-area{padding:8px 0}}.site-title{margin-bottom:0;font-weight:900;line-height:1;text-indent:-9999px;text-transform:uppercase;letter-spacing:2px;font-size:24px}@media (min-width:640px){.site-title{font-size:24px}}@media (min-width:880px){.site-title{font-size:30px}}@media (min-width:1200px){.site-title{font-size:30px}}.site-title a{display:block;width:140px;height:30px;background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/logo-mobile.png*/url() no-repeat center center;background-size:contain}@media (min-width:400px){.site-title a{width:173px;height:36px}}@media (min-width:920px){.site-title a{width:220px;height:47px;margin-top:21px}}@media (min-width:1058px){.site-title a{width:348px;height:64px;margin-top:0;background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/logo.png*/url() no-repeat center center;background-size:contain}}.site-title a{color:#484848;text-decoration:none}.site-description{position:absolute!important;width:1px;height:1px;overflow:hidden;clip:rect(0,0,0,0);word-wrap:normal!important;border:0}.content{max-width:100%;margin:0 auto}@media (min-width:880px){.content{float:left;width:72%;max-width:730px}}.sidebar{max-width:730px;margin:0 auto}@media (min-width:880px){.sidebar{float:right;width:25%}}.sidebar{font-size:16px;line-height:1.5}.sidebar p{margin-bottom:20px}.sidebar__block-title{font-size:20px;line-height:28px}.sidebar__block-content{margin-top:10px;margin-bottom:10px;font-size:14px;line-height:24px}.sidebar .widget{padding:24px;margin-bottom:10px;background-color:#f4f6fa}.sidebar__block{display:flex;flex-direction:column;align-items:center;justify-content:center;text-align:center}.sidebar__block h4{padding:0;margin:0}.sidebar__block h4 a{font-weight:700;color:#051e50;text-decoration:none}.sidebar__block img{margin-bottom:22px;box-shadow:0 15px 30px rgba(0,0,0,0.08),0 10px 15px rgba(0,0,0,0.12)}.sidebar__block a img{margin-bottom:0}.sidebar__block>:first-child{margin-bottom:20px}.entry-content>*{max-width:100%;margin:16px 0}@media (min-width:880px){.entry-content>*{margin:22px 0}}@media (min-width:1200px){.entry-content>*{margin:24px 0}}.entry-content>*:first-child{margin-top:0}.pyi-page-hero{position:relative;padding:20px 0 50px}@media (min-width:880px){.pyi-page-hero{padding:60px 0 80px}}.pyi-page-hero::after{position:absolute;bottom:0;width:100%;height:100px;content:'';background-image:/*savepage-url=https://929687.smushcdn.com/2633864/wp-content/themes/pyi/assets/images/wave.png?lossy=1&strip=1&webp=1*/url();background-repeat:repeat-x;background-position:top center;background-size:cover}.single-post .pyi-page-hero::after{display:none;content:none}.pyi-page-hero>.wrap{position:relative}.pyi-page-hero .pyi-hero-left{position:absolute;top:20px;left:-290px;z-index:-1;width:250px;height:250px;background-image:/*savepage-url=https://929687.smushcdn.com/2633864/wp-content/themes/pyi/assets/images/hero_bg_left.png?lossy=1&strip=1&webp=1*/url();background-repeat:no-repeat;background-position:top center;background-size:contain}.pyi-page-hero .pyi-hero-right{position:absolute;top:-80px;right:-200px;z-index:-1;z-index:-1;width:400px;height:500px;background-image:/*savepage-url=https://929687.smushcdn.com/2633864/wp-content/themes/pyi/assets/images/hero_bg_right.png?lossy=1&strip=1&webp=1*/url();background-repeat:no-repeat;background-position:top center;background-size:contain}@media (max-width:879px){.pyi-page-hero .pyi-hero-right{display:none}}.pyi-page-hero .entry-title{max-width:730px}@media (min-width:640px){.footer-cta{display:flex;align-items:center}}.footer-cta input{width:100%;margin-bottom:5px;line-height:1.5;text-align:center;border:2px #6dc713 solid}@media (min-width:640px){.footer-cta input{width:52%;margin-bottom:0;line-height:1.15;text-align:left}}.footer-cta button{width:100%;padding:16px 14px 14px;font-weight:600;line-height:30px;color:#fff;text-align:center;text-transform:uppercase;letter-spacing:1.5px;background-color:#6dc713;border:none;font-size:16px}@media (min-width:640px){.footer-cta button{width:48%}}@media (min-width:1023px){.footer-cta button{padding:17px 14px 16px}}@media (min-width:640px){.footer-cta button{font-size:18px}}@media (min-width:880px){.footer-cta button{font-size:16px}}@media (min-width:1200px){.footer-cta button{font-size:16px}}::-moz-placeholder{color:#4d5a75;opacity:1}::-webkit-input-placeholder{color:#4d5a75}input{width:100%;padding:20px 24px 16px;font-weight:400;color:#051e50;background-color:#fff;border:2px solid #f4f6fa;font-size:16px}@media (min-width:640px){input{font-size:18px}}@media (min-width:880px){input{font-size:20px}}@media (min-width:1200px){input{font-size:20px}}input[type='search']::-webkit-search-cancel-button,input[type='search']::-webkit-search-results-button{display:none}.search-form{position:relative;max-width:400px;overflow:hidden;border:1px solid #f4f6fa}.search-form .search-field{padding-right:32px;border:none}.search-form .search-submit{position:absolute;top:51%;right:32px;width:24px;min-width:0;height:24px;padding:0;margin:0;margin-top:-12px;text-align:center;background:transparent;border:none}.search-form .search-submit svg{fill:#169fe6}.nav-primary ul{width:100%;margin:0;clear:both;line-height:1}.nav-primary .menu-item{position:relative;float:left;list-style:none}.nav-primary .menu-item a{position:relative;display:block;font-weight:600;line-height:1;color:#051e50;text-decoration:none;border:none;font-size:18px}@media (min-width:640px){.nav-primary .menu-item a{font-size:18px}}@media (min-width:880px){.nav-primary .menu-item a{font-size:14px}}@media (min-width:1200px){.nav-primary .menu-item a{font-size:16px}}@media (max-width:920px){.nav-primary{position:absolute;right:10px;left:10px;z-index:999999;display:none;width:calc(100% - 20px);height:100%;padding:0;clear:both;background:#f4f6fa}.nav-primary .menu-primary{background-color:#051e50}}@media (min-width:921px){.nav-primary{float:right;width:auto}.nav-primary .menu>.menu-item.menu-item-has-children>a{padding-right:26px}.nav-primary .menu>.menu-item>a{padding:24px 12px;border-bottom:2px solid transparent}.nav-primary .menu>.menu-item>a span{padding-bottom:10px;border-bottom:2px solid transparent}.nav-primary .submenu-expand{position:absolute;top:50%;right:8px;margin-top:-5px;line-height:0}.nav-primary .submenu-expand svg{width:10px;height:10px}.nav-primary .sub-menu{position:absolute;left:-9999px;z-index:99;width:180px;background:#fff;box-shadow:0 15px 30px rgba(0,0,0,0.08),0 10px 15px rgba(0,0,0,0.12);opacity:0}.nav-primary .sub-menu .menu-item{float:none}.nav-primary .sub-menu .menu-item>a{padding:18px 16px 14px 16px;font-size:14px;border-bottom:1px solid #eceff5}}@media (min-width:1200px){.nav-primary .menu>.menu-item>a{padding:24px 16px}}.main-nav-wrap{display:block;float:right;width:auto}@media (min-width:920px){.main-nav-wrap{display:flex}}.nav-primary .is-topics>.sub-menu{width:auto;margin:0 32px 0 42px}@media (min-width:920px){.nav-primary .is-topics>.sub-menu{width:335px;margin-left:16px}}.nav-primary .is-topics .has-icon a{position:relative;padding-left:0px}@media (min-width:920px){.nav-primary .is-topics .has-icon a{padding-left:42px}}.nav-primary .is-topics .has-icon a::before{position:absolute;top:13px;left:0;width:16px;height:16px;content:'';filter:brightness(0) invert(1)}@media (min-width:920px){.nav-primary .is-topics .has-icon a::before{top:16px;left:12px;width:16px;height:16px;filter:grayscale(1)}}.nav-primary .is-topics .has-icon.has-icon--deep-learning a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-deeplearning.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--dlib a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-dlib.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--iot a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-iot.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--face a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-face.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--image a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-image.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--interviews a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-interviews.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--keras a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-keras.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--ml a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-ml.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--medical a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-medical.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--ocr a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-ocr.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--object-detection a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-object_detection.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--object-tracking a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-object_tracking.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--opencv a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-opencv.png*/url() no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--pi a::before{background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-pi.png*/url() no-repeat center center;background-size:contain}.nav-secondary{display:none;float:right;margin-top:10px}@media (min-width:920px){.nav-secondary{display:block}}.nav-secondary .wrap{margin:0}.nav-secondary ul{width:100%;margin:0;clear:both;line-height:1}.nav-secondary .menu-item{position:relative;float:left;margin-left:28px;list-style:none}@media (min-width:1200px){.nav-secondary .menu-item{margin-left:36px}}.nav-secondary .menu-item a{position:relative;display:block;font-size:16px;font-weight:400;color:#4d5a75;text-decoration:none;border:none;font-size:14px}@media (min-width:640px){.nav-secondary .menu-item a{font-size:14px}}@media (min-width:880px){.nav-secondary .menu-item a{font-size:15px 16px}}.nav-mobile{float:right;width:auto}@media (min-width:921px){.nav-mobile{display:none}}.mobile-menu-toggle{display:block;width:100%;padding:12px 20px 10px;margin-top:14px;font-size:13px;font-weight:700;text-transform:uppercase;letter-spacing:1px;background-color:#eceff5;border:none}.mobile-menu-toggle svg{margin:-2px 10px 0 0;fill:#051e50}.mobile-menu-toggle svg{vertical-align:middle}.mobile-menu-toggle .menu-close,.mobile-menu-toggle .mobile-menu-close{display:none}.header-search{position:relative;display:block;float:right;width:auto;margin:0 auto}@media (max-width:919px){.header-search ::-moz-placeholder{color:#4d5a75;opacity:1}.header-search ::-webkit-input-placeholder{color:#4d5a75}}.header-search input{margin-bottom:0}.header-search ::-moz-placeholder{color:#4d5a75;opacity:1}.header-search ::-webkit-input-placeholder{color:#4d5a75}.header-search .search-form{position:relative;z-index:99999;display:none;display:none;width:100%;margin:0 auto}.header-search .search-submit svg{fill:#169fe6}@media (min-width:920px){.header-search .search-submit svg{fill:#169fe6}}.header-search .mobile-search-toggle{display:block;padding:8px 11px 8px;margin:14px 0 0 4px;background-color:#169fe6;border:none;opacity:1}@media (min-width:920px){.header-search .mobile-search-toggle{position:relative;display:block;float:right;padding:11px 14px 7px;margin:6px -6px 0 16px;background-color:#169fe6}}@media (min-width:1200px){.header-search .mobile-search-toggle{padding:10px 19px 5px 17px;margin:12px 0 0 16px}}.header-search .mobile-search-toggle svg{fill:#fff;width:14px;height:14px;margin-top:calc((14px - 14px) / 2)}@media (min-width:920px){.header-search .mobile-search-toggle svg{fill:#fff;width:16px;height:16px;margin-top:calc((16px - 16px) / 2)}}.header-search .mobile-search-toggle .search-close{display:none}.nav-primary .mobile-only{display:block}@media (min-width:920px){.nav-primary .mobile-only{display:none}}blockquote{font-style:italic;text-align:left;background:transparent}blockquote p{font-weight:400;line-height:1.5;color:#051e50}blockquote cite{display:block;margin-top:20px;font-weight:700;color:#4d5a75;font-size:16px}@media (min-width:640px){blockquote cite{font-size:18px}}blockquote cite .cite-title{display:block;font-weight:400}blockquote p:last-of-type{margin-bottom:0}blockquote::before{position:relative;top:-37px;left:-51px;display:block;height:0;font-size:90px;color:#169fe6;content:'\201C'}@media (min-width:640px){blockquote::before{top:-48px;left:-61px;font-size:110px}}@media (min-width:880px){blockquote::before{top:-48px;left:-55px;font-size:110px}}@media (min-width:1200px){blockquote::before{top:-58px;left:-71px;font-size:120px}}p.entry-meta{margin-bottom:0;font-size:14px}@media (min-width:640px){p.entry-meta{font-size:15px}}@media (min-width:880px){p.entry-meta{font-size:16px}}@media (min-width:1200px){p.entry-meta{font-size:16px}}.entry-categories{display:block}.widget{margin-bottom:60px}.widget a{font-weight:400;color:#4d5a75;text-decoration:underline}.modal{position:relative;z-index:2;box-sizing:border-box;display:none;width:90%;max-width:500px;padding:15px 30px;text-align:left;vertical-align:middle;background:#fff;border-radius:8px;box-shadow:0 0 10px #000;-webkit-border-radius:8px;-moz-border-radius:8px;-o-border-radius:8px;-ms-border-radius:8px;-webkit-box-shadow:0 0 10px #000;-moz-box-shadow:0 0 10px #000;-o-box-shadow:0 0 10px #000;-ms-box-shadow:0 0 10px #000}.modal a.close-modal{position:absolute;top:-12.5px;right:-12.5px;display:block;width:30px;height:30px;text-indent:-9999px;background-repeat:no-repeat;background-position:center center;background-size:contain}.front-page-modal.modal{width:96%;max-width:1110px;padding:20px 20px;border-radius:0}@media (min-width:640px){.front-page-modal.modal{padding:40px 40px}}@media (min-width:880px){.front-page-modal.modal{padding:50px 60px}}@media (min-width:1200px){.front-page-modal.modal{padding:60px 80px}}.front-page-modal.modal p{margin-bottom:24px;font-size:16px}@media (min-width:640px){.front-page-modal.modal p{font-size:18px}}@media (min-width:880px){.front-page-modal.modal p{font-size:18px}}.front-page-modal.modal .front-modal-top{text-align:center}.front-page-modal.modal .front-modal-top h3{margin-bottom:20px;line-height:1.4;font-size:24px}@media (min-width:640px){.front-page-modal.modal .front-modal-top h3{font-size:28px}}@media (min-width:880px){.front-page-modal.modal .front-modal-top h3{font-size:32px}}@media (min-width:1200px){.front-page-modal.modal .front-modal-top h3{font-size:40px}}@media (min-width:880px){.front-page-modal.modal .front-modal-top h3{margin-bottom:40px}}.front-page-modal.modal .front-modal-action{max-width:730px;margin:20px auto}@media (min-width:880px){.front-page-modal.modal .front-modal-action{margin:40px auto}}.front-page-modal.modal .front-modal-action .footer-cta{display:block}@media (min-width:880px){.front-page-modal.modal .front-modal-action .footer-cta{display:flex}}@media (max-width:879px){.front-page-modal.modal .front-modal-action .footer-cta input,.front-page-modal.modal .front-modal-action .footer-cta button{width:100%;margin-bottom:4px;text-align:center}}.front-page-modal.modal .front-modal-video{display:grid;margin:30px auto 30px;grid-gap:30px;grid-template-columns:1fr}@media (min-width:880px){.front-page-modal.modal .front-modal-video{max-width:920px;margin:50px auto 60px;grid-template-columns:1fr 1fr;grid-gap:50px}}@media (min-width:1200px){.front-page-modal.modal .front-modal-video{margin:60px auto 80px;grid-gap:80px}}.front-page-modal.modal .front-modal-testimonial{padding:24px 30px;margin:0 -20px -24px -20px;background-color:#f4f6fa}@media (min-width:640px){.front-page-modal.modal .front-modal-testimonial{padding:40px 50px;margin:0 -40px -40px -40px}}@media (min-width:880px){.front-page-modal.modal .front-modal-testimonial{padding:50px 60px;margin:0 -60px -50px -60px}}@media (min-width:1200px){.front-page-modal.modal .front-modal-testimonial{padding:66px 80px;margin:0 -80px -60px -80px}}.front-page-modal.modal .front-modal-testimonial blockquote{max-width:730px;margin:0 auto 0 40px}@media (min-width:880px){.front-page-modal.modal .front-modal-testimonial blockquote{margin:0 auto}}.front-page-modal.modal .front-modal-testimonial blockquote p{font-size:16px}@media (min-width:640px){.front-page-modal.modal .front-modal-testimonial blockquote p{font-size:18px}}@media (min-width:880px){.front-page-modal.modal .front-modal-testimonial blockquote p{font-size:18px}}.front-page-modal.modal .front-modal-testimonial blockquote cite{margin-top:30px}.front-page-modal ul.is-style-list-checks li{position:relative;padding-left:40px;margin-bottom:15px;font-size:18px;font-weight:600;list-style-type:none}.front-page-modal ul.is-style-list-checks li::before{position:absolute;top:4px;left:0;width:20px;height:20px;content:'';background:/*savepage-url=https://pyimagesearch.com/wp-content/themes/pyi/assets/images/checks_blue.png*/url() no-repeat center center;background-size:contain}.front-page-modal a.close-modal{background-color:#000}.single-post .pyi-page-hero .entry-meta{font-style:italic;color:#4d5a75}.single-post .pyi-page-hero .entry-meta .entry-author,.single-post .pyi-page-hero .entry-meta .entry-time{font-style:normal;font-weight:600}.single-post .pyi-page-hero .entry-meta .entry-categories{font-style:normal}.single-post .pyi-page-hero{padding-bottom:0}.single-post .pyi-page-hero .entry-title{max-width:730px;margin-bottom:20px}.single-post .entry-categories{margin-bottom:20px}.single-post .entry-categories a{display:inline-block;padding:6px 8px;margin-bottom:4px;font-size:13px;line-height:1;color:#4d5a75;text-transform:uppercase;letter-spacing:1px;background-color:#f4f6fa}@media (min-width:880px){.single-post .entry-categories a{margin-bottom:0}}.single-post .site-inner{padding-top:30px}.screen-reader-shortcut,.screen-reader-text{position:absolute!important;width:1px;height:1px;overflow:hidden;clip:rect(0,0,0,0);word-wrap:normal!important;border:0}.genesis-skip-link{margin:0}.genesis-skip-link li{width:0;height:0;list-style:none}</style><link rel="stylesheet" href="https://pyimagesearch.com/wp-content/cache/min/1/803b014a2437c8bfad3d0b2990a1b1fe.css" media="all" type="text/css"><style id="avlabs-custom-critical-css-after-rocket">img.centered, .aligncenter { display: block;  margin: 0 auto;}
#loader-wrapper{ display: none; }
.pyi-top-bar {
  position: sticky;
  top: 0;
  z-index: 999999;
  width: 100%;
  padding: 16px 0 14px;
  font-weight: 600;
  color: #fff;
  text-align: center;
  background-color: #051e50;
  font-size: 14px;
}</style>
	<meta name="description" content="Detecting the brightest spot in an image is an easy, two step process. In this post, I'll show you how to use Python & OpenCV to detect bright spots in images.">
	<meta name="robots" content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1">
	<link rel="canonical" data-savepage-href="https://www.pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/" href="">
	<meta property="og:locale" content="en_US">
	<meta property="og:type" content="article">
	<meta property="og:title" content="Finding the Brightest Spot in an Image using OpenCV">
	<meta property="og:description" content="Detecting the brightest spot in an image is an easy, two step process. In this post, I'll show you how to use Python & OpenCV to detect bright spots in images.">
	<meta property="og:url" content="https://www.pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/">
	<meta property="og:site_name" content="PyImageSearch">
	<meta property="article:published_time" content="2014-09-29T14:00:33+00:00">
	<meta property="article:modified_time" content="2021-04-17T19:20:16+00:00">
	<meta property="og:image" content="https://pyimagesearch.com/wp-content/uploads/2014/08/bright-area-retina-noise.jpg">
	<meta property="og:image:width" content="1000">
	<meta property="og:image:height" content="401">
	<meta name="twitter:label1" content="Written by">
	<meta name="twitter:data1" content="Adrian Rosebrock">
	<meta name="twitter:label2" content="Est. reading time">
	<meta name="twitter:data2" content="9 minutes">
	<script type="text/javascript" async="" data-savepage-src="//tag.getdrip.com/4768429.js"></script><script type="text/javascript" async="" data-savepage-src="https://tw.rightmessage.com/1871593262.js"></script><script type="text/javascript" async="" data-savepage-src="https://www.gstatic.com/recaptcha/releases/85AXn53af-oJBEtL2o2WpAjZ/recaptcha__en.js" crossorigin="anonymous" integrity="sha384-gcMWyJurhs2OxKnLeJqCvLoRV/QghIiqjOme29q6JkyYNVHkVmiLiwnzz6TtRlzd"></script><script type="application/ld+json" class="yoast-schema-graph"></script>
	<!-- / Yoast SEO plugin. -->


<link rel="dns-prefetch" data-savepage-href="//a.omappapi.com" href="">
<link rel="dns-prefetch" data-savepage-href="//www.google.com" href="">
<link rel="dns-prefetch" data-savepage-href="//use.typekit.net" href="">
<link rel="dns-prefetch" data-savepage-href="//929687.smushcdn.com" href="">

<link rel="alternate" type="application/rss+xml" title="PyImageSearch » Feed" data-savepage-href="https://pyimagesearch.com/feed/" href="">
<link rel="alternate" type="application/rss+xml" title="PyImageSearch » Comments Feed" data-savepage-href="https://pyimagesearch.com/comments/feed/" href="">
<link rel="alternate" type="application/rss+xml" title="PyImageSearch » Finding the Brightest Spot in an Image using Python and OpenCV Comments Feed" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/feed/" href="">













<style id="rocket-lazyload-inline-css" type="text/css">
.rll-youtube-player{position:relative;padding-bottom:56.23%;height:0;overflow:hidden;max-width:100%;}.rll-youtube-player iframe{position:absolute;top:0;left:0;width:100%;height:100%;z-index:100;background:0 0}.rll-youtube-player img{bottom:0;display:block;left:0;margin:auto;max-width:100%;width:100%;position:absolute;right:0;top:0;border:none;height:auto;cursor:pointer;-webkit-transition:.4s all;-moz-transition:.4s all;transition:.4s all}.rll-youtube-player img:hover{-webkit-filter:brightness(75%)}.rll-youtube-player .play{height:72px;width:72px;left:50%;top:50%;margin-left:-36px;margin-top:-36px;position:absolute;background:/*savepage-url=https://pyimagesearch.com/wp-content/plugins/wp-rocket/assets/img/youtube.png*/url() no-repeat;cursor:pointer}.wp-has-aspect-ratio .rll-youtube-player{position:absolute;padding-bottom:0;width:100%;height:100%;top:0;bottom:0;left:0;right:0}
</style>






<link rel="https://api.w.org/" data-savepage-href="https://pyimagesearch.com/wp-json/" href=""><link rel="alternate" type="application/json" data-savepage-href="https://pyimagesearch.com/wp-json/wp/v2/posts/1136" href=""><link rel="EditURI" type="application/rsd+xml" title="RSD" data-savepage-href="https://pyimagesearch.com/xmlrpc.php?rsd" href="">
<link rel="wlwmanifest" type="application/wlwmanifest+xml" data-savepage-href="https://pyimagesearch.com/wp-includes/wlwmanifest.xml" href=""> 
<meta name="generator" content="WordPress 5.6.7">
<link rel="shortlink" data-savepage-href="https://pyimagesearch.com/?p=1136" href="">
<link rel="alternate" type="application/json+oembed" data-savepage-href="https://pyimagesearch.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fpyimagesearch.com%2F2014%2F09%2F29%2Ffinding-brightest-spot-image-using-python-opencv%2F" href="">
<link rel="alternate" type="text/xml+oembed" data-savepage-href="https://pyimagesearch.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fpyimagesearch.com%2F2014%2F09%2F29%2Ffinding-brightest-spot-image-using-python-opencv%2F&format=xml" href="">
    
<link rel="pingback" data-savepage-href="https://pyimagesearch.com/xmlrpc.php" href="">
<style type="text/css">
/* <![CDATA[ */
img.latex { vertical-align: middle; border: none; }
/* ]]> */
</style>
		<style type="text/css" id="wp-custom-css">
			.grecaptcha-badge {  
    display: none !important;
}

img.latex {
	margin: 0!important;
	display: inline!important;
}

.entry-content > .aligncenter {
	margin-left: auto;
	margin-right: auto;
} 

.page-template-page_success_stories .success-story-all .success-story-item {
	break-inside: avoid;
	float: none;
}
.site-title a {
    width: 160px;
	height: 50px;align-content}
@media (min-width: 1058px){
.site-title a {
	width: 300px;
  height: 90px;
}}		</style>
		<noscript><style id="rocket-lazyload-nojs-css">.rll-youtube-player, [data-lazy-src]{display:none !important;}</style></noscript><script></script><link rel="prefetch" data-savepage-href="https://pyimagesearch.com/category/tutorials/" href=""><script data-savepage-src="https://pyimagesearch.com/wp-includes/js/jquery/jquery.js"></script><script data-savepage-src="https://pyimagesearch.com/wp-content/cache/min/1/f67da8ef1bb72583a9be2d03590e071d_avlabs_primary_script.js"></script><script data-savepage-src="https://pyimagesearch.com/wp-content/avlabs-cache/js/avlabs-preloader.js?ver=5.6.7"></script><script data-savepage-src="https://pyimagesearch.com/wp-content/themes/pyi/assets/js/stickykit.min.js?ver=1597079258"></script><script data-savepage-src="https://pyimagesearch.com/wp-content/themes/pyi/assets/js/jquery.flexslider.min.js?ver=1597079258"></script><script data-savepage-src="https://pyimagesearch.com/wp-content/themes/pyi/assets/js/global-min.js?ver=1597079258"></script><script data-savepage-src="https://pyimagesearch.com/wp-content/avlabs-cache/js/avlabs-mobile-menu.js?ver=5.6.7"></script><script data-savepage-src="https://pyimagesearch.com/wp-content/plugins/wp-rocket/assets/js/lazyload/16.1/lazyload.min.js"></script><script data-savepage-src="https://fast.wistia.com/embed/medias/kno0cmko2z.jsonp"></script><script data-savepage-src="https://fast.wistia.com/embed/medias/8ggk996ods.jsonp"></script><script data-savepage-src="https://www.google.com/recaptcha/api.js?render=6LcSHsQUAAAAAIzvikURE5e1jZ-YAGgyhpZnfS6o&#038;ver=3.0"></script><script data-savepage-src="https://www.googletagmanager.com/gtag/js?id=UA-46641058-1"></script><script data-savepage-src="https://pyimagesearch.com/wp-includes/js/dist/vendor/wp-polyfill.min.js?ver=7.4.4"></script><script data-savepage-src="https://pyimagesearch.com/wp-includes/js/dist/i18n.min.js?ver=9e36b5da09c96c657b0297fd6f7cb1fd"></script><script data-savepage-src="https://pyimagesearch.com/wp-includes/js/dist/vendor/lodash.min.js?ver=4.17.21"></script><script data-savepage-src="https://pyimagesearch.com/wp-includes/js/dist/url.min.js?ver=1b4bb2b3f526a1db366ca3147ac39562"></script><script data-savepage-src="https://pyimagesearch.com/wp-includes/js/dist/hooks.min.js?ver=d0d9f43e03080e6ace9a3dabbd5f9eee"></script><script data-savepage-src="https://pyimagesearch.com/wp-includes/js/dist/api-fetch.min.js?ver=c207d2d188ba8bf763f7acd50b7fd5a9"></script><script data-savepage-src="https://pyimagesearch.com/wp-content/plugins/enlighter/cache/enlighterjs.min.js?ver=5lGqehphkeVpv3l"></script><script data-savepage-src="https://pyimagesearch.com/wp-content/cache/min/1/7b50bb5cfc84493bf2eaf0eb699d9eb0.js"></script><script data-savepage-src="https://pyimagesearch.com/wp-content/plugins/contact-form-7/includes/js/index.js?ver=5.4"></script><script data-savepage-src="https://pyimagesearch.com/wp-content/plugins/contact-form-7/modules/recaptcha/index.js?ver=5.4"></script><script data-savepage-src="https://pyimagesearch.com/wp-content/themes/genesis/lib/js/skip-links.min.js?ver=3.2.1"></script><script data-savepage-src="https://pyimagesearch.com/wp-content/themes/pyi/assets/js/modal-min.js?ver=1597079258"></script><script data-savepage-src="https://pyimagesearch.com/wp-includes/js/wp-embed.min.js?ver=5.6.7"></script><script data-savepage-src="https://pyimagesearch.com/wp-content/plugins/optinmonster/assets/js/helper.js?ver=2.6.7"></script><script data-savepage-src="https://pyimagesearch.com/wp-content/avlabs-cache/js/avlabs-lazy-load.js?ver=5.6.7"></script><script type="text/javascript" data-savepage-src="https://a.omappapi.com/app/js/api.min.js" async="" data-campaign="ckbsgcjhw0dhp0tgrys5" data-user="18464"></script><script type="text/javascript" data-savepage-src="https://a.omappapi.com/app/js/api.min.js" async="" data-campaign="or0sqbuuxvbrezoeac3e" data-user="18464"></script><script type="text/javascript" data-savepage-src="https://a.omappapi.com/app/js/api.min.js" async="" data-campaign="tortsem7qkvyuxc4cyfi" data-user="18464"></script><script type="text/javascript" data-savepage-src="https://a.omappapi.com/app/js/api.min.js" async="" data-campaign="mdoijtrmex7bpm0rp2hn" data-user="18464"></script><meta class="foundation-mq"><script type="text/javascript" data-savepage-src="https://a.omappapi.com/app/js/api.min.js" async="" id="omapi-script"></script><script data-savepage-src="https://dev.visualwebsiteoptimizer.com/j.php?a=586234&u=https%3A%2F%2Fpyimagesearch.com%2F2014%2F09%2F29%2Ffinding-brightest-spot-image-using-python-opencv%2F&f=1&r=0.6488718983536446" type="text/javascript"></script><style type="text/css">.rm-c,.rm-c a,.rm-c abbr,.rm-c acronym,.rm-c address,.rm-c applet,.rm-c area,.rm-c article,.rm-c aside,.rm-c audio,.rm-c b,.rm-c big,.rm-c blockquote,.rm-c button,.rm-c canvas,.rm-c caption,.rm-c cite,.rm-c code,.rm-c col,.rm-c colgroup,.rm-c datalist,.rm-c dd,.rm-c del,.rm-c dfn,.rm-c div,.rm-c dl,.rm-c dt,.rm-c em,.rm-c fieldset,.rm-c figcaption,.rm-c figure,.rm-c footer,.rm-c form,.rm-c h1,.rm-c h2,.rm-c h3,.rm-c h4,.rm-c h5,.rm-c h6,.rm-c header,.rm-c hr,.rm-c i,.rm-c iframe,.rm-c img,.rm-c input,.rm-c ins,.rm-c kbd,.rm-c label,.rm-c legend,.rm-c li,.rm-c main,.rm-c map,.rm-c mark,.rm-c menu,.rm-c meta,.rm-c nav,.rm-c object,.rm-c ol,.rm-c optgroup,.rm-c option,.rm-c output,.rm-c p,.rm-c pre,.rm-c progress,.rm-c q,.rm-c samp,.rm-c section,.rm-c select,.rm-c small,.rm-c span,.rm-c strike,.rm-c strong,.rm-c sub,.rm-c summary,.rm-c sup,.rm-c svg,.rm-c table,.rm-c tbody,.rm-c td,.rm-c textarea,.rm-c tfoot,.rm-c th,.rm-c thead,.rm-c time,.rm-c tr,.rm-c tt,.rm-c ul,.rm-c var,.rm-c video{background-attachment:scroll!important;background-color:transparent!important;background-image:none!important;background-position:0 0!important;background-repeat:repeat!important;border-color:#000!important;border:medium none currentColor!important;bottom:auto!important;clear:none!important;clip:auto!important;color:inherit!important;counter-increment:none!important;counter-reset:none!important;cursor:auto!important;direction:inherit!important;display:inline!important;float:none!important;font-family:inherit!important;font-size:inherit!important;font-style:inherit!important;font-variant:normal!important;font-weight:inherit!important;height:auto!important;left:auto!important;letter-spacing:normal!important;line-height:inherit!important;list-style-type:inherit!important;list-style-position:outside!important;list-style-image:none!important;margin:0!important;max-height:none!important;max-width:none!important;min-height:0!important;min-width:0!important;opacity:1;outline:medium none invert!important;overflow:visible!important;padding:0!important;position:static!important;quotes:"" ""!important;right:auto!important;table-layout:auto!important;text-align:inherit!important;text-decoration:inherit!important;text-indent:0!important;text-transform:none!important;top:auto!important;unicode-bidi:normal!important;vertical-align:baseline!important;visibility:inherit!important;white-space:normal!important;width:auto!important;word-spacing:normal!important;z-index:auto!important;-webkit-background-origin:padding-box!important;background-origin:padding-box!important;-webkit-background-clip:border-box!important;background-clip:border-box!important;-webkit-background-size:auto!important;-moz-background-size:auto!important;background-size:auto!important;-webkit-border-image:none!important;-moz-border-image:none!important;-o-border-image:none!important;border-image:none!important;-webkit-border-radius:0!important;-moz-border-radius:0!important;border-radius:0!important;-webkit-box-shadow:none!important;box-shadow:none!important;-webkit-box-sizing:content-box!important;-moz-box-sizing:content-box!important;box-sizing:content-box!important;-webkit-column-count:auto!important;-moz-column-count:auto!important;column-count:auto!important;-webkit-column-gap:normal!important;-moz-column-gap:normal!important;column-gap:normal!important;-webkit-column-rule:medium none #000!important;-moz-column-rule:medium none #000!important;column-rule:medium none #000!important;-webkit-column-span:1!important;-moz-column-span:1!important;column-span:1!important;-webkit-column-width:auto!important;-moz-column-width:auto!important;column-width:auto!important;font-feature-settings:normal!important;overflow-x:visible!important;overflow-y:visible!important;-webkit-hyphens:manual!important;-moz-hyphens:manual!important;hyphens:manual!important;-webkit-perspective:none!important;-moz-perspective:none!important;-ms-perspective:none!important;-o-perspective:none!important;perspective:none!important;-webkit-perspective-origin:50% 50%!important;-moz-perspective-origin:50% 50%!important;-ms-perspective-origin:50% 50%!important;-o-perspective-origin:50% 50%!important;perspective-origin:50% 50%!important;-webkit-backface-visibility:visible!important;-moz-backface-visibility:visible!important;-ms-backface-visibility:visible!important;-o-backface-visibility:visible!important;backface-visibility:visible!important;text-shadow:none!important;-webkit-transition:all 0s ease 0s!important;transition:all 0s ease 0s!important;-webkit-transform:none!important;-moz-transform:none!important;-ms-transform:none!important;-o-transform:none!important;transform:none!important;-webkit-transform-origin:50% 50%!important;-moz-transform-origin:50% 50%!important;-ms-transform-origin:50% 50%!important;-o-transform-origin:50% 50%!important;transform-origin:50% 50%!important;-webkit-transform-style:flat!important;-moz-transform-style:flat!important;-ms-transform-style:flat!important;-o-transform-style:flat!important;transform-style:flat!important;word-break:normal!important}.rm-c,.rm-c address,.rm-c article,.rm-c audio,.rm-c blockquote,.rm-c caption,.rm-c colgroup,.rm-c dd,.rm-c dialog,.rm-c div,.rm-c dl,.rm-c dt,.rm-c fieldset,.rm-c figure,.rm-c footer,.rm-c form,.rm-c h1,.rm-c h2,.rm-c h3,.rm-c h4,.rm-c h5,.rm-c h6,.rm-c header,.rm-c hgroup,.rm-c hr,.rm-c main,.rm-c menu,.rm-c nav,.rm-c ol,.rm-c option,.rm-c p,.rm-c pre,.rm-c progress,.rm-c section,.rm-c summary,.rm-c ul,.rm-c video{display:block!important}.rm-c h1,.rm-c h2,.rm-c h3,.rm-c h4,.rm-c h5,.rm-c h6{font-weight:700!important}.rm-c h1{font-size:2em!important;padding:.67em 0!important}.rm-c h2{font-size:1.5em!important}.rm-c h2,.rm-c h3{padding:.83em 0!important}.rm-c h3{font-size:1.17em!important}.rm-c h4{font-size:1em!important}.rm-c h5{font-size:.83em!important}.rm-c p{margin:1em 0!important}.rm-c table{display:table!important}.rm-c thead{display:table-header-group!important}.rm-c tbody{display:table-row-group!important}.rm-c tfoot{display:table-footer-group!important}.rm-c tr{display:table-row!important}.rm-c td,.rm-c th{display:table-cell!important;padding:2px!important}.rm-c ol,.rm-c ul{margin:1em 0!important}.rm-c ol li,.rm-c ol ol li,.rm-c ol ol ol li,.rm-c ol ol ul li,.rm-c ol ul ul li,.rm-c ul li,.rm-c ul ol ol li,.rm-c ul ul li,.rm-c ul ul ol li,.rm-c ul ul ul li{list-style-position:inside!important;margin-top:.08em!important}.rm-c ol ol,.rm-c ol ol ol,.rm-c ol ol ul,.rm-c ol ul,.rm-c ol ul ul,.rm-c ul ol,.rm-c ul ol ol,.rm-c ul ul,.rm-c ul ul ol,.rm-c ul ul ul{padding-left:40px!important;margin:0!important}.rm-c nav ol,.rm-c nav ul{list-style-type:none!important}.rm-c menu,.rm-c ul{list-style-type:disc!important}.rm-c ol{list-style-type:decimal!important}.rm-c menu menu,.rm-c menu ul,.rm-c ol menu,.rm-c ol ul,.rm-c ul menu,.rm-c ul ul{list-style-type:circle!important}.rm-c menu menu menu,.rm-c menu menu ul,.rm-c menu ol menu,.rm-c menu ol ul,.rm-c menu ul menu,.rm-c menu ul ul,.rm-c ol menu menu,.rm-c ol menu ul,.rm-c ol ol menu,.rm-c ol ol ul,.rm-c ol ul menu,.rm-c ol ul ul,.rm-c ul menu menu,.rm-c ul menu ul,.rm-c ul ol menu,.rm-c ul ol ul,.rm-c ul ul menu,.rm-c ul ul ul{list-style-type:square!important}.rm-c li{display:list-item!important;min-height:auto!important;min-width:auto!important;padding-left:20px!important}.rm-c strong{font-weight:700!important}.rm-c em{font-style:italic!important}.rm-c code,.rm-c kbd,.rm-c pre,.rm-c samp{font-family:monospace!important}.rm-c a,.rm-c a *,.rm-c button,.rm-c button *,.rm-c input[type=button],.rm-c input[type=checkbox],.rm-c input[type=radio],.rm-c input[type=submit],.rm-c select{cursor:pointer!important}.rm-c button,.rm-c input[type=submit]{font-family:inherit!important;outline:initial!important}.rm-c input[type=hidden]{display:none!important}.rm-c textarea{-webkit-appearance:textarea!important;background:#fff!important;padding:2px!important;margin-left:4px!important;word-wrap:break-word!important;white-space:pre-wrap!important;font-size:11px!important;font-family:inherit!important;line-height:13px!important;resize:both!important}.rm-c input,.rm-c select,.rm-c textarea{border:1px solid #ccc!important}.rm-c select{font-size:11px!important;font-family:inherit!important;display:inline-block}.rm-c input:focus,.rm-c textarea:focus{outline:5px auto -webkit-focus-ring-color!important;outline:initial!important}.rm-c input[type=email],.rm-c input[type=text]{background:#fff!important;padding:1px!important;font-family:inherit!important;font-size:small!important}.rm-c input[type=checkbox],.rm-c input[type=radio]{border:1px solid #2b2b2b!important;border-radius:4px!important;outline:initial!important}.rm-c input[type=radio]{margin:2px 2px 3px!important}.rm-c abbr[title],.rm-c acronym[title],.rm-c dfn[title]{cursor:help!important;border-bottom-width:1px!important;border-bottom-style:dotted!important}.rm-c ins{background-color:#ff9!important;color:#000!important}.rm-c del{text-decoration:line-through!important}.rm-c blockquote,.rm-c q{quotes:none!important}.rm-c blockquote:after,.rm-c blockquote:before,.rm-c li:after,.rm-c li:before,.rm-c q:after,.rm-c q:before{content:""!important}.rm-c input,.rm-c select{vertical-align:middle!important}.rm-c table{border-collapse:collapse!important;border-spacing:0!important}.rm-c hr{display:block!important;height:1px!important;border:0!important;border-top:1px solid #ccc!important;margin:1em 0!important}.rm-c [dir=rtl]{direction:rtl!important}.rm-c mark{background-color:#ff9!important;color:#000!important;font-style:italic!important;font-weight:700!important}.rm-c menu{padding-left:40px!important;padding-top:8px!important}.rm-c [hidden],.rm-c template{display:none!important}.rm-c abbr[title]{border-bottom:1px dotted!important}.rm-c sub,.rm-c sup{font-size:75%!important;line-height:0!important;position:relative!important;vertical-align:baseline!important}.rm-c sup{top:-.5em!important}.rm-c sub{bottom:-.25em!important}.rm-c img{border:0!important}.rm-c figure{margin:0!important}.rm-c textarea{overflow:auto!important;vertical-align:top!important}.rm-c{font-size:medium!important;line-height:1!important;text-align:left!important;text-align:start!important;color:#000!important;font-style:normal!important;font-weight:400!important;text-decoration:none!important;list-style-type:disc!important}.rm-c pre{white-space:pre!important}</style><style type="text/css">.rm-animated{animation-duration:1s;animation-fill-mode:both}.rm-animated.infinite{animation-iteration-count:infinite}.rm-animated.delay-1s{animation-delay:1s}.rm-animated.delay-2s{animation-delay:2s}.rm-animated.delay-3s{animation-delay:3s}.rm-animated.delay-4s{animation-delay:4s}.rm-animated.delay-5s{animation-delay:5s}.rm-animated.fast{animation-duration:.8s}.rm-animated.faster{animation-duration:.5s}.rm-animated.slow{animation-duration:2s}.rm-animated.slower{animation-duration:3s}@media (prefers-reduced-motion),(print){.rm-animated{animation:unset!important;transition:none!important}}@keyframes rm-tada{0%{transform:scaleX(1)}2%,4%{transform:scale3d(.9,.9,.9) rotate(-3deg)}6%,10%,14%,18%{transform:scale3d(1.1,1.1,1.1) rotate(3deg)}8%,12%,16%{transform:scale3d(1.1,1.1,1.1) rotate(-3deg)}20%{transform:scaleX(1)}}.rm-tada{animation-duration:5s;animation-name:rm-tada}</style><style>.rmtempinvisible { visibility: visible !important; }</style><link rel="prefetch" data-savepage-href="https://pyimagesearch.com/2014/01/20/basic-image-manipulations-in-python-and-opencv-resizing-scaling-rotating-and-cropping/" href="">
<style id="savepage-cssvariables">
  :root {
    --savepage-url-13: url(data:image/png;base64,);
    --savepage-url-14: url(data:image/png;base64,);
    --savepage-url-15: url(data:image/png;base64,);
    --savepage-url-16: url(data:image/png;base64,);
    --savepage-url-17: url(data:image/png;base64,);
    --savepage-url-18: url(data:image/png;base64,);
    --savepage-url-19: url(data:image/png;base64,);
    --savepage-url-20: url(data:image/png;base64,);
    --savepage-url-21: url(data:image/png;base64,);
    --savepage-url-22: url(data:image/png;base64,);
    --savepage-url-23: url(data:image/png;base64,);
    --savepage-url-24: url(data:image/png;base64,);
    --savepage-url-25: url(data:image/png;base64,);
    --savepage-url-26: url(data:image/png;base64,);
    --savepage-url-27: url(data:image/png;base64,);
    --savepage-url-28: url(data:image/png;base64,);
    --savepage-url-29: url(data:image/png;base64,);
    --savepage-url-30: url(data:image/png;base64,);
    --savepage-url-31: url(data:image/png;base64,);
    --savepage-url-78: url(data:image/png;base64,);
  }
</style>
<script id="savepage-shadowloader" type="application/javascript">
  "use strict";
  window.addEventListener("DOMContentLoaded",
  function(event) {
    savepage_ShadowLoader(99999);
  },false);
  function savepage_ShadowLoader(c){createShadowDOMs(0,document.documentElement);function createShadowDOMs(a,b){var i;if(b.localName=="iframe"||b.localName=="frame"){if(a<c){try{if(b.contentDocument.documentElement!=null){createShadowDOMs(a+1,b.contentDocument.documentElement)}}catch(e){}}}else{if(b.children.length>=1&&b.children[0].localName=="template"&&b.children[0].hasAttribute("data-savepage-shadowroot")){b.attachShadow({mode:"open"}).appendChild(b.children[0].content);b.removeChild(b.children[0]);for(i=0;i<b.shadowRoot.children.length;i++)if(b.shadowRoot.children[i]!=null)createShadowDOMs(a,b.shadowRoot.children[i])}for(i=0;i<b.children.length;i++)if(b.children[i]!=null)createShadowDOMs(a,b.children[i])}}}
</script>
<script id="savepage-pageinfo-bar-insert" type="application/javascript">
  "use strict";
  window.addEventListener('load',function(event) {
    var parser = new DOMParser();
    var pageinfodoc = parser.parseFromString('<html> <style id="savepage-pageinfo-bar-style" type="text/css">#savepage-pageinfo-bar-content,#savepage-pageinfo-bar-content *{all:initial!important}#savepage-pageinfo-bar-content,#savepage-pageinfo-bar-content *{font-family:"Segoe UI","Helvetica Neue",Ubuntu,Arial!important;font-size:12px!important;color:black!important;cursor:default!important;-moz-user-select:none!important;-webkit-user-select:none!important}#savepage-pageinfo-bar-content{display:flex!important;position:fixed!important;left:0!important;top:0!important;width:100%!important;height:25px!important;border-bottom:1px solid #E0E0E0!important;background:#F8F8F8!important;overflow:hidden!important;z-index:2147483645!important}#savepage-pageinfo-bar-spacer-1{flex:0 1 auto!important;background:#F8F8F8!important}#savepage-pageinfo-bar-link{flex:0 1 auto!important;padding:4px 0!important;background:#F8F8F8!important;white-space:nowrap!important;overflow:hidden!important;text-overflow:ellipsis!important}#savepage-pageinfo-bar-link:hover{text-decoration:underline!important}#savepage-pageinfo-bar-spacer-2{flex:1 1 auto!important;background:#F8F8F8!important}#savepage-pageinfo-bar-datetime{flex:0 1000000 auto!important;min-width:0!important;padding:4px 0!important;background:#F8F8F8!important;white-space:nowrap!important;overflow:hidden!important;text-overflow:ellipsis!important}#savepage-pageinfo-bar-spacer-3{flex:0 1 auto!important;background:#F8F8F8!important}#savepage-pageinfo-bar-button{flex:0 0 25px!important;background-color:#F8F8F8!important;background-image:url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAkAAAAJCAYAAADgkQYQAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAA8SURBVChTYwCC/0DsAGJgASBxkDycga4QQxxdAEMBDCBLYFUAAyQpIGgVCGAoxBCAAhRxrEZDAVCc4T8AbzkX8F/+uCwAAAAASUVORK5CYII=)!important;background-repeat:no-repeat!important;background-position:center center!important}#savepage-pageinfo-bar-button:hover{background-color:#E8E8E8!important}#savepage-pageinfo-bar-button:active{background-color:#D8D8D8!important}</style> <div id="savepage-pageinfo-bar-content"> <div id="savepage-pageinfo-bar-spacer-1">&nbsp;&nbsp;&nbsp;</div> <a id="savepage-pageinfo-bar-link" href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/" target="_blank">https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/</a> <div id="savepage-pageinfo-bar-spacer-2">&nbsp;&nbsp;&nbsp;</div> <div id="savepage-pageinfo-bar-datetime">12 Mar 2022&nbsp;&nbsp;&nbsp;15:54:58</div> <div id="savepage-pageinfo-bar-spacer-3">&nbsp;&nbsp;&nbsp;</div> <div id="savepage-pageinfo-bar-button"></div> </div> </html>','text/html');
    var container = document.createElement('div');
    container.setAttribute('id','savepage-pageinfo-bar-container');
    document.documentElement.appendChild(container);
    container.appendChild(pageinfodoc.getElementById('savepage-pageinfo-bar-style'));
    container.appendChild(pageinfodoc.getElementById('savepage-pageinfo-bar-content'));
    document.getElementById('savepage-pageinfo-bar-button').addEventListener('click',function(event) {
      var container = document.getElementById('savepage-pageinfo-bar-container');
      document.documentElement.removeChild(container);
    },false);
  },false);
</script>
<meta name="savepage-url" content="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/">
<meta name="savepage-title" content="Finding the Brightest Spot in an Image using OpenCV">
<meta name="savepage-pubdate" content="Mon Sep 29 2014 14:00:33 GMT+0000">
<meta name="savepage-from" content="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/">
<meta name="savepage-date" content="Sat Mar 12 2022 15:54:58 GMT-0600 (Central Standard Time)">
<meta name="savepage-state" content="Standard Items; Retain cross-origin frames; Merge CSS images; Remove unsaved URLs; Load lazy images in existing content; Max frame depth = 99999; Max resource size = 50MB; Max resource time = 10s;">
<meta name="savepage-version" content="25.9">
<meta name="savepage-comments" content="">
  </head>
<body class="post-template-default single single-post postid-1136 single-format-standard wp-embed-responsive header-full-width content-sidebar genesis-breadcrumbs-hidden genesis-footer-widgets-visible"><div class="site-container"><ul class="genesis-skip-link"><li><a href="#genesis-nav-primary" class="screen-reader-shortcut"> Skip to primary navigation</a></li><li><a href="#genesis-content" class="screen-reader-shortcut"> Skip to main content</a></li><li><a href="#genesis-sidebar-primary" class="screen-reader-shortcut"> Skip to primary sidebar</a></li><li><a href="#genesis-footer-widgets" class="screen-reader-shortcut"> Skip to footer</a></li></ul><header class="site-header"><div class="wrap"><div class="title-area"><p class="site-title"><a href="https://pyimagesearch.com/">PyImageSearch</a></p><p class="site-description">You can master Computer Vision, Deep Learning, and OpenCV - PyImageSearch</p></div><nav class="nav-secondary" aria-label="Secondary"><div class="wrap"><ul id="menu-header-secondary" class="menu genesis-nav-menu menu-secondary"><li id="menu-item-29226" class="menu-item"><a href="https://pyimagesearch.com/consulting-2/"><span>Consulting</span></a></li>
<li id="menu-item-15978" class="menu-item"><a href="https://pyimagesearch.com/opencv-tutorials-resources-guides/"><span>OpenCV Install Guides</span></a></li>
<li id="menu-item-12816" class="menu-item"><a href="https://pyimagesearch.com/about/"><span>About</span></a></li>
<li id="menu-item-12817" class="menu-item"><a href="https://pyimagesearch.com/faqs/"><span>FAQ</span></a></li>
<li id="menu-item-12818" class="menu-item"><a href="https://pyimagesearch.com/contact/"><span>Contact</span></a></li>
</ul></div></nav><div class="main-nav-wrap"><nav class="nav-primary" aria-label="Main" id="genesis-nav-primary"><ul id="menu-main-menu" class="menu genesis-nav-menu menu-primary"><li id="menu-item-11459" class="menu-item"><a href="https://pyimagesearch.com/start-here/"><span>Get Started</span></a></li>
<li id="menu-item-10696" class="is-topics menu-item menu-item-has-children"><a data-savepage-href="/topics/" href="https://pyimagesearch.com/topics/"><span>Topics</span></a><span class="submenu-expand" tabindex="-1"><svg class="svg-icon" width="16" height="16" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path d="M151.5 347.8L3.5 201c-4.7-4.7-4.7-12.3 0-17l19.8-19.8c4.7-4.7 12.3-4.7 17 0L160 282.7l119.7-118.5c4.7-4.7 12.3-4.7 17 0l19.8 19.8c4.7 4.7 4.7 12.3 0 17l-148 146.8c-4.7 4.7-12.3 4.7-17 0z"></path></svg></span>
<ul class="sub-menu">
	<li id="menu-item-10698" class="has-icon has-icon--deep-learning menu-item"><a href="https://pyimagesearch.com/category/deep-learning/"><span>Deep Learning</span></a></li>
	<li id="menu-item-10699" class="has-icon has-icon--dlib menu-item"><a href="https://pyimagesearch.com/category/dlib/"><span>Dlib Library</span></a></li>
	<li id="menu-item-10700" class="has-icon has-icon--iot menu-item"><a href="https://pyimagesearch.com/category/embedded/"><span>Embedded/IoT and Computer Vision</span></a></li>
	<li id="menu-item-10701" class="has-icon has-icon--face menu-item"><a href="https://pyimagesearch.com/category/faces/"><span>Face Applications</span></a></li>
	<li id="menu-item-10702" class="has-icon has-icon--image menu-item current-post-ancestor current-menu-parent current-post-parent"><a href="https://pyimagesearch.com/category/image-processing/"><span>Image Processing</span></a></li>
	<li id="menu-item-10703" class="has-icon has-icon--interviews menu-item"><a href="https://pyimagesearch.com/category/interviews/"><span>Interviews</span></a></li>
	<li id="menu-item-10704" class="has-icon has-icon--keras menu-item"><a href="https://pyimagesearch.com/category/keras-and-tensorflow/"><span>Keras and TensorFlow</span></a></li>
	<li id="menu-item-10705" class="has-icon has-icon--ml menu-item"><a href="https://pyimagesearch.com/category/machine-learning/"><span>Machine Learning and Computer Vision</span></a></li>
	<li id="menu-item-10706" class="has-icon has-icon--medical menu-item"><a href="https://pyimagesearch.com/category/medical/"><span>Medical Computer Vision</span></a></li>
	<li id="menu-item-10707" class="has-icon has-icon--ocr menu-item"><a href="https://pyimagesearch.com/category/optical-character-recognition-ocr/"><span>Optical Character Recognition (OCR)</span></a></li>
	<li id="menu-item-10708" class="has-icon has-icon--object-detection menu-item"><a href="https://pyimagesearch.com/category/object-detection/"><span>Object Detection</span></a></li>
	<li id="menu-item-10709" class="has-icon has-icon--object-tracking menu-item"><a href="https://pyimagesearch.com/category/object-tracking/"><span>Object Tracking</span></a></li>
	<li id="menu-item-10711" class="has-icon has-icon--opencv menu-item"><a href="https://pyimagesearch.com/category/opencv/"><span>OpenCV Tutorials</span></a></li>
	<li id="menu-item-10710" class="has-icon has-icon--pi menu-item"><a href="https://pyimagesearch.com/category/raspberry-pi/"><span>Raspberry Pi</span></a></li>
</ul>
</li>
<li id="menu-item-12831" class="menu-item"><a href="https://pyimagesearch.com/books-and-courses/"><span>Books and Courses</span></a></li>
<li id="menu-item-15979" class="menu-item"><a href="https://pyimagesearch.com/pyimagesearch-reviews-testimonials/"><span>Student Success Stories</span></a></li>
<li id="menu-item-12845" class="menu-item current_page_parent"><a href="https://pyimagesearch.com/blog/"><span>Blog</span></a></li>
<li id="menu-item-29296" class="mobile-only menu-item"><a href="https://pyimagesearch.com/consulting-2/"><span>Consulting</span></a></li>
<li id="menu-item-2619" class="mobile-only menu-item"><a href="https://pyimagesearch.com/about/"><span>About</span></a></li>
<li id="menu-item-10258" class="mobile-only menu-item"><a href="https://pyimagesearch.com/faqs/"><span>FAQ</span></a></li>
<li id="menu-item-6744" class="mobile-only menu-item"><a href="https://pyimagesearch.com/contact/"><span>Contact</span></a></li>
</ul></nav><div class="header-search"><button class="mobile-search-toggle"><svg class="svg-icon search-icon" width="28" height="28" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M508.5 468.9L387.1 347.5c-2.3-2.3-5.3-3.5-8.5-3.5h-13.2c31.5-36.5 50.6-84 50.6-136C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c52 0 99.5-19.1 136-50.6v13.2c0 3.2 1.3 6.2 3.5 8.5l121.4 121.4c4.7 4.7 12.3 4.7 17 0l22.6-22.6c4.7-4.7 4.7-12.3 0-17zM208 368c-88.4 0-160-71.6-160-160S119.6 48 208 48s160 71.6 160 160-71.6 160-160 160z"></path></svg><svg class="svg-icon search-close" width="28" height="28" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path d="M207.6 256l107.72-107.72c6.23-6.23 6.23-16.34 0-22.58l-25.03-25.03c-6.23-6.23-16.34-6.23-22.58 0L160 208.4 52.28 100.68c-6.23-6.23-16.34-6.23-22.58 0L4.68 125.7c-6.23 6.23-6.23 16.34 0 22.58L112.4 256 4.68 363.72c-6.23 6.23-6.23 16.34 0 22.58l25.03 25.03c6.23 6.23 16.34 6.23 22.58 0L160 303.6l107.72 107.72c6.23 6.23 16.34 6.23 22.58 0l25.03-25.03c6.23-6.23 6.23-16.34 0-22.58L207.6 256z"></path></svg><span class="screen-reader-text">Search</span></button>
<form role="search" method="get" class="search-form" action="https://pyimagesearch.com/">
	<label>
		<span class="screen-reader-text">Search...</span>
		<input type="search" class="search-field" placeholder="Search articles..." value="" name="s" title="Search for">
	</label>
	<button type="submit" class="search-submit"><svg class="svg-icon search" width="20" height="20" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M508.5 468.9L387.1 347.5c-2.3-2.3-5.3-3.5-8.5-3.5h-13.2c31.5-36.5 50.6-84 50.6-136C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c52 0 99.5-19.1 136-50.6v13.2c0 3.2 1.3 6.2 3.5 8.5l121.4 121.4c4.7 4.7 12.3 4.7 17 0l22.6-22.6c4.7-4.7 4.7-12.3 0-17zM208 368c-88.4 0-160-71.6-160-160S119.6 48 208 48s160 71.6 160 160-71.6 160-160 160z"></path></svg><span class="screen-reader-text">Submit</span></button>
</form>
</div><nav class="nav-mobile"><button class="mobile-menu-toggle"><span class="mobile-menu-open"><svg class="svg-icon menu-open" width="13" height="13" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg>Menu</span><span class="mobile-menu-close"><svg class="svg-icon menu-close" width="13" height="13" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path d="M207.6 256l107.72-107.72c6.23-6.23 6.23-16.34 0-22.58l-25.03-25.03c-6.23-6.23-16.34-6.23-22.58 0L160 208.4 52.28 100.68c-6.23-6.23-16.34-6.23-22.58 0L4.68 125.7c-6.23 6.23-6.23 16.34 0 22.58L112.4 256 4.68 363.72c-6.23 6.23-6.23 16.34 0 22.58l25.03 25.03c6.23 6.23 16.34 6.23 22.58 0L160 303.6l107.72 107.72c6.23 6.23 16.34 6.23 22.58 0l25.03-25.03c6.23-6.23 6.23-16.34 0-22.58L207.6 256z"></path></svg>Close</span><span class="screen-reader-text">Menu</span></button></nav></div></div></header><div class="pyi-page-hero"><div class="wrap"><p class="entry-meta"><span class="entry-categories"><a href="https://pyimagesearch.com/category/image-processing/" rel="category tag">Image Processing</a> <a href="https://pyimagesearch.com/category/tutorials/" rel="category tag">Tutorials</a></span></p><header class="entry-header"><h1 class="entry-title">Finding the Brightest Spot in an Image using Python and OpenCV</h1>
</header><p class="entry-meta">by <span class="entry-author"><a href="https://pyimagesearch.com/author/adrian/" class="entry-author-link" rel="author"><span class="entry-author-name">Adrian Rosebrock</span></a></span> on <time class="entry-time">September 29, 2014</time></p><div class="pyi-hero-left"></div><div class="pyi-hero-right"></div></div></div><div class="site-inner"><div class="wrap"><div class="content-sidebar-wrap"><main class="content" id="genesis-content"><article class="post-1136 post type-post status-publish format-standard has-post-thumbnail category-image-processing category-tutorials tag-brightest-pixel tag-brightest-spot tag-cv2-minmaxloc tag-darkest-pixel tag-image-processing-2 entry"><div class="entry-content">
<div id="pyis-cta-modal-sticky-top-anchor"></div>

<div id="pyis-cta-modal-sticky-bar" data-sticky-container="" class="sticky-container" style="height: 78px;">

	<div class="sticky is-at-top is-stuck" data-sticky="wdei93-sticky" data-top-anchor="pyis-cta-modal-sticky-top-anchor:top" data-btm-anchor="pyis-cta-modal-sticky-bottom-anchor:bottom" data-margin-top="0" data-sticky-on="small" data-resize="ugl6yf-sticky" data-mutate="ugl6yf-sticky" style="max-width: 730px; margin-top: 0em; bottom: auto; top: 0px;" data-events="mutate">

		<div class="grid-container">
			<div class="grid-x grid-margin-x">
				<div class="cell text-center">
		
					<a href="#download-the-code" class="pyis-cta-modal-open-modal">
						
						Click here to download the source code to this post						
					</a>

				</div>
			</div>
		</div>
		
	</div>

</div><p><a href="https://pyimagesearch.com/wp-content/uploads/2014/08/bright-area-retina-noise.jpg"><img class="aligncenter wp-image-1137 lazyloaded" data-savepage-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina-noise.jpg?size=600x241&lossy=1&strip=1&webp=1" src="" alt="" width="600" height="241" data-ll-status="loaded"><noscript><img class="aligncenter wp-image-1137" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina-noise.jpg?lossy=1&strip=1&webp=1" alt="" width="600" height="241" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina-noise.jpg?lossy=1&strip=1&webp=1 1000w,https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina-noise.jpg?size=126x51&lossy=1&strip=1&webp=1 126w,https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina-noise.jpg?size=252x101&lossy=1&strip=1&webp=1 252w,https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina-noise.jpg?size=378x152&lossy=1&strip=1&webp=1 378w,https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina-noise.jpg?size=504x202&lossy=1&strip=1&webp=1 504w,https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina-noise.jpg?size=630x253&lossy=1&strip=1&webp=1 630w" sizes="(max-width: 1000px) 100vw, 1000px"></noscript></a></p>
<p>Originally I had intended on doing a followup post on my <a href="https://pyimagesearch.com/2014/09/22/getting-started-deep-learning-python/" target="_blank" rel="noopener noreferrer">Getting Started with Deep Learning Guide</a>, but due to some unfortunate personal events, I wasn’t able to complete the blog post. But don’t worry…I still have a really great tutorial for you today!</p>
<hr>
<p>Bad tutorials are worse than warm beer.</p>
<p>You want to know why?</p>
<p>Because you can always chug a warm beer down in a few seconds…</p>
<p>But you can spend <strong><em>hours</em></strong> going down the wrong path when reading a misguiding tutorial.</p>
<p>And that’s my inspiration for this post — I really hate all the blog posts I’ve seen that detail how to find the brightest spot of an image using OpenCV.</p>
<p>You see, they are leaving out a <em>single line of code</em> that is absolutely crucial to being more robust to noise.</p>
<p>Now, if you’re like me, that doesn’t sit well.</p>
<p>So sit back. Relax. And know that you’re about to read a good tutorial. You won’t spend hours wasting your time here.</p>
<p>In this blog post I’ll show you how to find the brightest spot in an image using Python and OpenCV…and I’ll show you the single line of pre-processing code you’ll need to improve your results.</p>
<div id="pyi-source-code-block" class="source-code-wrap"><div class="gpd-source-code">
    <div class="gpd-source-code-content">
        <img data-savepage-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/source-code-icon.png?lossy=1&strip=1&webp=1" src="" alt="" class="lazyloaded" data-ll-status="loaded"><noscript><img src="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/source-code-icon.png?lossy=1&strip=1&webp=1" alt=""></noscript>
        <h4>Looking for the source code to this post?</h4>
                    <a href="#download-the-code" class="pyis-cta-modal-open-modal">Jump Right To The Downloads Section <svg class="svg-icon arrow-right" width="12" height="12" aria-hidden="true" role="img" focusable="false" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.8125 0.1875C6.875 0.125 6.96875 0.09375 7.09375 0.09375C7.1875 0.09375 7.28125 0.125 7.34375 0.1875L13.875 6.75C13.9375 6.8125 14 6.90625 14 7C14 7.125 13.9375 7.1875 13.875 7.25L7.34375 13.8125C7.28125 13.875 7.1875 13.9062 7.09375 13.9062C6.96875 13.9062 6.875 13.875 6.8125 13.8125L6.1875 13.1875C6.125 13.125 6.09375 13.0625 6.09375 12.9375C6.09375 12.8438 6.125 12.75 6.1875 12.6562L11.0312 7.8125H0.375C0.25 7.8125 0.15625 7.78125 0.09375 7.71875C0.03125 7.65625 0 7.5625 0 7.4375V6.5625C0 6.46875 0.03125 6.375 0.09375 6.3125C0.15625 6.25 0.25 6.1875 0.375 6.1875H11.0312L6.1875 1.34375C6.125 1.28125 6.09375 1.1875 6.09375 1.0625C6.09375 0.96875 6.125 0.875 6.1875 0.8125L6.8125 0.1875Z" fill="#169FE6"></path></svg></a>
            </div>
</div>
</div>
<p><strong>OpenCV and Python versions:</strong><br>This example will run on<strong> Python 2.7/Python 3.4+</strong> and <strong>OpenCV 2.4.X/OpenCV 3.0+</strong>.</p>
<h1>You Need More than <code>cv2.minMaxLoc</code></h1>
<p>A few weeks ago a PyImageSearch reader wrote in and asked about the best way to find the brightest spot in the image.</p>
<p>You see, they were working with retinal images (see the top of this post for an example). These images are normally orange or yellowish in color, circular, and contain important physical structures of the eye, including the optic nerve and the macula.</p>
<p>This reader wanted to know the best way to find the optic nerve center, which is normally the brightest spot of the retinal image.</p>
<p>To find the brightest spot of the image using Python and OpenCV, you would utilize the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.</span><span class="enlighter-m3">minMaxLoc</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">cv2.minMaxLoc</code>  function.</p>
<p>However, the term “spot” here is a little misleading.</p>
<p>The “brightest spot” of the image according to <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.</span><span class="enlighter-m3">minMaxLoc</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">cv2.minMaxLoc</code>  actually isn’t a region — <em>it’s simply the brightest single pixel in the <strong>entire</strong> image.</em></p>
<p>This means that the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.</span><span class="enlighter-m3">minMaxLoc</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">cv2.minMaxLoc</code>  function is extremely susceptible to noise if you don’t take the necessary pre-cautionary steps. A single bright pixel in an area where there wouldn’t normally be a bright pixel (in this case, an area other than the optic nerve center) can dramatically throw off your results.</p>
<p>Instead, you are better off examining <em>regions</em> of the image, rather than a single pixel. When you examine regions you let the average balance everything out — and you’re less susceptible to noise.</p>
<p>So how do you mimic this “region” effect without explicitly examining each and every region of the image?</p>
<p>I’ll show you.</p>
<p>The rest of this blog post is dedicated to showing you how to find the brightest spot of an image using Python and OpenCV</p>
<h1>Finding the Brightest Spot in an Image using Python and OpenCV</h1>
<p>Let’s go ahead and get started.</p>
<p>Open up your favorite editor, create a new file named <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">bright.</span><span class="enlighter-m3">py</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">bright.py</code> , and let’s get started.</p>


<div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Finding the Brightest Spot in an Image using Python and OpenCV</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style=""><div class=""><div><span class="enlighter-c0"># import the necessary packages</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k0">import</span><span class="enlighter-text"> numpy </span><span class="enlighter-k0">as</span><span class="enlighter-text"> np</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k0">import</span><span class="enlighter-text"> argparse</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k0">import</span><span class="enlighter-text"> cv2</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"></span></div></div><div class=""><div><span class="enlighter-c0"># construct the argument parse and parse the arguments</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">ap = argparse.</span><span class="enlighter-m1">ArgumentParser</span><span class="enlighter-g1">()</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">ap.</span><span class="enlighter-m1">add_argument</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"-i"</span><span class="enlighter-text">, </span><span class="enlighter-s0">"--image"</span><span class="enlighter-text">, help = </span><span class="enlighter-s0">"path to the image file"</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">ap.</span><span class="enlighter-m1">add_argument</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"-r"</span><span class="enlighter-text">, </span><span class="enlighter-s0">"--radius"</span><span class="enlighter-text">, type = int,</span></div></div><div class=""><div><span class="enlighter-text">	help = </span><span class="enlighter-s0">"radius of Gaussian blur; must be odd"</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">args = </span><span class="enlighter-m0">vars</span><span class="enlighter-g1">(</span><span class="enlighter-text">ap.</span><span class="enlighter-m1">parse_args</span><span class="enlighter-g1">())</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"></span></div></div><div class=""><div><span class="enlighter-c0"># load the image and convert it to grayscale</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">image = cv2.</span><span class="enlighter-m1">imread</span><span class="enlighter-g1">(</span><span class="enlighter-text">args</span><span class="enlighter-g1">[</span><span class="enlighter-s0">"image"</span><span class="enlighter-g1">])</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">orig = image.</span><span class="enlighter-m1">copy</span><span class="enlighter-g1">()</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">gray = cv2.</span><span class="enlighter-m1">cvtColor</span><span class="enlighter-g1">(</span><span class="enlighter-text">image, cv2.COLOR_BGR2GRAY</span><span class="enlighter-g1">)</span></div></div></div><div class="enlighter-raw"># import the necessary packages
import numpy as np
import argparse
import cv2

# construct the argument parse and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-i", "--image", help = "path to the image file")
ap.add_argument("-r", "--radius", type = int,
	help = "radius of Gaussian blur; must be odd")
args = vars(ap.parse_args())

# load the image and convert it to grayscale
image = cv2.imread(args["image"])
orig = image.copy()
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="" data-enlighter-title="Finding the Brightest Spot in an Image using Python and OpenCV" data-enlighter-group="4"># import the necessary packages
import numpy as np
import argparse
import cv2

# construct the argument parse and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-i", "--image", help = "path to the image file")
ap.add_argument("-r", "--radius", type = int,
	help = "radius of Gaussian blur; must be odd")
args = vars(ap.parse_args())

# load the image and convert it to grayscale
image = cv2.imread(args["image"])
orig = image.copy()
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
</pre>


<p>On <strong>Lines 2-4</strong> we’ll import the packages we’ll need. If you’re a regular PyImageSearch reader, these packages should feel like old hat to you now. We’ll use NumPy for numerical processing, <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">argparse</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">argparse</code>  to parse command line arguments, and <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">cv2</code>  for our OpenCV bindings.</p>
<p>From there, we’ll parse our command line arguments on <strong>Lines 7-11</strong>. Nothing too special here.<br>
The first switch, <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">--image</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">--image</code> , is the path to the image we are going to find the brightest spot in. The second switch <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">--radius</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">--radius</code> , is an integer indicating the radius of the Gaussian blur we are going to apply to the image.</p>
<p>It’s important to note that this radius value must be <em>odd</em> and <strong>not</strong> <em>even.</em></p>
<p>Next up, lets go ahead and load the image on <strong>Line 14</strong>, make a clone of it on <strong>Line 15</strong>, and convert it to grayscale on <strong>Line 15</strong>.</p>
<h2>The Susceptible Method:</h2>
<p>Now, let’s go ahead and apply the suspectible method method to detecting the brightest spot in the image:</p>


<div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Finding the Brightest Spot in an Image using Python and OpenCV</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style="counter-reset: enlighter 17"><div class=""><div><span class="enlighter-c0"># perform a naive attempt to find the (x, y) coordinates of</span><span class="enlighter-c0"></span></div></div><div class=""><div><span class="enlighter-c0"># the area of the image with the largest intensity value</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-g1">(</span><span class="enlighter-text">minVal, maxVal, minLoc, maxLoc</span><span class="enlighter-g1">)</span><span class="enlighter-text"> = cv2.</span><span class="enlighter-m1">minMaxLoc</span><span class="enlighter-g1">(</span><span class="enlighter-text">gray</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">cv2.</span><span class="enlighter-m1">circle</span><span class="enlighter-g1">(</span><span class="enlighter-text">image, maxLoc, </span><span class="enlighter-n1">5</span><span class="enlighter-text">, </span><span class="enlighter-g1">(</span><span class="enlighter-n1">255</span><span class="enlighter-text">, </span><span class="enlighter-n1">0</span><span class="enlighter-text">, </span><span class="enlighter-n1">0</span><span class="enlighter-g1">)</span><span class="enlighter-text">, </span><span class="enlighter-n1">2</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"></span></div></div><div class=""><div><span class="enlighter-c0"># display the results of the naive attempt</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">cv2.</span><span class="enlighter-m1">imshow</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"Naive"</span><span class="enlighter-text">, image</span><span class="enlighter-g1">)</span></div></div></div><div class="enlighter-raw"># perform a naive attempt to find the (x, y) coordinates of
# the area of the image with the largest intensity value
(minVal, maxVal, minLoc, maxLoc) = cv2.minMaxLoc(gray)
cv2.circle(image, maxLoc, 5, (255, 0, 0), 2)

# display the results of the naive attempt
cv2.imshow("Naive", image)</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="18" data-enlighter-title="Finding the Brightest Spot in an Image using Python and OpenCV" data-enlighter-group="9"># perform a naive attempt to find the (x, y) coordinates of
# the area of the image with the largest intensity value
(minVal, maxVal, minLoc, maxLoc) = cv2.minMaxLoc(gray)
cv2.circle(image, maxLoc, 5, (255, 0, 0), 2)

# display the results of the naive attempt
cv2.imshow("Naive", image)
</pre>


<p>The susceptible method to finding the brightest spot in an image is to use the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.</span><span class="enlighter-m3">minMaxLoc</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">cv2.minMaxLoc</code>  function <strong><em>without any pre-processing</em></strong>. This function requires a single argument, which is our grayscale image. Then, this function takes our grayscale image and finds the value and <em>(x, y)</em> location of the pixel with the smallest and largest intensity values, respectively.</p>
<p>To break it down: <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">minVal</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">minVal</code>  contains the smallest pixel intensity value, <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">maxVal</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">maxVal</code>  contains the largest pixel intensity value, <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">minLoc</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">minLoc</code>  specifies the <em>(x, y)</em> coordinates of minVal, and <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">maxLoc</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">maxLoc</code>  specifies the <em>(x, y)</em> coordinates of <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">maxLoc</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">maxLoc</code> .</p>
<p>In this application, we’re only concerned with the pixel with the largest value, so we’ll grab that and draw a circle around the region on <strong>Line 20</strong> and display it on <strong>Line 24</strong>.</p>
<p>The biggest problem with this method, and why I call it the susceptible method to find the brightest spot in an image, is that it’s <strong><em>extremely</em></strong> susceptible to noise.</p>
<p>A single pixel could dramatically throw off your results…</p>
<p>So how do we fix this?</p>
<p>Simple.</p>
<p>We’ll apply a Gaussian blurring through a pre-processing step.</p>
<h2>The Slightly More Robust Method:</h2>
<p>Let’s go ahead and check out how to do this:</p>


<div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Finding the Brightest Spot in an Image using Python and OpenCV</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style=""><div class=""><div><span class="enlighter-c0"># import the necessary packages</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k0">import</span><span class="enlighter-text"> numpy </span><span class="enlighter-k0">as</span><span class="enlighter-text"> np</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k0">import</span><span class="enlighter-text"> argparse</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k0">import</span><span class="enlighter-text"> cv2</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"></span></div></div><div class=""><div><span class="enlighter-c0"># construct the argument parse and parse the arguments</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">ap = argparse.</span><span class="enlighter-m1">ArgumentParser</span><span class="enlighter-g1">()</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">ap.</span><span class="enlighter-m1">add_argument</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"-i"</span><span class="enlighter-text">, </span><span class="enlighter-s0">"--image"</span><span class="enlighter-text">, help = </span><span class="enlighter-s0">"path to the image file"</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">ap.</span><span class="enlighter-m1">add_argument</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"-r"</span><span class="enlighter-text">, </span><span class="enlighter-s0">"--radius"</span><span class="enlighter-text">, type = int,</span></div></div><div class=""><div><span class="enlighter-text">	help = </span><span class="enlighter-s0">"radius of Gaussian blur; must be odd"</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">args = </span><span class="enlighter-m0">vars</span><span class="enlighter-g1">(</span><span class="enlighter-text">ap.</span><span class="enlighter-m1">parse_args</span><span class="enlighter-g1">())</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"></span></div></div><div class=""><div><span class="enlighter-c0"># load the image and convert it to grayscale</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">image = cv2.</span><span class="enlighter-m1">imread</span><span class="enlighter-g1">(</span><span class="enlighter-text">args</span><span class="enlighter-g1">[</span><span class="enlighter-s0">"image"</span><span class="enlighter-g1">])</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">orig = image.</span><span class="enlighter-m1">copy</span><span class="enlighter-g1">()</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">gray = cv2.</span><span class="enlighter-m1">cvtColor</span><span class="enlighter-g1">(</span><span class="enlighter-text">image, cv2.COLOR_BGR2GRAY</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"></span></div></div><div class=""><div><span class="enlighter-c0"># perform a naive attempt to find the (x, y) coordinates of</span><span class="enlighter-c0"></span></div></div><div class=""><div><span class="enlighter-c0"># the area of the image with the largest intensity value</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-g1">(</span><span class="enlighter-text">minVal, maxVal, minLoc, maxLoc</span><span class="enlighter-g1">)</span><span class="enlighter-text"> = cv2.</span><span class="enlighter-m1">minMaxLoc</span><span class="enlighter-g1">(</span><span class="enlighter-text">gray</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">cv2.</span><span class="enlighter-m1">circle</span><span class="enlighter-g1">(</span><span class="enlighter-text">image, maxLoc, </span><span class="enlighter-n1">5</span><span class="enlighter-text">, </span><span class="enlighter-g1">(</span><span class="enlighter-n1">255</span><span class="enlighter-text">, </span><span class="enlighter-n1">0</span><span class="enlighter-text">, </span><span class="enlighter-n1">0</span><span class="enlighter-g1">)</span><span class="enlighter-text">, </span><span class="enlighter-n1">2</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"></span></div></div><div class=""><div><span class="enlighter-c0"># display the results of the naive attempt</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">cv2.</span><span class="enlighter-m1">imshow</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"Naive"</span><span class="enlighter-text">, image</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"></span></div></div><div class=""><div><span class="enlighter-c0"># apply a Gaussian blur to the image then find the brightest</span><span class="enlighter-c0"></span></div></div><div class=""><div><span class="enlighter-c0"># region</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">gray = cv2.</span><span class="enlighter-m1">GaussianBlur</span><span class="enlighter-g1">(</span><span class="enlighter-text">gray, </span><span class="enlighter-g1">(</span><span class="enlighter-text">args</span><span class="enlighter-g1">[</span><span class="enlighter-s0">"radius"</span><span class="enlighter-g1">]</span><span class="enlighter-text">, args</span><span class="enlighter-g1">[</span><span class="enlighter-s0">"radius"</span><span class="enlighter-g1">])</span><span class="enlighter-text">, </span><span class="enlighter-n1">0</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-g1">(</span><span class="enlighter-text">minVal, maxVal, minLoc, maxLoc</span><span class="enlighter-g1">)</span><span class="enlighter-text"> = cv2.</span><span class="enlighter-m1">minMaxLoc</span><span class="enlighter-g1">(</span><span class="enlighter-text">gray</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">image = orig.</span><span class="enlighter-m1">copy</span><span class="enlighter-g1">()</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">cv2.</span><span class="enlighter-m1">circle</span><span class="enlighter-g1">(</span><span class="enlighter-text">image, maxLoc, args</span><span class="enlighter-g1">[</span><span class="enlighter-s0">"radius"</span><span class="enlighter-g1">]</span><span class="enlighter-text">, </span><span class="enlighter-g1">(</span><span class="enlighter-n1">255</span><span class="enlighter-text">, </span><span class="enlighter-n1">0</span><span class="enlighter-text">, </span><span class="enlighter-n1">0</span><span class="enlighter-g1">)</span><span class="enlighter-text">, </span><span class="enlighter-n1">2</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"></span></div></div><div class=""><div><span class="enlighter-c0"># display the results of our newly improved method</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">cv2.</span><span class="enlighter-m1">imshow</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"Robust"</span><span class="enlighter-text">, image</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">cv2.</span><span class="enlighter-m1">waitKey</span><span class="enlighter-g1">(</span><span class="enlighter-n1">0</span><span class="enlighter-g1">)</span></div></div></div><div class="enlighter-raw"># import the necessary packages
import numpy as np
import argparse
import cv2

# construct the argument parse and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-i", "--image", help = "path to the image file")
ap.add_argument("-r", "--radius", type = int,
	help = "radius of Gaussian blur; must be odd")
args = vars(ap.parse_args())

# load the image and convert it to grayscale
image = cv2.imread(args["image"])
orig = image.copy()
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# perform a naive attempt to find the (x, y) coordinates of
# the area of the image with the largest intensity value
(minVal, maxVal, minLoc, maxLoc) = cv2.minMaxLoc(gray)
cv2.circle(image, maxLoc, 5, (255, 0, 0), 2)

# display the results of the naive attempt
cv2.imshow("Naive", image)

# apply a Gaussian blur to the image then find the brightest
# region
gray = cv2.GaussianBlur(gray, (args["radius"], args["radius"]), 0)
(minVal, maxVal, minLoc, maxLoc) = cv2.minMaxLoc(gray)
image = orig.copy()
cv2.circle(image, maxLoc, args["radius"], (255, 0, 0), 2)

# display the results of our newly improved method
cv2.imshow("Robust", image)
cv2.waitKey(0)</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="" data-enlighter-title="Finding the Brightest Spot in an Image using Python and OpenCV" data-enlighter-group="16"># import the necessary packages
import numpy as np
import argparse
import cv2

# construct the argument parse and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-i", "--image", help = "path to the image file")
ap.add_argument("-r", "--radius", type = int,
	help = "radius of Gaussian blur; must be odd")
args = vars(ap.parse_args())

# load the image and convert it to grayscale
image = cv2.imread(args["image"])
orig = image.copy()
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# perform a naive attempt to find the (x, y) coordinates of
# the area of the image with the largest intensity value
(minVal, maxVal, minLoc, maxLoc) = cv2.minMaxLoc(gray)
cv2.circle(image, maxLoc, 5, (255, 0, 0), 2)

# display the results of the naive attempt
cv2.imshow("Naive", image)

# apply a Gaussian blur to the image then find the brightest
# region
gray = cv2.GaussianBlur(gray, (args["radius"], args["radius"]), 0)
(minVal, maxVal, minLoc, maxLoc) = cv2.minMaxLoc(gray)
image = orig.copy()
cv2.circle(image, maxLoc, args["radius"], (255, 0, 0), 2)

# display the results of our newly improved method
cv2.imshow("Robust", image)
cv2.waitKey(0)
</pre>


<p>Like I mentioned above, using <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.</span><span class="enlighter-m3">minMaxLoc</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">cv2.minMaxLoc</code>  without any pre-processing can leave you extremely susceptible to noise.</p>
<p>Instead, it’s better to first apply a Gaussian blur to the image to remove high frequency noise. This way, even pixels that have very large values (again, due to noise) will be averaged out by their neighbors.</p>
<p>On <strong>Line 28</strong> we apply our Gaussian blur with the supplied radius from our command line argument.</p>
<p>Then we once again make a call to <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.</span><span class="enlighter-m3">minMaxLoc</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">cv2.minMaxLoc</code>  to find the brightest pixel in the image.</p>
<p>However, since we have applied a blurring pre-processing step, we’ve averaged all pixels together with the supplied <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">radius</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">radius</code>  of each other. Doing this allows us to remove high frequency noise and leaves <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.</span><span class="enlighter-m3">minMaxLoc</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">cv2.minMaxLoc</code>  substantially less susceptible.</p>
<p>By using a <em>larger</em> radius we’ll be averaging over a larger neighborhood of pixels — thus mimicking larger regions of the image.</p>
<p>And by using a <em>smaller</em> radius we can average over smaller regions.</p>
<p>Determining the correct radius will heavily dependent on the application you are developing and the task you are trying to solve.</p>
<h1>Results</h1>
<p>Fire up a terminal and execute the following command:</p>


<div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Finding the Brightest Spot in an Image using Python and OpenCV</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style=""><div class=""><div><span class="enlighter-text">$ python bright.py --image retina.png --radius </span><span class="enlighter-n1">41</span></div></div></div><div class="enlighter-raw">$ python bright.py --image retina.png --radius 41</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="" data-enlighter-title="Finding the Brightest Spot in an Image using Python and OpenCV" data-enlighter-group="21">$ python bright.py --image retina.png --radius 41
</pre>


<p>If all goes well, you should see the following image:</p>
<figure id="attachment_1138" aria-describedby="caption-attachment-1138" style="width: 600px" class="wp-caption aligncenter"><a href="https://pyimagesearch.com/wp-content/uploads/2014/08/bright-area-retina.jpg"><img class="wp-image-1138 lazyloaded" data-savepage-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina.jpg?size=600x243&lossy=1&strip=1&webp=1" src="" alt="Figure 1: Detecting the brightest area of a retinal image using our naive and robust methods. The results are good and look quite similar." width="600" height="243" data-ll-status="loaded"><noscript><img class="wp-image-1138" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina.jpg?lossy=1&strip=1&webp=1" alt="Figure 1: Detecting the brightest area of a retinal image using our naive and robust methods. The results are good and look quite similar." width="600" height="243" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina.jpg?lossy=1&strip=1&webp=1 1000w,https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina.jpg?size=126x51&lossy=1&strip=1&webp=1 126w,https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina.jpg?size=252x102&lossy=1&strip=1&webp=1 252w,https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina.jpg?size=378x153&lossy=1&strip=1&webp=1 378w,https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina.jpg?size=504x204&lossy=1&strip=1&webp=1 504w,https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina.jpg?size=630x255&lossy=1&strip=1&webp=1 630w" sizes="(max-width: 1000px) 100vw, 1000px"></noscript></a><figcaption id="caption-attachment-1138" class="wp-caption-text"><strong>Figure 1:</strong> Detecting the brightest area of a retinal image using our naive and robust methods. The results are good and look quite similar.</figcaption></figure>
<p>On the <em>left</em> we have the susceptible method using <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.</span><span class="enlighter-m3">minMaxLoc</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">cv2.minMaxLoc</code>  <strong><em>without</em></strong> any pre-processing and on the <em>right</em> we have the robust method.</p>
<p>But you’re probably looking at these images and saying, <em>“Hey Adrian, they both detected the same region of the image!”</em></p>
<p>You’re right. They did.</p>
<p>But watch what happens when I add a single bright pixel to the top-center part of this image when you issue this command:</p>


<div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Finding the Brightest Spot in an Image using Python and OpenCV</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style=""><div class=""><div><span class="enlighter-text">$ python bright.py --image images/retina-noise.png --radius </span><span class="enlighter-n1">41</span></div></div></div><div class="enlighter-raw">$ python bright.py --image images/retina-noise.png --radius 41</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="" data-enlighter-title="Finding the Brightest Spot in an Image using Python and OpenCV" data-enlighter-group="23">$ python bright.py --image images/retina-noise.png --radius 41
</pre>


<p>Your results should look something like:</p>
<figure id="attachment_1137" aria-describedby="caption-attachment-1137" style="width: 600px" class="wp-caption aligncenter"><a href="https://pyimagesearch.com/wp-content/uploads/2014/08/bright-area-retina-noise.jpg"><img class="wp-image-1137 lazyloaded" data-savepage-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina-noise.jpg?size=600x241&lossy=1&strip=1&webp=1" src="" alt="Figure 2: Adding a single white pixel to the image has thrown off the results of cv2.minMaxLoc (left), but the robust method is still able to easily find the optic center." width="600" height="241" data-ll-status="loaded"><noscript><img class="wp-image-1137" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina-noise.jpg?lossy=1&strip=1&webp=1" alt="Figure 2: Adding a single white pixel to the image has thrown off the results of cv2.minMaxLoc (left), but the robust method is still able to easily find the optic center." width="600" height="241" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina-noise.jpg?lossy=1&strip=1&webp=1 1000w,https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina-noise.jpg?size=126x51&lossy=1&strip=1&webp=1 126w,https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina-noise.jpg?size=252x101&lossy=1&strip=1&webp=1 252w,https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina-noise.jpg?size=378x152&lossy=1&strip=1&webp=1 378w,https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina-noise.jpg?size=504x202&lossy=1&strip=1&webp=1 504w,https://929687.smushcdn.com/2633864/wp-content/uploads/2014/08/bright-area-retina-noise.jpg?size=630x253&lossy=1&strip=1&webp=1 630w" sizes="(max-width: 1000px) 100vw, 1000px" /></noscript></a><figcaption id="caption-attachment-1137" class="wp-caption-text"><strong>Figure 2:</strong> Adding a single bright pixel to the image has thrown off the results of cv2.minMaxLoc without any pre-processing (<em>left</em>), but the robust method is still able to easily find the optic center (<em>right</em>).</figcaption></figure>
<p>Now, the naive <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.</span><span class="enlighter-m3">minMaxLoc</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">cv2.minMaxLoc</code>  method finds this white pixel. Let’s be clear. The function is working correctly. It is indeed finding the single brightest pixel in the entire image.</p>
<p>However, this really isn’t what we want.</p>
<p>We are interested in the brightest <strong><em>region</em></strong> of the image, which is the optic nerve center.</p>
<p>Luckily, by utilizing a Gaussian blur, we are able to average a neighborhood of pixels within a given radius, and thus discard the single bright pixel and narrow in on the optic center region without an issue.</p>
<p>Obviously, a big aspect of getting the robust method to work correctly is properly setting your <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">radius</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">radius</code>   size. If your <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">radius</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">radius</code>  size is too small, you won’t be able to find larger, brighter regions of the image.</p>
<p>But if you set the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">radius</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">radius</code>   size too large, then you’ll be detecting too large of regions, missing out on the smaller ones, leading to sub-par results.</p>
<p>Definitely spend some time playing with the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">radius</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">radius</code>  size and viewing the results.</p>
<div style="padding: 40px; width: 100%; background-color: #F4F6FA;">
	<h3>What's next? I recommend <a target="_blank" href="https://pyimagesearch.com/pyimagesearch-university/?utm_source=blogPost&utm_medium=bottomBanner&utm_campaign=What%27s%20next%3F%20I%20recommend">PyImageSearch University</a>.</h3>

	<div class="wistia_responsive_padding" style="padding:56.25% 0 0 0;position:relative;"><div class="wistia_responsive_wrapper" style="height:100%;left:0;position:absolute;top:0;width:100%;"><div class="wistia_video_foam_dummy" data-source-container-id="wistia-kno0cmko2z-1" style="border: 0px; display: block; height: 0px; margin: 0px; padding: 0px; position: static; visibility: hidden; width: auto;"></div><div class="wistia_embed wistia_async_kno0cmko2z videoFoam=true wistia_embed_initialized" style="height: 365px; position: relative; width: 650px;" id="wistia-kno0cmko2z-1"><div class="wistia_swatch" style="height: 100%; left: 0px; opacity: 1; overflow: hidden; position: absolute; top: 0px; transition: opacity 200ms ease 0s; width: 100%;"><img data-savepage-src="https://fast.wistia.com/embed/medias/kno0cmko2z/swatch" src="" style="filter:blur(5px);height:100%;object-fit:contain;width:100%;" alt="" aria-hidden="true" onload="this.parentNode.style.opacity=1;"></div><div id="wistia_chrome_37" class="w-chrome" tabindex="-1" style="display: inline-block; height: 365px; line-height: normal; margin: 0px; padding: 0px; position: relative; vertical-align: top; width: 650px; zoom: 1; outline: none; overflow: hidden; box-sizing: content-box;"><div id="wistia_grid_43_wrapper" style="display: block; width: 650px; height: 365px;"><div id="wistia_grid_43_above" style="height: 0px; font-size: 0px; line-height: 0px;"> </div><div id="wistia_grid_43_main" style="width: 650px; left: 0px; height: 365px; margin-top: 0px;"><div id="wistia_grid_43_behind"></div><div id="wistia_grid_43_center" style="width: 100%; height: 100%;"><div class="w-video-wrapper w-css-reset" style="height: 100%; position: absolute; top: 0px; width: 100%; opacity: 1; background-color: rgb(0, 0, 0);"><video id="wistia_simple_video_127" crossorigin="anonymous" data-savepage-poster="https://fast.wistia.net/assets/images/blank.gif" poster="data:image/gif;base64,R0lGODlhZABkAIAAAP///wAAACH/C1hNUCBEYXRhWE1QPD94cGFja2V0IGJlZ2luPSLvu78iIGlkPSJXNU0wTXBDZWhpSHpyZVN6TlRjemtjOWQiPz4gPHg6eG1wbWV0YSB4bWxuczp4PSJhZG9iZTpuczptZXRhLyIgeDp4bXB0az0iQWRvYmUgWE1QIENvcmUgNS42LWMwNjcgNzkuMTU3NzQ3LCAyMDE1LzAzLzMwLTIzOjQwOjQyICAgICAgICAiPiA8cmRmOlJERiB4bWxuczpyZGY9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkvMDIvMjItcmRmLXN5bnRheC1ucyMiPiA8cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0iIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtbG5zOnhtcE1NPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvbW0vIiB4bWxuczpzdFJlZj0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL3NUeXBlL1Jlc291cmNlUmVmIyIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ0MgMjAxNSAoTWFjaW50b3NoKSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDpCMDZDMTMwQzQ3OEExMUU2QjNFOEQ2NzY1NTcxOEQ0RCIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDpCMDZDMTMwRDQ3OEExMUU2QjNFOEQ2NzY1NTcxOEQ0RCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOjQ5MkExRDdGNDc4ODExRTZCM0U4RDY3NjU1NzE4RDREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjQ5MkExRDgwNDc4ODExRTZCM0U4RDY3NjU1NzE4RDREIi8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+Af/+/fz7+vn49/b19PPy8fDv7u3s6+rp6Ofm5eTj4uHg397d3Nva2djX1tXU09LR0M/OzczLysnIx8bFxMPCwcC/vr28u7q5uLe2tbSzsrGwr66trKuqqainpqWko6KhoJ+enZybmpmYl5aVlJOSkZCPjo2Mi4qJiIeGhYSDgoGAf359fHt6eXh3dnV0c3JxcG9ubWxramloZ2ZlZGNiYWBfXl1cW1pZWFdWVVRTUlFQT05NTEtKSUhHRkVEQ0JBQD8+PTw7Ojk4NzY1NDMyMTAvLi0sKyopKCcmJSQjIiEgHx4dHBsaGRgXFhUUExIREA8ODQwLCgkIBwYFBAMCAQAAIfkEAQAAAAAsAAAAAGQAZAAAAnOEj6nL7Q+jnLTai7PevPsPhuJIluaJpurKtu4Lx/JM1/aN5/rO9/4PDAqHxKLxiEwql8ym8wmNSqfUqvWKzWq33K73Cw6Lx+Sy+YxOq9fstvsNj8vn9Lr9js/r9/y+/w8YKDhIWGh4iJiouMjY6PgIaVgAADs=" aria-label="Video" src="blob:https://pyimagesearch.com/569ed6a6-4ffb-4da6-80e3-5eff4376cbe5" controlslist="nodownload" playsinline="" preload="none" type="video/m3u8" x-webkit-airplay="allow" style="background: transparent; display: block; height: 100%; max-height: none; max-width: none; position: static; visibility: visible; width: 100%; object-fit: fill;"></video></div><div class="w-ui-container" style="height: 100%; left: 0px; position: absolute; top: 0px; width: 100%; opacity: 1;"><div class="w-vulcan-v2 w-css-reset" id="w-vulcan-v2-42" style="box-sizing: border-box; cursor: default; height: 100%; left: 0px; position: absolute; visibility: visible; top: 0px; width: 100%;"><div class="w-vulcan--background w-css-reset" style="height: 100%; left: 0px; position: absolute; top: 0px; width: 100%;"><div class="w-css-reset" data-handle="statusBar"></div><div class="w-css-reset" data-handle="backgroundFocus"><button aria-label="Play Video" class="w-css-reset w-vulcan-v2-button" tabindex="0" style="width: 0px; height: 0px; pointer-events: none;"></button></div><div class="w-css-reset" data-handle="thumbnail"><div><div class="w-css-reset" style="filter: blur(5px); height: 100%; left: 0px; position: absolute; top: 0px; width: 100%; display: block;"><img class="w-css-reset" srcset="" data-savepage-src="https://fast.wistia.net/embed/medias/kno0cmko2z/swatch" src="" alt="Video Thumbnail" aria-hidden="true" style="height: 365px; left: 0px; position: absolute; top: 0px; width: 650px; clip: auto; display: block; border-width: 0px; border-style: solid; border-color: rgb(0, 0, 0); box-sizing: content-box;"></div><div class="w-css-reset" style="height: 100%; left: 0px; opacity: 1; position: absolute; top: 0px; width: 100%; display: block; transition: opacity 3s ease 0s;"><img class="w-css-reset" data-savepage-srcset="https://embed-fastly.wistia.com/deliveries/4bda0a1602c8b4d96d63a02617f3069e.webp?image_crop_resized=640x360 320w, https://embed-fastly.wistia.com/deliveries/4bda0a1602c8b4d96d63a02617f3069e.webp?image_crop_resized=640x360 640w, https://embed-fastly.wistia.com/deliveries/4bda0a1602c8b4d96d63a02617f3069e.webp?image_crop_resized=960x540 960w, https://embed-fastly.wistia.com/deliveries/4bda0a1602c8b4d96d63a02617f3069e.webp?image_crop_resized=1280x720 1280w, https://embed-fastly.wistia.com/deliveries/4bda0a1602c8b4d96d63a02617f3069e.webp?image_crop_resized=1920x1080 1920w, https://embed-fastly.wistia.com/deliveries/4bda0a1602c8b4d96d63a02617f3069e.webp?image_crop_resized=1920x1080 3840w" srcset="" data-savepage-src="https://embed-fastly.wistia.com/deliveries/4bda0a1602c8b4d96d63a02617f3069e.webp?image_crop_resized=1920x1080" src="" alt="Video Thumbnail" style="height: 365px; left: 0px; position: absolute; top: 0px; width: 650px; clip: auto; display: block; border-width: 0px; border-style: solid; border-color: rgb(0, 0, 0); box-sizing: content-box;"></div></div></div></div><div aria-live="polite" class="w-vulcan--aria-live w-css-reset" aria-atomic="true" style="position: absolute; left: -99999em;"></div><div class="w-vulcan-overlays-table w-css-reset" style="display: table; pointer-events: none; position: absolute; width: 100%;"><div class="w-vulcan-overlays--left w-css-reset" style="display: table-cell; vertical-align: top; position: relative; width: 0px;"><div class="w-css-reset" style="height: 331px;"></div></div><div class="w-vulcan-overlays--center w-css-reset" style="display: table-cell; vertical-align: top; position: relative; width: 100%;"><div class="w-css-reset" style="height: 331px;"><div class="w-css-reset" data-handle="bigPlayButton" style="pointer-events: auto;"><div class="w-bpb-wrapper w-css-reset w-css-reset-tree" style="display: block; left: calc(50%); margin-left: -62.5px; margin-top: -40px; position: absolute; top: calc(50%);"><button class="w-big-play-button w-css-reset-button-important w-vulcan-v2-button" aria-label="Play Video: Pyimagesearch_Sales_page w/out Autoplay" style="cursor: pointer; height: 80px; box-shadow: none; width: 125px;"><div style="background: rgb(30, 113, 231); display: block; left: 0px; height: 80px; mix-blend-mode: darken; position: absolute; top: 0px; width: 125px;"></div><div style="background-color: rgba(30, 113, 231, 0.7); height: 80px; left: 0px; position: absolute; top: 0px; transition: background-color 150ms ease 0s; width: 125px;"></div><svg x="0px" y="0px" viewBox="0 0 125 80" enable-background="new 0 0 125 80" focusable="false" alt="" style="fill: rgb(255, 255, 255); height: 80px; left: 0px; stroke-width: 0px; top: 0px; width: 100%; position: absolute;"><rect fill-rule="evenodd" clip-rule="evenodd" fill="none" width="125" height="80"></rect><polygon fill-rule="evenodd" clip-rule="evenodd" fill="#FFFFFF" points="53,22 53,58 79,40"></polygon></svg></button></div></div><div class="w-css-reset" data-handle="clickForSoundButton" style="pointer-events: auto;"><div class="w-css-reset w-css-reset-tree" data-handle="click-for-sound-backdrop" style="display: none; height: 100%; left: 0px; pointer-events: auto; position: absolute; top: 0px; width: 100%;"><button aria-label="Click for sound" class="w-vulcan-v2-button" style="background: rgba(0, 0, 0, 0.8); border: 2px solid transparent; border-radius: 50%; cursor: pointer; height: 52.5px; width: 52.5px; line-height: 52.5px; outline: none; pointer-events: auto; position: absolute; right: 20.5px; text-align: left; top: 20.5px;"><svg viewBox="0 0 237 237"><style>
      @keyframes VOLUME_SMALL_WAVE_FLASH {
          0% { opacity: 0; }
         33% { opacity: 1; }
         66% { opacity: 1; }
        100% { opacity: 0; }
      }

      @keyframes VOLUME_LARGE_WAVE_FLASH {
          0% { opacity: 0; }
         33% { opacity: 1; }
         66% { opacity: 1; }
        100% { opacity: 0; }
      }

      .volume__small-wave {
        animation: VOLUME_SMALL_WAVE_FLASH 2s infinite;
        opacity: 0;
      }

      .volume__large-wave {
        animation: VOLUME_LARGE_WAVE_FLASH 2s infinite .3s;
        opacity: 0;
      }
    </style><polygon fill="white" points="88 107 65 107 65 131 89 131 112 154 112 84"></polygon><g fill="none" stroke="white" stroke-width="10" stroke-linecap="round"><path class="volume__small-wave" d="M 142 86 C 151 107 151 130 142 151"></path><path class="volume__large-wave" d="M 165 74 C 178 97 178 140 165 163"></path></g></svg></button></div></div><div class="w-css-reset" data-handle="playPauseNotifier" style="pointer-events: auto;"></div><div class="w-css-reset" data-handle="playPauseLoading" style="pointer-events: auto;"><div class="w-css-reset w-css-reset-tree" style="height: 100%; left: 0px; pointer-events: none; position: absolute; top: 0px; width: 100%;"><button aria-label="Play Video" class="w-vulcan-v2-button" style="background: rgba(0, 0, 0, 0.6); border: 0px; border-radius: 50%; cursor: pointer; display: none; height: 140px; left: 50%; margin: 0px; padding: 0px; pointer-events: auto; position: absolute; opacity: 0; outline: none; top: 50%; transform: translate(-50%, -50%) scale(0.8); transition: opacity 200ms ease 0s, transform 600ms ease 0s; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); width: 140px;"><div style="box-sizing: border-box; height: 100%; padding: 47.25px 47.25px 47.25px 57.75px;"><div style="height: 100%; width: 100%;"><div style="display: none; height: 100%; width: 100%;"><svg x="0px" y="0px" viewBox="0 0 11.556 16" enable-background="new 0 0 11.556 16" focusable="false" class="w-css-reset w-css-reset-tree" style="fill: rgb(255, 255, 255); height: 100%; left: 0px; stroke-width: 0px; top: 0px; width: 100%;"><g><rect x="0" y="0" width="3.5" height="12"></rect><rect x="6.5" y="0" width="3.5" height="12"></rect></g></svg></div><div style="display: block; height: 100%; width: 100%;"><svg x="0px" y="0px" viewBox="0 0 11.556 16" enable-background="new 0 0 11.556 16" focusable="false" class="w-css-reset w-css-reset-tree" style="fill: rgb(255, 255, 255); height: 100%; left: 0px; stroke-width: 0px; top: 0px; width: 100%;"><polygon points="11.556,7.5 0,15 0,0"></polygon></svg></div></div></div></button></div></div></div></div><div class="w-vulcan-overlays--right w-css-reset" style="display: table-cell; vertical-align: top; position: relative; width: 0px;"><div class="w-css-reset" style="height: 331px;"></div></div></div><div class="w-bottom-bar w-css-reset" style="bottom: 0px; border-collapse: collapse; display: table; height: 34px; pointer-events: none; position: absolute; right: 0px; table-layout: auto; width: 100%;"><div class="w-bottom-bar-lower w-css-reset" style="position: relative;"><div style="height: 100%; left: 0px; position: absolute; top: 0px; width: 100%;"><div style="background: rgb(30, 113, 231); display: none; height: 100%; mix-blend-mode: darken; left: 0px; opacity: 1; position: absolute; top: 0px; transition: opacity 0s ease 0s; width: 100%;"></div><div style="background: rgba(30, 113, 231, 0.85); height: 100%; opacity: 1; left: 0px; position: absolute; top: 0px; transition: opacity 0s ease 0s; width: 100%;"></div></div><div style="display: none;"><div style="background: rgb(30, 113, 231); display: none; height: 100%; mix-blend-mode: darken; left: 0px; opacity: 1; position: absolute; top: 0px; transition: opacity 0s ease 0s; width: 100%;"></div><div style="background: rgba(30, 113, 231, 0.85); height: 100%; opacity: 1; left: 0px; position: absolute; top: 0px; transition: opacity 0s ease 0s; width: 100%;"></div></div><div class="w-bottom-bar-left w-css-reset" style="display: table-cell; vertical-align: top; position: relative; width: 0px; opacity: 1; transition: opacity 0s ease 0s;"><div class="w-bottom-bar-left-inner w-css-reset" style="height: 34px; position: relative; pointer-events: auto; white-space: nowrap;"><div class="w-css-reset" data-handle="smallPlayButton" style="display: inline-block; vertical-align: top;"><div class="w-vulcan-button-wrapper w-css-reset" style="display: inline-block; height: 34px; position: relative; vertical-align: top; width: 40px;"><button tagname="button" class="w-vulcan-v2-button w-css-reset w-css-reset-tree w-css-reset-button-important" aria-label="Play Video" title="Play Video" style="background-color: rgba(0, 0, 0, 0); box-shadow: none; cursor: pointer; height: 100%; position: relative; transition: background-color 150ms ease 0s; width: 100%;"><div class="w-vulcan-icon-wrapper" data-handle="smallPlayButton" style="box-sizing: border-box; height: 100%; position: relative; transform: scale(1.001); transition: transform 200ms ease 0s;"><div style="box-sizing: border-box; height: 100%; margin-left: 1px; padding: 10px 0px 9px; position: relative; width: 100%;"><div style="height: 100%; width: 100%;"><div style="display: none; height: 100%; width: 100%;"><svg x="0px" y="0px" viewBox="0 0 11.556 16" enable-background="new 0 0 11.556 16" focusable="false" class="w-css-reset w-css-reset-tree" style="fill: rgb(255, 255, 255); height: 100%; left: 0px; stroke-width: 0px; top: 0px; width: 100%; vertical-align: top;"><g><rect x="0" y="0" width="3.5" height="12"></rect><rect x="6.5" y="0" width="3.5" height="12"></rect></g></svg></div><div style="display: block; height: 100%; width: 100%;"><svg x="0px" y="0px" viewBox="0 0 11.556 16" enable-background="new 0 0 11.556 16" focusable="false" class="w-css-reset w-css-reset-tree" style="fill: rgb(255, 255, 255); height: 100%; left: 0px; stroke-width: 0px; top: 0px; width: 100%; vertical-align: top;"><polygon points="11.556,7.5 0,15 0,0"></polygon></svg></div></div></div></div></button></div></div></div></div><div class="w-bottom-bar-middle w-css-reset" style="display: table-cell; vertical-align: top; position: relative; width: 100%; opacity: 1; transition: opacity 0s ease 0s;"><div class="w-bottom-bar-middle-inner w-css-reset" style="height: 34px; position: relative; pointer-events: auto; white-space: nowrap; opacity: 1; transform: translateY(0px); transition: opacity 0ms ease 0s, transform 0ms ease 0s;"><div class="w-css-reset" data-handle="playbar" style="height: 100%; position: relative;"><div class="w-playbar-wrapper w-css-reset w-css-reset-tree" style="display: flex; height: 100%; width: 100%;"><div class="w-playbar__time" style="box-sizing: content-box; color: white; font-family: WistiaPlayerInterNumbersSemiBold, Helvetica, sans-serif; font-size: 13px; letter-spacing: 0.5px; line-height: 34px; padding-left: 5px; pointer-events: none; position: relative; text-align: center; width: 28px;">3:52</div><div aria-label="Playbar" aria-orientation="horizontal" aria-valuemax="231.5" aria-valuemin="0" aria-valuenow="0" aria-valuetext="0:00" role="slider" tabindex="0" style="cursor: pointer; flex: 1 1 0%; height: 34px; outline: none; margin-left: 15px; margin-right: 10px; position: relative;"><canvas height="68" width="914" style="height: 34px; left: -15px; position: absolute; top: 0px; width: 457px; /*savepage-canvas-image*/ background-image: url(data:image/png;base64,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) !important; background-attachment: scroll !important; background-blend-mode: normal !important; background-clip: content-box !important; background-color: transparent !important; background-origin: content-box !important; background-position: center center !important; background-repeat: no-repeat !important; background-size: 100% 100% !important;"></canvas><div style="border-radius: 50%; height: 11.2px; left: -5.6px; opacity: 0; position: absolute; top: 11.4px; width: 11.2px;"></div></div></div></div></div></div><div class="w-bottom-bar-right w-css-reset" style="display: table-cell; vertical-align: top; position: relative; width: 0px; opacity: 1; transition: opacity 0s ease 0s; white-space: nowrap;"><div class="w-bottom-bar-right-inner-anchor w-css-reset" style="height: 34px; position: relative; pointer-events: auto; white-space: nowrap; display: inline-block; right: 0px; top: 0px; vertical-align: top;"><div class="w-bottom-bar-right-inner w-css-reset" style="height: 34px; position: relative; pointer-events: auto; white-space: nowrap; display: inline-block; opacity: 1; right: 0px; top: 0px; transform: translateY(0px); transition: opacity 0ms ease 0s, transform 0ms ease 0s;"><div class="w-css-reset" data-handle="volumeButton" style="display: inline-block; vertical-align: top;"><div class="w-vulcan-button-wrapper w-css-reset" style="display: inline-block; height: 34px; position: relative; vertical-align: top; width: 40px;"><button tagname="button" class="w-vulcan-v2-button w-css-reset w-css-reset-tree w-css-reset-button-important" aria-label="Mute" title="Mute" style="background-color: rgba(0, 0, 0, 0); box-shadow: none; cursor: pointer; height: 100%; position: relative; transition: background-color 150ms ease 0s; width: 100%;"><div class="w-vulcan-icon-wrapper" data-handle="volumeButton" style="box-sizing: border-box; height: 100%; position: relative; transform: scale(1.001); transition: transform 200ms ease 0s;"><svg x="0px" y="0px" viewBox="0 0 40 34" enable-background="new 0 0 40 34" focusable="false" style="fill: rgb(255, 255, 255); height: 100%; left: 0px; stroke-width: 0px; top: 0px; width: 100%;"><g style="transform: translateX(1.25px); transition: transform 100ms ease 0s;"><g><path d="M13.8,14.2c-0.5,0.5-1.4,0.8-2,0.8h-1.6C9.5,15,9,15.5,9,16.2v1.6c0,0.7,0.5,1.2,1.2,1.2h1.6c0.7,0,1.6,0.4,2,0.8l2.3,2.3c0.5,0.5,0.8,0.3,0.8-0.4v-9.6c0-0.7-0.4-0.8-0.8-0.4L13.8,14.2z"></path></g><g><path fill="none" stroke="#ffffff" stroke-line-cap="round" stroke-miterlimit="10" stroke-width="2" d="M22,11.7c0,0,1.1,2.5,1.1,5s-1.1,5-1.1,5" style="opacity: 1; transition: opacity 100ms ease 0s;"></path><path fill="none" stroke="#ffffff" stroke-line-cap="round" stroke-miterlimit="10" stroke-width="2" d="M25.8,9.2c0,0,1.7,3.8,1.7,7.5c0,3.7-1.7,7.5-1.7,7.5" style="opacity: 1; transition: opacity 100ms ease 0s;"></path></g><g style="opacity: 0; transition: opacity 100ms ease 0s;"><line fill="none" stroke="#ffffff" stroke-line-cap="round" stroke-miterlimit="10" stroke-width="1.8102" x1="19.2" y1="15" x2="23.2" y2="19"></line><line fill="none" stroke="#ffffff" stroke-line-cap="round" stroke-miterlimit="10" stroke-width="1.8102" x1="19.2" y1="19" x2="23.2" y2="15"></line></g></g></svg></div></button></div></div><div class="w-css-reset" data-handle="settingsButton" style="display: inline-block; vertical-align: top;"><div class="w-vulcan-button-wrapper w-css-reset" style="display: inline-block; height: 34px; position: relative; vertical-align: top; width: 40px;"><button tagname="button" class="w-vulcan-v2-button w-css-reset w-css-reset-tree w-css-reset-button-important" aria-expanded="false" aria-label="Show settings menu" title="Show settings menu" style="background-color: rgba(0, 0, 0, 0); box-shadow: none; cursor: pointer; height: 100%; position: relative; transition: background-color 150ms ease 0s; width: 100%;"><div class="w-vulcan-icon-wrapper" data-handle="settingsButton" style="box-sizing: border-box; height: 100%; position: relative; transform: scale(1.001); transition: transform 200ms ease 0s;"><svg x="0px" y="0px" viewBox="0 0 40 34" enable-background="new 0 0 40 34" focusable="false" style="fill: rgb(255, 255, 255); height: 100%; left: 0px; stroke-width: 0px; top: 0px; width: 100%;"><g><g><path d="M28.3,16.4h-1.9c-0.4,0-0.8-0.3-0.9-0.7l-0.4-1.1c-0.2-0.3-0.1-0.8,0.2-1.1l1.3-1.3c0.3-0.3,0.3-0.7,0-1l-0.4-0.4c-0.3-0.3-0.7-0.3-1,0l-1.3,1.3c-0.3,0.3-0.8,0.3-1.1,0.1l-1.1-0.5c-0.4-0.1-0.7-0.5-0.7-0.9V9.1c0-0.4-0.3-0.7-0.7-0.7h-0.6c-0.4,0-0.7,0.3-0.7,0.7v1.7c0,0.4-0.3,0.8-0.7,0.9l-1.2,0.5c-0.3,0.2-0.8,0.1-1.1-0.2l-1.2-1.2c-0.3-0.3-0.7-0.3-1,0l-0.4,0.4c-0.3,0.3-0.3,0.7,0,1l1.2,1.2c0.3,0.3,0.3,0.8,0.1,1.1l-0.5,1.2c-0.1,0.4-0.5,0.7-0.9,0.7h-1.6c-0.4,0-0.7,0.3-0.7,0.7v0.6c0,0.4,0.3,0.7,0.7,0.7h1.6c0.4,0,0.8,0.3,0.9,0.7l0.5,1.2c0.2,0.3,0.1,0.8-0.1,1.1l-1.2,1.2c-0.3,0.3-0.3,0.7,0,1l0.4,0.4c0.3,0.3,0.7,0.3,1,0l1.2-1.2c0.3-0.3,0.8-0.3,1.1-0.2l1.2,0.5c0.4,0.1,0.7,0.5,0.7,0.9v1.7c0,0.4,0.3,0.7,0.7,0.7h0.6c0.4,0,0.7-0.3,0.7-0.7V24c0-0.4,0.3-0.8,0.7-0.9l1.1-0.5c0.3-0.2,0.8-0.1,1.1,0.1l1.3,1.3c0.3,0.3,0.7,0.3,1,0l0.4-0.4c0.3-0.3,0.3-0.7,0-1l-1.3-1.3C25,21,25,20.5,25.1,20.2l0.4-1.1c0.1-0.4,0.5-0.7,0.9-0.7h1.9c0.4,0,0.7-0.3,0.7-0.7v-0.6C29,16.7,28.7,16.4,28.3,16.4z M23.8,17.5c0,2.2-1.8,3.9-3.9,3.9c-2.2,0-3.9-1.8-3.9-3.9s1.7-3.9,3.9-3.9C22.1,13.6,23.8,15.3,23.8,17.5z"></path></g></g></svg></div></button></div></div><div class="w-css-reset" data-handle="fullscreenButton" style="display: inline-block; vertical-align: top;"><div class="w-vulcan-button-wrapper w-css-reset" style="display: inline-block; height: 34px; position: relative; vertical-align: top; width: 40px;"><button tagname="button" class="w-vulcan-v2-button w-css-reset w-css-reset-tree w-css-reset-button-important" aria-label="Fullscreen" title="Fullscreen" style="background-color: rgba(0, 0, 0, 0); box-shadow: none; cursor: pointer; height: 100%; position: relative; transition: background-color 150ms ease 0s; width: 100%;"><div class="w-vulcan-icon-wrapper" data-handle="fullscreenButton" style="box-sizing: border-box; height: 100%; position: relative; transform: scale(1.001); transition: transform 200ms ease 0s;"><svg x="0px" y="0px" viewBox="0 0 40 34" enable-background="new 0 0 40 34" focusable="false" style="fill: rgb(255, 255, 255); height: 100%; left: 0px; stroke-width: 0px; top: 0px; width: 100%;"><g><g><polyline fill="none" stroke="#ffffff" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke-miterlimit="10" points="31.4,12.6 31.4,8.7 25.8,8.7"></polyline><polyline fill="none" stroke="#ffffff" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke-miterlimit="10" points="14.7,8.7 9.1,8.7 9.1,12.6"></polyline><polyline fill="none" stroke="#ffffff" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke-miterlimit="10" points="25.8,24.8 31.4,24.8 31.4,20.9"></polyline><polyline fill="none" stroke="#ffffff" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke-miterlimit="10" points="9.1,20.9 9.1,24.8 14.7,24.8"></polyline></g><rect x="13.7" y="12.3" fill="none" stroke="#ffffff" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke-miterlimit="10" enable-background="new" width="13.3" height="8.9"></rect></g></svg></div></button></div></div></div></div><div class="w-ellipsis w-css-reset" style="height: 34px; position: relative; pointer-events: auto; white-space: nowrap; display: none;"></div></div></div></div><div class="w-foreground w-css-reset" style="height: 100%; left: 0px; pointer-events: none; position: absolute; top: 0px; width: 100%;"><div class="w-css-reset" data-handle="contextMenu" style="pointer-events: auto;"></div><div class="w-css-reset" data-handle="loadingHourglass" style="pointer-events: auto;"></div><div class="w-css-reset" data-handle="focusOutline" style="pointer-events: auto;"><div class="w-focus-outline" style="box-shadow: rgb(255, 255, 255) 0px 0px 0px 2px inset; display: none; height: 100%; left: 0px; pointer-events: none; position: absolute; right: 0px; width: 100%;"></div></div></div></div><style id="wistia_49_style" type="text/css" class="wistia_injected_style">
      #wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset{font-size:14px;}
#wistia_chrome_37 #wistia_grid_43_wrapper div.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper span.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper ul.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper li.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper label.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper fieldset.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper button.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper img.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper a.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper svg.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper p.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper a.w-css-reset{border:0;}
#wistia_chrome_37 #wistia_grid_43_wrapper h1.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:2em;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper h2.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:1.5em;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper h3.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:1.17em;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper p.w-css-reset{margin:1.4em 0;}
#wistia_chrome_37 #wistia_grid_43_wrapper a.w-css-reset{display:inline;}
#wistia_chrome_37 #wistia_grid_43_wrapper span.w-css-reset{display:inline;}
#wistia_chrome_37 #wistia_grid_43_wrapper svg.w-css-reset{display:inline;}
#wistia_chrome_37 #wistia_grid_43_wrapper ul.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased;list-style-type:none}
#wistia_chrome_37 #wistia_grid_43_wrapper ol.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased;list-style-type:none}
#wistia_chrome_37 #wistia_grid_43_wrapper li.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased;list-style-type:none}
#wistia_chrome_37 #wistia_grid_43_wrapper ul:before.w-css-reset{display:none}
#wistia_chrome_37 #wistia_grid_43_wrapper ol:before.w-css-reset{display:none}
#wistia_chrome_37 #wistia_grid_43_wrapper li:before.w-css-reset{display:none}
#wistia_chrome_37 #wistia_grid_43_wrapper ul:after.w-css-reset{display:none}
#wistia_chrome_37 #wistia_grid_43_wrapper ol:after.w-css-reset{display:none}
#wistia_chrome_37 #wistia_grid_43_wrapper li:after.w-css-reset{display:none}
#wistia_chrome_37 #wistia_grid_43_wrapper label.w-css-reset{background-attachment:scroll;background-color:transparent;background-image:none;background-position:0 0;background-repeat:no-repeat;background-size:100% 100%;float:none;outline:none}
#wistia_chrome_37 #wistia_grid_43_wrapper button.w-css-reset{background-attachment:scroll;background-color:transparent;background-image:none;background-position:0 0;background-repeat:no-repeat;background-size:100% 100%;border:0;border-radius:0;outline:none;position:static}
#wistia_chrome_37 #wistia_grid_43_wrapper img.w-css-reset{border:0;display:inline-block;vertical-align:top;border-radius:0;outline:none;position:static}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset button::-moz-focus-inner{border: 0;}
      #wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree {font-size:14px;}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree div{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree span{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree ul{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree li{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree label{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree fieldset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree button{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree img{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree a{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree svg{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree p{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree a{border:0;}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree h1{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:2em;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree h2{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:1.5em;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree h3{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:1.17em;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree p{margin:1.4em 0;}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree a{display:inline;}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree span{display:inline;}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree svg{display:inline;}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree ul{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased;list-style-type:none}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree ol{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased;list-style-type:none}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree li{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased;list-style-type:none}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree ul:before{display:none}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree ol:before{display:none}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree li:before{display:none}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree ul:after{display:none}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree ol:after{display:none}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree li:after{display:none}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree label{background-attachment:scroll;background-color:transparent;background-image:none;background-position:0 0;background-repeat:no-repeat;background-size:100% 100%;float:none;outline:none}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree button{background-attachment:scroll;background-color:transparent;background-image:none;background-position:0 0;background-repeat:no-repeat;background-size:100% 100%;border:0;border-radius:0;outline:none;position:static}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree img{border:0;display:inline-block;vertical-align:top;border-radius:0;outline:none;position:static}
#wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-tree  button::-moz-focus-inner{border: 0;}
      #wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-max-width-none-important{max-width:none!important}
      #wistia_chrome_37 #wistia_grid_43_wrapper .w-css-reset-button-important{border-radius:0!important;color:#fff!important;}
    </style></div></div><div id="wistia_grid_43_front"></div><div id="wistia_grid_43_top_inside"><div id="wistia_grid_43_top" style="height: 0px; font-size: 0px; line-height: 0px;"> </div></div><div id="wistia_grid_43_bottom_inside"><div id="wistia_grid_43_bottom" style="height: 0px; font-size: 0px; line-height: 0px;"> </div></div><div id="wistia_grid_43_left_inside"><div id="wistia_grid_43_left" style="height: 0px; font-size: 0px; line-height: 0px;"> </div></div><div id="wistia_grid_43_right_inside"><div id="wistia_grid_43_right" style="height: 0px; font-size: 0px; line-height: 0px;"> </div></div></div><div id="wistia_grid_43_below" style="height: 0px; font-size: 0px; line-height: 0px;"> </div><style id="wistia_44_style" type="text/css" class="wistia_injected_style">#wistia_grid_43_wrapper{-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box;font-family:Arial,sans-serif;font-size:14px;height:100%;position:relative;text-align:left;width:100%;}
#wistia_grid_43_wrapper *{-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box;}
#wistia_grid_43_above{position:relative;}
#wistia_grid_43_main{display:block;height:100%;position:relative;}
#wistia_grid_43_behind{height:100%;left:0;position:absolute;top:0;width:100%;}
#wistia_grid_43_center{height:100%;overflow:hidden;position:relative;width:100%;}
#wistia_grid_43_front{display:none;height:100%;left:0;position:absolute;top:0;width:100%;}
#wistia_grid_43_top_inside{position:absolute;left:0;top:0;width:100%;}
#wistia_grid_43_top{width:100%;position:absolute;bottom:0;left:0;}
#wistia_grid_43_bottom_inside{position:absolute;left:0;bottom:0;width:100%;}
#wistia_grid_43_bottom{width:100%;position:absolute;top:0;left:0;}
#wistia_grid_43_left_inside{height:100%;position:absolute;left:0;top:0;}
#wistia_grid_43_left{height:100%;position:absolute;right:0;top:0;}
#wistia_grid_43_right_inside{height:100%;right:0;position:absolute;top:0;}
#wistia_grid_43_right{height:100%;left:0;position:absolute;top:0;}
#wistia_grid_43_below{position:relative;}</style></div></div></div></div></div>

	<div style="margin-top: 32px; margin-bottom: 32px; ">
		<strong>Course information:</strong><br>
		35+ total classes • 39h 44m video • Last updated: February 2022<br>
		<span style="color: #169FE6;">★★★★★</span> 4.84 (128 Ratings) • 3,000+ Students Enrolled
	</div>

	<p><strong>I strongly believe that if you had the right teacher you could <em>master</em> computer vision and deep learning.</strong></p>

	<p>Do you think learning computer vision and deep learning has to be time-consuming, overwhelming, and complicated? Or has to involve complex mathematics and equations? Or requires a degree in computer science?</p>

	<p>That’s <em>not</em> the case.</p>

	<p>All you need to master computer vision and deep learning is for someone to explain things to you in <em>simple, intuitive</em> terms. <em>And that’s exactly what I do</em>. My mission is to change education and how complex Artificial Intelligence topics are taught.</p>

	<p>If you're serious about learning computer vision, your next stop should be PyImageSearch University, the most comprehensive computer vision, deep learning, and OpenCV course online today. Here you’ll learn how to <em>successfully</em> and <em>confidently</em> apply computer vision to your work, research, and projects. Join me in computer vision mastery.</p>

	<p><strong>Inside PyImageSearch University you'll find:</strong></p>

	<ul style="margin-left: 0px;">
		<li style="list-style: none;">✓ <strong>35+ courses</strong> on essential computer vision, deep learning, and OpenCV topics</li>
		<li style="list-style: none;">✓ 35+ Certificates of Completion</li>
		<li style="list-style: none;">✓ <strong>39h 44m</strong> on-demand video</li>
		<li style="list-style: none;">✓ <strong>Brand new courses released <em>every month</em></strong>, ensuring you can keep up with state-of-the-art techniques</li>
		<li style="list-style: none;">✓ <strong>Pre-configured Jupyter Notebooks in Google Colab</strong></li>
		<li style="list-style: none;">✓ Run all code examples in your web browser — works on Windows, macOS, and Linux (no dev environment configuration required!)</li>
		<li style="list-style: none;">✓ Access to <strong>centralized code repos for <em>all</em> 500+ tutorials</strong> on PyImageSearch</li>
		<li style="list-style: none;">✓ <strong> Easy one-click downloads</strong> for code, datasets, pre-trained models, etc.</li>
		<li style="list-style: none;">✓ Access on mobile, laptop, desktop, etc.</li>
	</ul>

	<p style="text-align: center;">
		<a target="_blank" class="button link" href="https://pyimagesearch.com/pyimagesearch-university/?utm_source=blogPost&utm_medium=bottomBanner&utm_campaign=What%27s%20next%3F%20I%20recommend" style="background-color: #6DC713; border-bottom: none;">Click here to join PyImageSearch University</a>
	</p>
</div>
<h1>Summary</h1>
<p>In this blog post I showed you why it is critical to apply Gaussian blurring prior to finding the brightest spot in an image.</p>
<p>By applying a Gaussian blur, you are averaging the pixels within a given radius of each other together. Taking the average allows you to remove high frequency noise that would have otherwise thrown off the results of the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.</span><span class="enlighter-m3">minMaxLoc</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic">cv2.minMaxLoc</code>  function.</p>
<p>Be sure to explore appropriate values for the radius of Gaussian blur. If you take too small of a value, you’ll mitigate the effects of the average and miss out on the larger, brighter regions. But if your radius is too large, you won’t detect the small bright regions.<br></p><div id="download-the-code" class="post-cta-wrap">
<div class="gpd-post-cta">
	<div class="gpd-post-cta-content">
		

			<div class="gpd-post-cta-top">
				<div class="gpd-post-cta-top-image"><img data-savepage-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/cta-source-guide-1.png?lossy=1&strip=1&webp=1" src="" alt="" class="lazyloaded" data-ll-status="loaded"><noscript><img src="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/cta-source-guide-1.png?lossy=1&strip=1&webp=1" alt="" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/cta-source-guide-1.png?lossy=1&strip=1&webp=1 410w,https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/cta-source-guide-1.png?size=126x174&lossy=1&strip=1&webp=1 126w,https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/cta-source-guide-1.png?size=252x348&lossy=1&strip=1&webp=1 252w" sizes="(max-width: 410px) 100vw, 410px" /></noscript></div>
				
				<div class="gpd-post-cta-top-title"><h4>Download the Source Code and FREE 17-page Resource Guide</h4></div>
				<div class="gpd-post-cta-top-desc"><p>Enter your email address below to get a .zip of the code and a <strong>FREE 17-page Resource Guide on Computer Vision, OpenCV, and Deep Learning.</strong> Inside you'll find my hand-picked tutorials, books, courses, and libraries to help you master CV and DL!</p></div>


			</div>

			<div class="gpd-post-cta-bottom">
				<form id="footer-cta-code" class="footer-cta" action="https://www.getdrip.com/forms/4130035/submissions" method="post" target="blank" data-drip-embedded-form="4130035">
					<input name="fields[email]" type="email" value="" placeholder="Your email address" class="form-control">

					<button type="submit">Download the code!</button>

					<div style="display: none;" aria-hidden="true"><label for="website">Website</label><br><input type="text" id="website" name="website" tabindex="-1" autocomplete="false" value=""></div>
				</form>
			</div>


		
	</div>

</div>
</div><p></p><!-- RightMessage WP -->
<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/"
    dc:identifier="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/"
    dc:title="Finding the Brightest Spot in an Image using Python and OpenCV"
    trackback:ping="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/trackback/" />
</rdf:RDF>-->
</div></article><section class="author-box"><img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=480&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=240&d=mm&r=g" src="" class="avatar avatar-240 photo lazyloaded" height="240" width="240" data-savepage-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=480&d=mm&r=g 2x" srcset="" data-ll-status="loaded"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=240&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=480&#038;d=mm&#038;r=g 2x' class='avatar avatar-240 photo' height='240' width='240' /></noscript><h4 class="author-box-title"><strong>About the Author</strong></h4><div class="author-box-content" itemprop="description"><p>Hi there, I’m Adrian Rosebrock, PhD. All too often I see developers, students, and researchers wasting their time, studying the wrong things, and generally struggling to get started with Computer Vision, Deep Learning, and OpenCV. I created this website to show you what I believe is the best possible way to get your start.</p>
</div></section><h2 class="screen-reader-text">Reader Interactions</h2><div class="single-post-nav"><a href="https://pyimagesearch.com/2014/09/22/getting-started-deep-learning-python/"><div class="single-post-nav__previous"><p>Previous Article:</p><h3>Getting Started with Deep Learning and Python</h3></div></a><a href="https://pyimagesearch.com/2014/10/13/deep-learning-amazon-ec2-gpu-python-nolearn/"><div class="single-post-nav__next"><p>Next Article:</p><h3>Deep Learning on Amazon EC2 GPU with Python and nolearn</h3></div></a></div><div class="entry-comments" id="comments"><h3>68 responses to: Finding the Brightest Spot in an Image using Python and OpenCV</h3><ol class="comment-list">
	<li class="comment even thread-even depth-1" id="comment-66241">
	<article id="article-comment-66241">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/162621ce6ade0d3433aaae3a924893df?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/162621ce6ade0d3433aaae3a924893df?s=48&d=mm&r=g" src="" class="avatar avatar-48 photo lazyloaded" height="48" width="48" data-savepage-srcset="https://secure.gravatar.com/avatar/162621ce6ade0d3433aaae3a924893df?s=96&d=mm&r=g 2x" srcset="" data-ll-status="loaded"><noscript><img alt='' src='https://secure.gravatar.com/avatar/162621ce6ade0d3433aaae3a924893df?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/162621ce6ade0d3433aaae3a924893df?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name"><a href="http://www.bitesizebio.com/profiles/jeremy-chacon" class="comment-author-link" rel="external nofollow">Jeremy</a></span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-66241" href="#comment-66241">September 29, 2014 at 11:04 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Adrian,</p>
<p>Nice tutorial. However I think there is a different approach (more similar to finding the brightest pixel) that may also work, without having to write your own method. </p>
<p>Step 1: filter the image using a Gaussian or median filter (median is best for salt-and-pepper noise)</p>
<p>Step 2: find the brightest pixel the less-robust way</p>
<p>That said, I like your method better. However, I think that usually when people learn to find peaks, they have it drilled into them to filter first, for exactly this reason!</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-66294">
	<article id="article-comment-66294">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" class="avatar avatar-48 photo lazyloaded" height="48" width="48" data-savepage-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" srcset="" data-ll-status="loaded"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-66294" href="#comment-66294">September 29, 2014 at 12:03 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Jeremy, thank you for commenting. Great point — using a filter prior to finding the brightest pixel is a good idea. Given that this is an introductory post, I think using the Gaussian blur is a better idea and easier to understand. I’m going to go back and update the post.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment even depth-3" id="comment-412395">
	<article id="article-comment-412395">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/ec93469a1489daaab44b2f4324d4c687?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/ec93469a1489daaab44b2f4324d4c687?s=48&d=mm&r=g" src="" class="avatar avatar-48 photo lazyloaded" height="48" width="48" data-savepage-srcset="https://secure.gravatar.com/avatar/ec93469a1489daaab44b2f4324d4c687?s=96&d=mm&r=g 2x" srcset="" data-ll-status="loaded"><noscript><img alt='' src='https://secure.gravatar.com/avatar/ec93469a1489daaab44b2f4324d4c687?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/ec93469a1489daaab44b2f4324d4c687?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name"><a href="http://ces.itec.kit.edu/21_ahmed.php" class="comment-author-link" rel="external nofollow">Ahmed</a></span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-412395" href="#comment-412395">December 1, 2016 at 11:41 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hello Adrian, Great to see the post! I want to  detect the hot point in my thermal Video. How can I get the exact temperature and is there any method to compare two videos according to the characteristics?<br>
Sorry to ask this, I am learning tutorials but a new one to Python. Thanks</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-4" id="comment-412714">
	<article id="article-comment-412714">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" class="avatar avatar-48 photo lazyloaded" height="48" width="48" data-savepage-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" srcset="" data-ll-status="loaded"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-412714" href="#comment-412714">December 5, 2016 at 1:49 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>If you are using the same thermal sensor to capture the temperatures (and therefore know what temperatures of various color bands are) then yes, it would be possible. This solution would involve <a target="blank" href="https://pyimagesearch.com/2014/08/04/opencv-python-color-detection/" rel="nofollow">color thresholding</a>.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-odd thread-alt depth-1" id="comment-190193">
	<article id="article-comment-190193">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/81be216abdba9946b9c8c6fee7832075?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/81be216abdba9946b9c8c6fee7832075?s=48&d=mm&r=g" src="" class="avatar avatar-48 photo lazyloaded" height="48" width="48" data-savepage-srcset="https://secure.gravatar.com/avatar/81be216abdba9946b9c8c6fee7832075?s=96&d=mm&r=g 2x" srcset="" data-ll-status="loaded"><noscript><img alt='' src='https://secure.gravatar.com/avatar/81be216abdba9946b9c8c6fee7832075?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/81be216abdba9946b9c8c6fee7832075?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">EmmaG</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-190193" href="#comment-190193">November 22, 2014 at 9:19 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hey Adrian,<br>
Nice example ! I am working on something similar like draw circle only if the bright spot found.<br>
Else no circle.One way is to use threshold, if min_val &lt; threshold then draw rectangle. But in my case i am not able to decide threshold values between 0-1.my min max values are something like 221462064.0 and 758624512.0 respectively.I want to work this for other images too.<br>
Can u show how can i do it or may be some other method to do it?</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-191996">
	<article id="article-comment-191996">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" class="avatar avatar-48 photo lazyloaded" height="48" width="48" data-savepage-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" srcset="" data-ll-status="loaded"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-191996" href="#comment-191996">November 23, 2014 at 7:41 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Emma. You could always scale your values into the range [0, 1] first by dividing my the maximum value that occurs in your image. But not really wouldn’t be a fix. It seems like you are trying to accomplish some sort of adaptive thresholding based on the brightest parts of the image. Without seeing your images (and getting more details), I can’t really provide a solution to the problem.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-even depth-1" id="comment-284671">
	<article id="article-comment-284671">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/2e7cedf43568adec7b1f6a2065dbd154?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/2e7cedf43568adec7b1f6a2065dbd154?s=48&d=mm&r=g" src="" class="avatar avatar-48 photo lazyloaded" height="48" width="48" data-savepage-srcset="https://secure.gravatar.com/avatar/2e7cedf43568adec7b1f6a2065dbd154?s=96&d=mm&r=g 2x" srcset="" data-ll-status="loaded"><noscript><img alt='' src='https://secure.gravatar.com/avatar/2e7cedf43568adec7b1f6a2065dbd154?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/2e7cedf43568adec7b1f6a2065dbd154?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Azrael</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-284671" href="#comment-284671">March 7, 2015 at 6:57 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hello Adrian,<br>
Thanks for the post.<br>
Can you tell me how to find out the darkest region in the image, but only within the circle(eye)?<br>
And do you have any thoughts on using kernels to find the darkest and brightest regions of the image? How would you do that?<br>
I believe using a kernel would greatly help in removing any errors.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-284672">
	<article id="article-comment-284672">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" class="avatar avatar-48 photo lazyloaded" height="48" width="48" data-savepage-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" srcset="" data-ll-status="loaded"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-284672" href="#comment-284672">March 7, 2015 at 7:15 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Azrael, to find the darkest region of the image simply take a look at the <code>minVal</code> and <code>minLoc</code> values. And to only find the regions within the actual eye, you just need to specify the ROI (Region of Interest) that you want to investigate — which is in this case the eye. Take a look at <a target="blank" href="https://pyimagesearch.com/2014/01/20/basic-image-manipulations-in-python-and-opencv-resizing-scaling-rotating-and-cropping/" rel="nofollow">this</a> blog post on OpenCV basics to learn how to crop the image. You can then take this cropped image and find the min/max values.</p>
<p>Also, a Gaussian kernel (for blurring) has already been applied (Line 28) to the image prior to finding the min/max values. This helps reduce noise and improve results.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-odd thread-alt depth-1" id="comment-295727">
	<article id="article-comment-295727">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/860fec81c0a0dc29715326b9b201bf92?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/860fec81c0a0dc29715326b9b201bf92?s=48&d=mm&r=g" src="" class="avatar avatar-48 photo lazyloaded" height="48" width="48" data-savepage-srcset="https://secure.gravatar.com/avatar/860fec81c0a0dc29715326b9b201bf92?s=96&d=mm&r=g 2x" srcset="" data-ll-status="loaded"><noscript><img alt='' src='https://secure.gravatar.com/avatar/860fec81c0a0dc29715326b9b201bf92?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/860fec81c0a0dc29715326b9b201bf92?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Tuhin</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-295727" href="#comment-295727">March 24, 2015 at 9:53 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>If I want to find the mean intensity of the brightest region of an image</p>
<p> then how would I do that ??</p>
<p>Thankx in advance</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-295744">
	<article id="article-comment-295744">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" class="avatar avatar-48 photo lazyloaded" height="48" width="48" data-savepage-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" srcset="" data-ll-status="loaded"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-295744" href="#comment-295744">March 24, 2015 at 10:09 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Tuhin. If you want to find the mean intensity of the brightest region of the image, you could use <code>cv2.minMaxLoc</code> as I did in the example. Then you would extract an <em>M x N</em> pixel region surrounding the brightest region. And then call <code>cv2.mean</code> on that region — that will give you the mean intensity of the brightest region.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment even depth-3" id="comment-295768">
	<article id="article-comment-295768">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/860fec81c0a0dc29715326b9b201bf92?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/860fec81c0a0dc29715326b9b201bf92?s=48&d=mm&r=g" src="" class="avatar avatar-48 photo lazyloaded" height="48" width="48" data-savepage-srcset="https://secure.gravatar.com/avatar/860fec81c0a0dc29715326b9b201bf92?s=96&d=mm&r=g 2x" srcset="" data-ll-status="loaded"><noscript><img alt='' src='https://secure.gravatar.com/avatar/860fec81c0a0dc29715326b9b201bf92?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/860fec81c0a0dc29715326b9b201bf92?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Tuhin</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-295768" href="#comment-295768">March 24, 2015 at 10:40 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>How should I extract MxN region ? </p>
<p>How to find the values of M an N?</p>
<p>Thanx again!!</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-4" id="comment-295797">
	<article id="article-comment-295797">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-295797" href="#comment-295797">March 24, 2015 at 11:21 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>You need to determine the values of M and N yourself. For example, you could extract a 20 x 20 pixel region, a 10 x 10 pixel region, etc. That decision is entirely up to you. Take a look at <a target="blank" href="https://pyimagesearch.com/2014/01/20/basic-image-manipulations-in-python-and-opencv-resizing-scaling-rotating-and-cropping/" rel="nofollow">this</a> post to learn more about cropping and extracting regions from images. I would also suggest taking a look a my book, <a target="blank" href="https://pyimagesearch.com/practical-python-opencv/" rel="nofollow">Practical Python and OpenCV</a>. It will definitely help jumpstart your OpenCV education! Cheers.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-even depth-1" id="comment-295802">
	<article id="article-comment-295802">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/860fec81c0a0dc29715326b9b201bf92?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/860fec81c0a0dc29715326b9b201bf92?s=48&d=mm&r=g" src="" class="avatar avatar-48 photo lazyloaded" height="48" width="48" data-savepage-srcset="https://secure.gravatar.com/avatar/860fec81c0a0dc29715326b9b201bf92?s=96&d=mm&r=g 2x" srcset="" data-ll-status="loaded"><noscript><img alt='' src='https://secure.gravatar.com/avatar/860fec81c0a0dc29715326b9b201bf92?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/860fec81c0a0dc29715326b9b201bf92?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Tuhin</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-295802" href="#comment-295802">March 24, 2015 at 11:29 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hey!! thankx a bunch!!!</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->

	<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-336462">
	<article id="article-comment-336462">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/2122da97bdc71a671ed2e621f867a3c8?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/2122da97bdc71a671ed2e621f867a3c8?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/2122da97bdc71a671ed2e621f867a3c8?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/2122da97bdc71a671ed2e621f867a3c8?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/2122da97bdc71a671ed2e621f867a3c8?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/2122da97bdc71a671ed2e621f867a3c8?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/2122da97bdc71a671ed2e621f867a3c8?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Miash</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-336462" href="#comment-336462">July 16, 2015 at 5:20 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Sorry to ask stupid question, because i’m a newbie in python and opencv…<br>
I would like to ask if the method mentioned above can be applied to a live feed video in the previous tutorial “Accessing the Raspberry Pi Camera with OpenCV and Python”.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor even depth-2" id="comment-336479">
	<article id="article-comment-336479">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-336479" href="#comment-336479">July 16, 2015 at 6:27 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>It certainly can! You just need to update the <a target="blank" href="https://pyimagesearch.com/2015/03/30/accessing-the-raspberry-pi-camera-with-opencv-and-python/" rel="nofollow">Accessing Raspberry Pi Camera</a> code, specifically the <code>for</code> loop where the frames are being accessed, to apply the techniques proposed in this post.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment odd alt depth-3" id="comment-414556">
	<article id="article-comment-414556">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/fadd1580a79159c7255327f54132c566?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/fadd1580a79159c7255327f54132c566?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/fadd1580a79159c7255327f54132c566?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/fadd1580a79159c7255327f54132c566?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/fadd1580a79159c7255327f54132c566?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/fadd1580a79159c7255327f54132c566?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/fadd1580a79159c7255327f54132c566?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Vishal</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-414556" href="#comment-414556">December 28, 2016 at 7:20 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hey Adrian. Could you please explain in detail on how to set this  code up for a live video tracking ??</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor even depth-4" id="comment-414828">
	<article id="article-comment-414828">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-414828" href="#comment-414828">December 31, 2016 at 1:30 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>It depends on what type of camera you are using (webcam or Raspberry Pi camera module), but the gist is that you should <a target="blank" href="https://pyimagesearch.com/2016/01/04/unifying-picamera-and-cv2-videocapture-into-a-single-class-with-opencv/" rel="nofollow">start with this blog post</a> and then use it as a template to access your webcam. From there, detect the brightest region in each frame.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment odd alt thread-even depth-1" id="comment-345976">
	<article id="article-comment-345976">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/abc9a89829d45f25f324be90c126e538?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/abc9a89829d45f25f324be90c126e538?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/abc9a89829d45f25f324be90c126e538?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/abc9a89829d45f25f324be90c126e538?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/abc9a89829d45f25f324be90c126e538?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/abc9a89829d45f25f324be90c126e538?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/abc9a89829d45f25f324be90c126e538?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">vin</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-345976" href="#comment-345976">August 14, 2015 at 6:23 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>hi adrian!</p>
<p>i understand why blurring works in this specific instance. would there be any instances where you simply filtered by size? (eg, find pixels above a certain value and then simply ignore anything less than N pixels).</p>
<p>thanks!</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor even depth-2" id="comment-346168">
	<article id="article-comment-346168">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-346168" href="#comment-346168">August 15, 2015 at 6:27 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Certainly! A great example is in <a target="blank" href="https://pyimagesearch.com/2015/05/04/target-acquired-finding-targets-in-drone-and-quadcopter-video-streams-using-python-and-opencv/" rel="nofollow">this post on target detection</a>. Notice how I ignore any regions of the image that are smaller than <em>25×25</em> pixels.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-380206">
	<article id="article-comment-380206">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/4b26cd4c9fc9c35c96a270999085bbc3?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/4b26cd4c9fc9c35c96a270999085bbc3?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/4b26cd4c9fc9c35c96a270999085bbc3?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/4b26cd4c9fc9c35c96a270999085bbc3?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/4b26cd4c9fc9c35c96a270999085bbc3?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/4b26cd4c9fc9c35c96a270999085bbc3?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/4b26cd4c9fc9c35c96a270999085bbc3?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Brian</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-380206" href="#comment-380206">November 22, 2015 at 12:10 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Adrian,<br>
I tried the above code verbatim but encountered the following error:<br>
AttributeError: ‘Nonetype’ object has no attribute ‘copy’</p>
<p>Why not use:  orig = image?</p>
<p>Also, must the image be PNG format or will any other format work such as JPG, BMP, etc.?</p>
<p>Thanks,<br>
-Brian</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor even depth-2" id="comment-380378">
	<article id="article-comment-380378">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-380378" href="#comment-380378">November 23, 2015 at 6:39 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>If you’re getting an error related to the image being <code>None</code>, then your image is not being properly loaded from disk via the <code>cv2.imread</code> function <em>or</em> the path supplied the <code>cv2.imread</code> is not valid. OpenCV comes with built-in support for reading BMP images, but you need to install the appropriate JPEG and PNG libraries for your system prior to compiling and installing OpenCV.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment odd alt depth-3" id="comment-413628">
	<article id="article-comment-413628">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/fadd1580a79159c7255327f54132c566?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/fadd1580a79159c7255327f54132c566?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/fadd1580a79159c7255327f54132c566?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/fadd1580a79159c7255327f54132c566?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/fadd1580a79159c7255327f54132c566?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/fadd1580a79159c7255327f54132c566?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/fadd1580a79159c7255327f54132c566?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Vishal</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-413628" href="#comment-413628">December 16, 2016 at 12:41 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>can you explain on how to remove debug this error now ??</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor even depth-4" id="comment-413784">
	<article id="article-comment-413784">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-413784" href="#comment-413784">December 18, 2016 at 8:47 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>What is your error?</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment odd alt thread-even depth-1" id="comment-380230">
	<article id="article-comment-380230">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/4b26cd4c9fc9c35c96a270999085bbc3?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/4b26cd4c9fc9c35c96a270999085bbc3?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/4b26cd4c9fc9c35c96a270999085bbc3?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/4b26cd4c9fc9c35c96a270999085bbc3?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/4b26cd4c9fc9c35c96a270999085bbc3?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/4b26cd4c9fc9c35c96a270999085bbc3?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/4b26cd4c9fc9c35c96a270999085bbc3?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Brian</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-380230" href="#comment-380230">November 22, 2015 at 2:37 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Adrian,<br>
Great tutorial!  </p>
<p>When I copied your code verbatim I encountered an error with image.copy().  I was able to get around it by simply replacing this line of code with:  orig = image.  I’m using OpenCV 3.0.0 so I’m not sure if that was the issue.  I thought I should post this to help anyone else who might be having the same issue.  </p>
<p>Digging a little deeper, I didn’t quite understand the purpose of making a copy of the image.  I commented out the image.copy lines of code completely and the program seems to work just fine.  Can you add some detail as to what the image copy was for?</p>
<p>One final note, I’d would highly recommend adding to this tutorial:<br>
cv2.imshow(“Gray”, gray)</p>
<p>This certainly helped me to understand what was happening during the Gaussian blur process as the radius changes.  </p>
<p>Thanks again for the great tutorials!<br>
-Brian</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor even depth-2" id="comment-380376">
	<article id="article-comment-380376">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-380376" href="#comment-380376">November 23, 2015 at 6:36 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>The <code>.copy()</code> method is used to make a deep copy (rather than a shallow copy) of the image. This allows us to “draw” the circles on two separate images and display our results. If you’re using this code in an image processing pipeline, you can certainly leave it out.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-391135">
	<article id="article-comment-391135">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/2bda2649c8ce3fd97b6cc97c7d4346a4?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/2bda2649c8ce3fd97b6cc97c7d4346a4?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/2bda2649c8ce3fd97b6cc97c7d4346a4?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/2bda2649c8ce3fd97b6cc97c7d4346a4?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/2bda2649c8ce3fd97b6cc97c7d4346a4?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/2bda2649c8ce3fd97b6cc97c7d4346a4?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/2bda2649c8ce3fd97b6cc97c7d4346a4?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Angel John Babasa</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-391135" href="#comment-391135">March 1, 2016 at 1:33 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi! Is it possible to detect multiple bright spots in an image and find their pixel coordinates? thanks!</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor even depth-2" id="comment-391188">
	<article id="article-comment-391188">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-391188" href="#comment-391188">March 1, 2016 at 3:41 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Indeed, it is possible! I plan on covering it in a future blog post, but in the meantime, take a look at <a target="blank" href="http://scikit-image.org/docs/dev/auto_examples/plot_peak_local_max.html" rel="nofollow">this tutorial with scikit-image</a>.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment odd alt depth-3" id="comment-395082">
	<article id="article-comment-395082">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/b11dbfebc37ab49aa29057df563dfb68?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/b11dbfebc37ab49aa29057df563dfb68?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/b11dbfebc37ab49aa29057df563dfb68?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/b11dbfebc37ab49aa29057df563dfb68?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/b11dbfebc37ab49aa29057df563dfb68?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/b11dbfebc37ab49aa29057df563dfb68?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/b11dbfebc37ab49aa29057df563dfb68?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">TimTom</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-395082" href="#comment-395082">April 16, 2016 at 8:02 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>I’d be really interested in such a tutorial as well.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-even depth-1" id="comment-391922">
	<article id="article-comment-391922">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">YaddyVirus</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-391922" href="#comment-391922">March 13, 2016 at 10:43 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Ardian! Nice tutorial there, really helpful tutorial. I am working on a project that requires a raspberry pi doing image processing and finding a traffic light. Once its been found, monitor it until it goes off, and as soon as it does, send appropriate commands to the Arduino(which controls motors). Now since at the moment I don’t have a RPi, I’m writing the code on my PC(Windows 8.1), the PC version of my code, detects a light from the frames captured from my Webcam, and when the light goes off, display a message on the screen, when it comes back on, display the corresponding message.<br>
I plan to convert the video captured from the webcam into greyscale and then finding the brightest spot(hopefully the light). Now can you please tell me how to display a message (and send command to Arduino too of course), based upon the detected status of the light?<br>
I’m new to Both OpenCV and Python, but I’ve been coding in other languages so thats not a problem. I’ve literally spent entire nights reading up the OpenCV documentation(I was initially writing the code in C++, but realized that I should switch to python as ultimately I have to use this on a RPi) and writing code. I’m in real need if help!<br>
Thanks!</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-391924">
	<article id="article-comment-391924">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-391924" href="#comment-391924">March 13, 2016 at 11:11 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Your project sounds very cooL! However, I have never done any Arduino-based development before, so I’m unfortunately not the right person to ask regarding this question. In the future, I’ll try to do more GPIO and Arduino posts that cover computer vision topics as well.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment even depth-3" id="comment-391939">
	<article id="article-comment-391939">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">YaddyVirus</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-391939" href="#comment-391939">March 13, 2016 at 3:47 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Okay fine, no problem. Anyways if not Arduino based, can you tell me how to display the corresponding  message depending upon the status of the brightest spot(the light being on or off) simply in python?</p>
<p>Thanks again for such a nice tutorial.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment odd alt depth-4" id="comment-391940">
	<article id="article-comment-391940">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">YaddyVirus</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-391940" href="#comment-391940">March 13, 2016 at 4:16 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>And yeah, is there any way to make a trackbar to control the Guassian blur radius? Like there are in C++ Visual Studio tutorials for OpenCV object detection based on color where they convert the image to HSV and then control the H,S and V values with trackbars until they get the required binary output in the resultant window. I’m thinking that controlling the Guassian blur with a trackbar would be a good idea as in my case I’m working with a live video feed from my webcam. What do you think?<br>
Thanks</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-odd thread-alt depth-1" id="comment-391942">
	<article id="article-comment-391942">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">YaddyVirus</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-391942" href="#comment-391942">March 13, 2016 at 5:14 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Adrian! Sorry to harass you with so many comments, but I thought I’ll post back with my most recent experiment towards my project. Okay so I did a bit of modification to your code and got the bright spot detection to work from my webcam feed. I ran the test in a room brightly lit and detected LEDs of a spare webcam I had lying around. It was quite successful(just while testing with some extreme angles it detected the collar of my white shirt as the brightest spot). Any ways, since I have to do the actual detection in sunlight, will this method work? I mean I don’t want my robot to see any other “bright spots” other than the traffic light just before a race is about to start. I can’t experiment right now as its night here in world.<br>
Also, in my previous comment on my previous reply I thought that using a trackbar for applying Guassian blur would be better as it would give me more control over what gets detected. Can that be done? (For some reason I saw that that comment has disappeared.)</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-392007">
	<article id="article-comment-392007">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-392007" href="#comment-392007">March 14, 2016 at 3:27 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>All comments have to be manually approved by me, so please make sure you consolidate your comments whenever possible.</p>
<p>To address your questions, yes, you can create track-bars to manually control the Gaussian blur radius. Please see the <a target="blank" href="https://github.com/jrosebr1/imutils/blob/master/bin/range-detector" rel="nofollow">range-detector</a> script for an example of using a trackbar.</p>
<p>As for changing your lighting conditions, that is entirely dependent on your environment. You won’t know until you try. But in short, if there is a brighter spot in your image (brighter than the LEDs), then yes, the code will (incorrectly) detect the brighter object. In that case, you need to build extra logic into your code to prune the false-positive cases. I would suggest looking into color thresholding and contour properties (solidity, extent, aspect ratio, etc.) to prune these regions.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment even depth-3" id="comment-392068">
	<article id="article-comment-392068">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">YaddyVirus</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-392068" href="#comment-392068">March 15, 2016 at 9:31 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Well thanks for the reply. So what if I convert the image to HSV instead of grayscale and then adjust the HSV values and apply hough transform to find circles? Once all circles are found, find the brightest circle using this method ( but this method only works for single channel images if I’m right.)</p>
<p>Also, which language you suggest using for this project on the Raspberry Pi? C++ or Python? I’ve written the code for both languages (to the point where I can find out the required object by thresholding the image.)<br>
Thanks! You’re a great help buddy!</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-4" id="comment-392089">
	<article id="article-comment-392089">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-currentsrc="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo error" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" data-savepage-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" srcset="" data-ll-status="error"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-392089" href="#comment-392089">March 15, 2016 at 4:28 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>If you can use the HSV color space to help filter your object, then yes, absolutely do that. You’ll likely need to experiment with this approach and see if you can filter each channel or use something like <a target="blank" href="https://pyimagesearch.com/2014/08/04/opencv-python-color-detection/" rel="nofollow">cv2.inRange</a> to filter for a specific color. And yes, this method is intended for use on single channels, but if you can filter out extraneous regions and then only examine the Value channel (which will store the intensity of the color), then you can get around this problem.</p>
<p>As for using Python or C++, I nearly always suggest prototyping in Python and then only coding in C++ if absolutely necessary.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment even depth-5" id="comment-392123">
	<article id="article-comment-392123">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">YaddyVirus</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-392123" href="#comment-392123">March 16, 2016 at 1:15 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Very well, sounds like a plan. Now the only question that remains is , since I don’t know how to do this in either Python or C++, how do I display a message on the screen once the desired circle(the traffic light) goes off(or comes back on)?</p>
<p>And yeah what to you mean by “coding in C++ if absolutely necessary”.</p>
<p>Thanks!</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-5" id="comment-392149">
	<article id="article-comment-392149">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-392149" href="#comment-392149">March 16, 2016 at 8:10 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>What do you mean by “display a message on the screen”? You could use the <code>print</code> statement/function to write text to the terminal or you could use <code>cv2.putText</code> to draw a message on the actual image.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->

	<li class="comment even depth-5" id="comment-392267">
	<article id="article-comment-392267">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">YaddyVirus</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-392267" href="#comment-392267">March 18, 2016 at 8:15 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Well displaying a message in the sense that as soon as the detected spot goes black in my binary image, show a message on the screen. What’s the statement for that?<br>
Thanks!</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-5" id="comment-392269">
	<article id="article-comment-392269">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-392269" href="#comment-392269">March 18, 2016 at 9:12 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Please see my previous comment — use either the <code>print</code> statement/function or <code>cv2.putText</code>.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->

	<li class="comment even depth-5" id="comment-392286">
	<article id="article-comment-392286">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/22680f3d6822528385913f297fc58650?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">YaddyVirus</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-392286" href="#comment-392286">March 18, 2016 at 5:25 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Yeah that print statement is fine.<br>
But there should be some condition checking statement there too, right? Like if (*as long as light is detected*). How do I check for the “visibility” of the light? Or, if no conditional check is required, where do I write the print statement? </p>
<p>P.S – sorry I’m still new to Python, so I’m not much proficient with the basics yet, but I’m learning! All thanks to you!</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-5" id="comment-392330">
	<article id="article-comment-392330">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-392330" href="#comment-392330">March 19, 2016 at 9:14 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Yes, a conditional is required to determine if there is sufficient light. You’ll need to program that logic yourself. Normally you would be looking for a large enough region in an image (based on width and height) that has the pixel intensity you’re looking for. If you’re still getting used to Python + OpenCV, you should absolutely work through <a target="blank" href="https://pyimagesearch.com/practical-python-opencv/" rel="nofollow">Practical Python and OpenCV</a> to help you get up to speed quickly.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-even depth-1" id="comment-396344">
	<article id="article-comment-396344">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/166a012e3eb65b013943a032e09af4ef?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/166a012e3eb65b013943a032e09af4ef?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/166a012e3eb65b013943a032e09af4ef?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/166a012e3eb65b013943a032e09af4ef?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/166a012e3eb65b013943a032e09af4ef?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Sanira</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-396344" href="#comment-396344">May 1, 2016 at 1:15 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Adrian ,</p>
<p>Great tutorial..!! thanks a lot for sharing your knowledge. 🙂</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-396388">
	<article id="article-comment-396388">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-396388" href="#comment-396388">May 1, 2016 at 3:07 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>I’m glad you found it useful Sanira! 🙂</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-odd thread-alt depth-1" id="comment-408554">
	<article id="article-comment-408554">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/bff0b654cd01f06a757a47f9f8de53df?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/bff0b654cd01f06a757a47f9f8de53df?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/bff0b654cd01f06a757a47f9f8de53df?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/bff0b654cd01f06a757a47f9f8de53df?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/bff0b654cd01f06a757a47f9f8de53df?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Richie Close</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-408554" href="#comment-408554">October 20, 2016 at 5:42 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Adrian</p>
<p>Thanks for the tutorial – a great introduction to this area!  I’ve a couple of questions.<br>
What does the radius value refer to?  Is it pixels?<br>
What would be the best way to find the 6 (for example) brights area’s on an image?  Could you set a brightness target threshold and search for that (along with the radius value)?</p>
<p>Thanks again</p>
<p>Richie</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-408563">
	<article id="article-comment-408563">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-408563" href="#comment-408563">October 20, 2016 at 8:38 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>The radius is the size (in pixels) of the Gaussian blur. The smaller the radius, the less blur. The larger the radius, the more blur. As for finding <em>multiple</em> bright spots in an image I actually have a blog post scheduled for that. It will be published late October/early November so be sure to keep an eye out!</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-even depth-1" id="comment-420109">
	<article id="article-comment-420109">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/5c421169e6287fbb8fa1aa8a542f67aa?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/5c421169e6287fbb8fa1aa8a542f67aa?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/5c421169e6287fbb8fa1aa8a542f67aa?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/5c421169e6287fbb8fa1aa8a542f67aa?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/5c421169e6287fbb8fa1aa8a542f67aa?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">kiran</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-420109" href="#comment-420109">March 13, 2017 at 5:05 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>in the cursor control system,<br>
the first step was to have robust hand skin detection.<br>
the image frames from webcam i have converted to HSV and ycbcr colour space,applied morphological operations on individual hsv and ycbcr thresholded images.<br>
and combined both images.<br>
thing is that i need to detect only hand skin rest such as face and some body part need to be removed ,<br>
could you suggest me how to remove non- hand skin regions.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-420136">
	<article id="article-comment-420136">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-420136" href="#comment-420136">March 13, 2017 at 12:10 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>I would suggest detecting the hand first. You might need to apply other methods than just color thresholding such as object detection. I would also suggest contour extraction and filtering only the hand regions.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-odd thread-alt depth-1" id="comment-438632">
	<article id="article-comment-438632">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/576793c5b05cd0332ae39a9e7e1e3c93?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/576793c5b05cd0332ae39a9e7e1e3c93?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/576793c5b05cd0332ae39a9e7e1e3c93?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/576793c5b05cd0332ae39a9e7e1e3c93?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/576793c5b05cd0332ae39a9e7e1e3c93?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Saurav</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-438632" href="#comment-438632">October 25, 2017 at 10:03 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>hey thanks for the tutorial but i want to know how will you issue the command in cmd like how will you give arguments.<br>
sorry for the question but i m a beginner.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrianr odd alt depth-2" id="comment-438649">
	<article id="article-comment-438649">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/770b7b7f983d2829a836d9d48af8117c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/770b7b7f983d2829a836d9d48af8117c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/770b7b7f983d2829a836d9d48af8117c?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/770b7b7f983d2829a836d9d48af8117c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/770b7b7f983d2829a836d9d48af8117c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-438649" href="#comment-438649">October 25, 2017 at 12:45 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Saurav — You’re welcome. I suggest you read <a href="https://pyimagesearch.com/2018/03/12/python-argparse-command-line-arguments/" target="_blank" rel="nofollow">this tutorial on command line arguments</a>.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-even depth-1" id="comment-453440">
	<article id="article-comment-453440">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/0b9447092003d12d3c2da2ec089443d8?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/0b9447092003d12d3c2da2ec089443d8?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/0b9447092003d12d3c2da2ec089443d8?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/0b9447092003d12d3c2da2ec089443d8?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/0b9447092003d12d3c2da2ec089443d8?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Moorthy</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-453440" href="#comment-453440">March 18, 2018 at 5:41 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>i have one small help how to find the crop the brightest region on your code please help me .</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-453578">
	<article id="article-comment-453578">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-453578" href="#comment-453578">March 19, 2018 at 5:14 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>You can extract the region using basic NumPy array slicing.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-odd thread-alt depth-1" id="comment-473951">
	<article id="article-comment-473951">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/83db3df7888a9f5291baae38437ad3b0?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/83db3df7888a9f5291baae38437ad3b0?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/83db3df7888a9f5291baae38437ad3b0?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/83db3df7888a9f5291baae38437ad3b0?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/83db3df7888a9f5291baae38437ad3b0?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name"><a data-savepage-href="http://NA" href="http://na/" class="comment-author-link" rel="external nofollow">Nayan</a></span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-473951" href="#comment-473951">August 11, 2018 at 12:57 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>i like to extract the logo from an image. can i apply this Gaussian blur method to get the logo. Or is there any other method.</p>
<p>I will be highly grateful if you please let me know.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-474434">
	<article id="article-comment-474434">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-474434" href="#comment-474434">August 15, 2018 at 9:25 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>You should look into <a target="blank" href="https://pyimagesearch.com/2018/05/14/a-gentle-guide-to-deep-learning-object-detection/">object detection methods</a> as well as keypoint detection and keypoint matching. I would suggest reading through <a target="blank" href="https://pyimagesearch.com/practical-python-opencv/">Practical Python and OpenCV</a> to learn more about keypoint matching and then <a target="blank" href="https://pyimagesearch.com/deep-learning-computer-vision-python-book/">Deep Learning for Computer Vision with Python</a> to learn more about deep learning-based object detection.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-even depth-1" id="comment-476420">
	<article id="article-comment-476420">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/998a183f5ef3aab32a5378d49e0b9a47?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/998a183f5ef3aab32a5378d49e0b9a47?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/998a183f5ef3aab32a5378d49e0b9a47?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/998a183f5ef3aab32a5378d49e0b9a47?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/998a183f5ef3aab32a5378d49e0b9a47?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Manavendra</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-476420" href="#comment-476420">September 3, 2018 at 1:32 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Adrian,<br>
I am working on a project using rasberrypi and rasberrypi camera  where I am blinking a led at certain frequency and their are other Led lights which are continuously on ,so is it possible to frame by frame check (process) the frames simultaneously and circle the blinking led in the video as the video is static ( the position of the led is not changing for 1 complete video ) I am going to keep the frequency of the led and the fps of the video equal so  checking (processing) frames will not be a problem , as I think the led will locate maxval in one frame and minval in second frame for the same location so is there any method to locate the blinking led with highlighting circle in real time .<br>
And last but not the least thanks for such great tutorials<br>
I would be really grateful if you you can help me for the above problem</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-476703">
	<article id="article-comment-476703">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-476703" href="#comment-476703">September 5, 2018 at 8:53 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>If the position of the LED is fixed and non-moving why not just monitor that specific area of the video frame? You could compute the mean value of the region and if it’s above a pre-defined threshold the LED is “on”, otherwise it’s “off”.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment even depth-3" id="comment-476925">
	<article id="article-comment-476925">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/998a183f5ef3aab32a5378d49e0b9a47?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/998a183f5ef3aab32a5378d49e0b9a47?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/998a183f5ef3aab32a5378d49e0b9a47?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/998a183f5ef3aab32a5378d49e0b9a47?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/998a183f5ef3aab32a5378d49e0b9a47?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Manavendra</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-476925" href="#comment-476925">September 7, 2018 at 12:50 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>The position of the led is fixed but it’s unknown to the user initially and we have to spot the blinking led in all other lights using pi camera…..  that’s the project all about</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-4" id="comment-477502">
	<article id="article-comment-477502">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-477502" href="#comment-477502">September 11, 2018 at 8:34 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Got it, I understand now. One way to frame this problem is via <a target="blank" href="https://pyimagesearch.com/2015/06/01/home-surveillance-and-motion-detection-with-the-raspberry-pi-python-and-opencv/">motion detection/background subtraction</a>. Since all LEDs will be “on” and only the blinking one changes, you can monitor the frames for changes in background which in turn give you the ROI of the blinking LED. I hope that helps!</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-odd thread-alt depth-1" id="comment-483989">
	<article id="article-comment-483989">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/344ff1d81f468dbe5a03dd72f0db908c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/344ff1d81f468dbe5a03dd72f0db908c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/344ff1d81f468dbe5a03dd72f0db908c?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/344ff1d81f468dbe5a03dd72f0db908c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/344ff1d81f468dbe5a03dd72f0db908c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">shincheng</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-483989" href="#comment-483989">October 26, 2018 at 5:46 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>$ python bright.py –image images/retina-noise.png –step 41</p>
<p>small typo<br>
 –step 41 should be –radius 41</p>
<p>nice introduction</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-484469">
	<article id="article-comment-484469">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-484469" href="#comment-484469">October 29, 2018 at 1:42 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Thank you for pointing that out! I’ve updated the post 🙂</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-even depth-1" id="comment-497554">
	<article id="article-comment-497554">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/ae4ad8488929a4b840bb694c75b89a2f?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/ae4ad8488929a4b840bb694c75b89a2f?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/ae4ad8488929a4b840bb694c75b89a2f?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/ae4ad8488929a4b840bb694c75b89a2f?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/ae4ad8488929a4b840bb694c75b89a2f?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">esha</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-497554" href="#comment-497554">January 23, 2019 at 1:10 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>hello sir<br>
how can we extract the region of an image consist of brightest pixels in its dark channel.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-497870">
	<article id="article-comment-497870">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-497870" href="#comment-497870">January 25, 2019 at 7:32 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>You could use NumPy array slicing to extract the region — or perhaps I’m misunderstanding your question?</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-odd thread-alt depth-1" id="comment-498162">
	<article id="article-comment-498162">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/ae4ad8488929a4b840bb694c75b89a2f?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/ae4ad8488929a4b840bb694c75b89a2f?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/ae4ad8488929a4b840bb694c75b89a2f?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/ae4ad8488929a4b840bb694c75b89a2f?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/ae4ad8488929a4b840bb694c75b89a2f?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">esha</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-498162" href="#comment-498162">January 28, 2019 at 1:17 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>actually sir i want a region in an image consisits of brighest pixels in its dark channel.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->

	<li class="comment odd alt thread-even depth-1" id="comment-510930">
	<article id="article-comment-510930">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/ad75c12ee548d678fc5116424a7a32ec?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/ad75c12ee548d678fc5116424a7a32ec?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/ad75c12ee548d678fc5116424a7a32ec?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/ad75c12ee548d678fc5116424a7a32ec?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/ad75c12ee548d678fc5116424a7a32ec?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Isaac</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-510930" href="#comment-510930">April 3, 2019 at 2:11 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Adrian, thanks for this. I have a question though. How do i locate the center of the  brightest “spot” within the cirlce and possible use a dot to visually indicate that?</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor even depth-2" id="comment-511111">
	<article id="article-comment-511111">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-511111" href="#comment-511111">April 4, 2019 at 1:15 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>You would compute the centroid of the circle and then use the “cv2.circle” function to draw the dot. I cover both of those techniques inside <a target="blank" href="https://pyimagesearch.com/practical-python-opencv/">Practical Python and OpenCV.</a> I would highly suggest you start there.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-523120">
	<article id="article-comment-523120">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/a33a90acafa601d38ad4b01f7a04d3bf?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/a33a90acafa601d38ad4b01f7a04d3bf?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/a33a90acafa601d38ad4b01f7a04d3bf?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/a33a90acafa601d38ad4b01f7a04d3bf?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/a33a90acafa601d38ad4b01f7a04d3bf?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Nitin rai</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-523120" href="#comment-523120">June 26, 2019 at 11:43 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hey i applied same trick to calculate overall brightness of an image..  i hope this link<br>
<a href="https://github.com/imneonizer/How-to-find-if-an-image-is-bright-or-dark/blob/master/README.md" rel="nofollow ugc">https://github.com/imneonizer/How-to-find-if-an-image-is-bright-or-dark/blob/master/README.md</a><br>
 would help you out understanding the same.<br>
In this blog i have explained how i divided the image into smaller segments and find brightness in those segments and finally took the average of all those calculated brightness to get the brightness level of image<br>
It can easily tell which images are brighter and which are dark.<br>
Hope it could help you with something.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->

	<li class="comment even thread-even depth-1" id="comment-765345">
	<article id="article-comment-765345">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" data-savepage-src="https://secure.gravatar.com/avatar/ec5d62c3ab0d6708db1848e3ffc28882?s=48&d=mm&r=g" src="" data-lazy-srcset="https://secure.gravatar.com/avatar/ec5d62c3ab0d6708db1848e3ffc28882?s=96&d=mm&r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/ec5d62c3ab0d6708db1848e3ffc28882?s=48&d=mm&r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/ec5d62c3ab0d6708db1848e3ffc28882?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/ec5d62c3ab0d6708db1848e3ffc28882?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Chong You Wang</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-765345" href="#comment-765345">March 3, 2020 at 7:48 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Thanks so much for the tutorial. I have some question. If I want to detect multiple bright spot from some PET/CT image and classified it to folder(have bright spot or no bright spot). How should I do?</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ol></div><div class="entry-pings"><h3>Trackbacks</h3><ol class="ping-list">		<li id="comment-409461" class="pingback even thread-even depth-1">
			<article id="div-comment-409461" class="comment-body">
				<footer class="comment-meta">
					<div class="comment-author vcard">
												<b class="fn"><a href="https://pyimagesearch.com/2016/10/31/detecting-multiple-bright-spots-in-an-image-with-python-and-opencv/" rel="external nofollow ugc" class="url">Detecting multiple bright spots in an image with Python and OpenCV - PyImageSearch</a></b> <span class="says">says:</span>					</div><!-- .comment-author -->

					<div class="comment-metadata">
						<a data-savepage-href="https://pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/#comment-409461" href="#comment-409461"><time datetime="2016-10-31T10:00:36-04:00">October 31, 2016 at 10:00 am</time></a>					</div><!-- .comment-metadata -->

									</footer><!-- .comment-meta -->

				<div class="comment-content">
					<p>[…] Today’s blog post is a followup to a tutorial I did a couple of years ago on finding the brightest spot in an image. […]</p>
				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		</li><!-- #comment-## -->
</ol></div><div class="comment-policy">  <h3 class="comment-policy__title">Comment section</h3>  <div class="comment-policy__content"><p>Hey, Adrian Rosebrock here, author and creator of PyImageSearch. While I love hearing from readers, a couple years ago I made the tough decision to no longer offer 1:1 help over blog post comments.</p>
<p>At the time I was receiving 200+ emails per day and another 100+ blog post comments. I simply did not have the time to moderate and respond to them all, and the sheer volume of requests was taking a toll on me.</p>
<p>Instead, my goal is to <em>do the most good</em> for the computer vision, deep learning, and OpenCV community at large by focusing my time on authoring high-quality blog posts, tutorials, and books/courses.</p>
<p><strong>If you need help learning computer vision and deep learning, <a href="https://pyimagesearch.com/books-and-courses/" target="_blank" rel="noopener">I suggest you refer to my full catalog of books and courses</a></strong> — they have helped tens of thousands of developers, students, and researchers <em>just like yourself</em> learn Computer Vision, Deep Learning, and OpenCV.</p>
<p><a href="https://pyimagesearch.com/books-and-courses/" target="_blank" rel="noopener">Click here to browse my full catalog.</a></p>
</div></div>
<div id="pyis-cta-modal-sticky-bottom-anchor"></div></main><aside class="sidebar sidebar-primary widget-area" role="complementary" aria-label="Primary Sidebar" id="genesis-sidebar-primary"><h2 class="genesis-sidebar-title screen-reader-text">Primary Sidebar</h2><section id="custom_html-11" class="widget_text widget widget_custom_html"><div class="widget_text widget-wrap"><div class="textwidget custom-html-widget"><div class="sidebar__block">
	<h4 class="sidebar__block-title"><a target="_blank" href="https://pyimagesearch.com/pyimagesearch-university/?utm_source=blogPost&utm_medium=sideBanner&utm_campaign=joinNow" rel="noopener">PyImageSearch University — NOW ENROLLING!</a></h4>	
	<a target="_blank" href="https://pyimagesearch.com/pyimagesearch-university/?utm_source=blogPost&utm_medium=sideBanner&utm_campaign=joinNow" rel="noopener"><img data-savepage-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/pyuni_full_access_plan_small.png?lossy=1&strip=1&webp=1" src="" alt="" class="wp-image-11909 lazyloaded" data-ll-status="loaded"><noscript><img src="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/pyuni_full_access_plan_small.png?lossy=1&strip=1&webp=1" alt="" class="wp-image-11909" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/pyuni_full_access_plan_small.png?size=126x95&lossy=1&strip=1&webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/pyuni_full_access_plan_small.png?lossy=1&strip=1&webp=1 200w" sizes="(max-width: 200px) 100vw, 200px"></noscript></a>	
	<div class="sidebar__block-content">
		<p style="font-size: 16px;"><strong>You can master Computer Vision, Deep Learning, and OpenCV</strong></p>
		<p style="font-size: 16px;">
			<strong>Course information:</strong><br>
			35+ total classes • 39h 44m video • Last updated: February 2022<br>
			<span style="color: #169FE6;">★★★★★</span><br>
			4.84 (128 Ratings) • 3,000+ Students Enrolled
		</p>
		<p style="text-align: left; font-size: 16px; line-height: 34px;">
			✓ <strong>35+ courses</strong> on essential computer vision, deep learning, and OpenCV topics<br>
			✓ 35+ Certificates of Completion<br>
			✓ <strong>39h 44m</strong> on-demand video<br>
			✓ <strong>Brand new courses released <em>every month</em></strong>, ensuring you can keep up with state-of-the-art techniques<br>
			✓ <strong>Pre-configured Jupyter Notebooks in Google Colab</strong><br>
			✓ Run all code examples in your web browser — works on Windows, macOS, and Linux (no dev environment configuration required!)<br>
			✓ Access to <strong>centralized code repos for <em>all</em> 500+ tutorials</strong> on PyImageSearch<br>
			✓ <strong> Easy one-click downloads</strong> for code, datasets, pre-trained models, etc.<br>
			✓ Access on mobile, laptop, desktop, etc.
		</p>
	</div>

	<a target="_blank" href="https://pyimagesearch.com/pyimagesearch-university/?utm_source=blogPost&utm_medium=sideBanner&utm_campaign=joinNow" class="button sidebar__block-button" rel="noopener">Join Now</a>
</div></div></div></section>
<section id="related-posts-by-taxonomy-2" class="widget related_posts_by_taxonomy"><div class="widget-wrap">
<h3 class="widgettitle widget-title">Picked For You</h3>
<div id="rpbt-related-gallery-1" class="gallery related-gallery related-galleryid-1136 gallery-columns-1 gallery-size-medium"><figure class="gallery-item" role="group" aria-label="OpenCV Contour Approximation">
			<div class="gallery-icon landscape">
				<a href="https://pyimagesearch.com/2021/10/06/opencv-contour-approximation/"><img width="300" height="169" data-savepage-currentsrc="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/10/opencv_contour_approximation_header.png?lossy=1&strip=1&webp=1" data-savepage-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/10/opencv_contour_approximation_header-300x169.png?size=300x300&lossy=1&strip=1&webp=1" src="" class="attachment-medium size-medium lazyloaded" alt="" aria-describedby="rpbt-related-gallery-1-18747" sizes="(max-width: 300px) 100vw, 300px" data-savepage-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/10/opencv_contour_approximation_header.png?size=126x71&lossy=1&strip=1&webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/10/opencv_contour_approximation_header-300x169.png?lossy=1&strip=1&webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/10/opencv_contour_approximation_header.png?lossy=1&strip=1&webp=1 500w" srcset="" data-ll-status="loaded"><noscript><img width="300" height="169" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/10/opencv_contour_approximation_header-300x169.png?lossy=1&strip=1&webp=1" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-18747" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/10/opencv_contour_approximation_header.png?size=126x71&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/10/opencv_contour_approximation_header-300x169.png?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/10/opencv_contour_approximation_header.png?lossy=1&amp;strip=1&amp;webp=1 500w" sizes="(max-width: 300px) 100vw, 300px" /></noscript></a>
			</div>
				<figcaption class="wp-caption-text gallery-caption" id="rpbt-related-gallery-1-18747">
				<a href="https://pyimagesearch.com/2021/10/06/opencv-contour-approximation/">OpenCV Contour Approximation</a>
				</figcaption></figure><figure class="gallery-item" role="group" aria-label="Image Gradients with OpenCV (Sobel and Scharr)">
			<div class="gallery-icon landscape">
				<a href="https://pyimagesearch.com/2021/05/12/image-gradients-with-opencv-sobel-and-scharr/"><img width="300" height="193" data-savepage-currentsrc="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_gradients_header.png?lossy=1&strip=1&webp=1" data-savepage-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_gradients_header-300x193.png?size=300x300&lossy=1&strip=1&webp=1" src="" class="attachment-medium size-medium lazyloaded" alt="" aria-describedby="rpbt-related-gallery-1-21730" sizes="(max-width: 300px) 100vw, 300px" data-savepage-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_gradients_header.png?size=126x81&lossy=1&strip=1&webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_gradients_header-300x193.png?lossy=1&strip=1&webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_gradients_header.png?lossy=1&strip=1&webp=1 700w" srcset="" data-ll-status="loaded"><noscript><img width="300" height="193" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_gradients_header-300x193.png?lossy=1&strip=1&webp=1" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-21730" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_gradients_header.png?size=126x81&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_gradients_header-300x193.png?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_gradients_header.png?lossy=1&amp;strip=1&amp;webp=1 700w" sizes="(max-width: 300px) 100vw, 300px" /></noscript></a>
			</div>
				<figcaption class="wp-caption-text gallery-caption" id="rpbt-related-gallery-1-21730">
				<a href="https://pyimagesearch.com/2021/05/12/image-gradients-with-opencv-sobel-and-scharr/">Image Gradients with OpenCV (Sobel and Scharr)</a>
				</figcaption></figure><figure class="gallery-item" role="group" aria-label="OpenCV Morphological Operations">
			<div class="gallery-icon landscape">
				<a href="https://pyimagesearch.com/2021/04/28/opencv-morphological-operations/"><img width="300" height="179" data-savepage-currentsrc="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_morphological_ops_header.png?lossy=1&strip=1&webp=1" data-savepage-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_morphological_ops_header-300x179.png?size=300x300&lossy=1&strip=1&webp=1" src="" class="attachment-medium size-medium lazyloaded" alt="" aria-describedby="rpbt-related-gallery-1-18751" sizes="(max-width: 300px) 100vw, 300px" data-savepage-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_morphological_ops_header.png?size=126x75&lossy=1&strip=1&webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_morphological_ops_header-300x179.png?lossy=1&strip=1&webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_morphological_ops_header.png?lossy=1&strip=1&webp=1 700w" srcset="" data-ll-status="loaded"><noscript><img width="300" height="179" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_morphological_ops_header-300x179.png?lossy=1&strip=1&webp=1" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-18751" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_morphological_ops_header.png?size=126x75&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_morphological_ops_header-300x179.png?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_morphological_ops_header.png?lossy=1&amp;strip=1&amp;webp=1 700w" sizes="(max-width: 300px) 100vw, 300px" /></noscript></a>
			</div>
				<figcaption class="wp-caption-text gallery-caption" id="rpbt-related-gallery-1-18751">
				<a href="https://pyimagesearch.com/2021/04/28/opencv-morphological-operations/">OpenCV Morphological Operations</a>
				</figcaption></figure><figure class="gallery-item" role="group" aria-label="OpenCV Smoothing and Blurring">
			<div class="gallery-icon landscape">
				<a href="https://pyimagesearch.com/2021/04/28/opencv-smoothing-and-blurring/"><img width="300" height="193" data-savepage-currentsrc="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_blurring_header.png?lossy=1&strip=1&webp=1" data-savepage-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_blurring_header-300x193.png?size=300x300&lossy=1&strip=1&webp=1" src="" class="attachment-medium size-medium lazyloaded" alt="" aria-describedby="rpbt-related-gallery-1-18753" sizes="(max-width: 300px) 100vw, 300px" data-savepage-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_blurring_header.png?size=126x81&lossy=1&strip=1&webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_blurring_header-300x193.png?lossy=1&strip=1&webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_blurring_header.png?lossy=1&strip=1&webp=1 700w" srcset="" data-ll-status="loaded"><noscript><img width="300" height="193" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_blurring_header-300x193.png?lossy=1&strip=1&webp=1" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-18753" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_blurring_header.png?size=126x81&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_blurring_header-300x193.png?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_blurring_header.png?lossy=1&amp;strip=1&amp;webp=1 700w" sizes="(max-width: 300px) 100vw, 300px" /></noscript></a>
			</div>
				<figcaption class="wp-caption-text gallery-caption" id="rpbt-related-gallery-1-18753">
				<a href="https://pyimagesearch.com/2021/04/28/opencv-smoothing-and-blurring/">OpenCV Smoothing and Blurring</a>
				</figcaption></figure><figure class="gallery-item" role="group" aria-label="OpenCV Thresholding ( cv2.threshold )">
			<div class="gallery-icon landscape">
				<a href="https://pyimagesearch.com/2021/04/28/opencv-thresholding-cv2-threshold/"><img width="300" height="193" data-savepage-currentsrc="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_thresholding_header.png?lossy=1&strip=1&webp=1" data-savepage-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_thresholding_header-300x193.png?size=300x300&lossy=1&strip=1&webp=1" src="" class="attachment-medium size-medium lazyloaded" alt="" aria-describedby="rpbt-related-gallery-1-18755" sizes="(max-width: 300px) 100vw, 300px" data-savepage-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_thresholding_header.png?size=126x81&lossy=1&strip=1&webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_thresholding_header-300x193.png?lossy=1&strip=1&webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_thresholding_header.png?lossy=1&strip=1&webp=1 700w" srcset="" data-ll-status="loaded"><noscript><img width="300" height="193" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_thresholding_header-300x193.png?lossy=1&strip=1&webp=1" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-18755" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_thresholding_header.png?size=126x81&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_thresholding_header-300x193.png?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/opencv_thresholding_header.png?lossy=1&amp;strip=1&amp;webp=1 700w" sizes="(max-width: 300px) 100vw, 300px" /></noscript></a>
			</div>
				<figcaption class="wp-caption-text gallery-caption" id="rpbt-related-gallery-1-18755">
				<a href="https://pyimagesearch.com/2021/04/28/opencv-thresholding-cv2-threshold/">OpenCV Thresholding ( cv2.threshold )</a>
				</figcaption></figure>
		</div>
</div></section></aside></div></div></div><div class="similar-articles"><div class="wrap"><h3>Similar articles</h3><div class="gpd-simple-card-group"><article class="post-summary"><a href="https://pyimagesearch.com/2014/11/24/detecting-barcodes-images-python-opencv/" class="post-summary--link"><header class="entry-header"><div class="entry-categories"><div class="entry-category">Image Processing</div><div class="entry-category">Tutorials</div></div><h2 class="entry-title">Detecting Barcodes in Images with Python and OpenCV</h2><div class="entry-date">November 24, 2014</div></header><p class="entry-content-link"><svg class="svg-icon long-arrow" width="14" height="14" aria-hidden="true" role="img" focusable="false" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.8125 0.1875C6.875 0.125 6.96875 0.09375 7.09375 0.09375C7.1875 0.09375 7.28125 0.125 7.34375 0.1875L13.875 6.75C13.9375 6.8125 14 6.90625 14 7C14 7.125 13.9375 7.1875 13.875 7.25L7.34375 13.8125C7.28125 13.875 7.1875 13.9062 7.09375 13.9062C6.96875 13.9062 6.875 13.875 6.8125 13.8125L6.1875 13.1875C6.125 13.125 6.09375 13.0625 6.09375 12.9375C6.09375 12.8438 6.125 12.75 6.1875 12.6562L11.0312 7.8125H0.375C0.25 7.8125 0.15625 7.78125 0.09375 7.71875C0.03125 7.65625 0 7.5625 0 7.4375V6.5625C0 6.46875 0.03125 6.375 0.09375 6.3125C0.15625 6.25 0.25 6.1875 0.375 6.1875H11.0312L6.1875 1.34375C6.125 1.28125 6.09375 1.1875 6.09375 1.0625C6.09375 0.96875 6.125 0.875 6.1875 0.8125L6.8125 0.1875Z" fill="#169FE6"></path></svg></p></a></article><article class="post-summary"><a href="https://pyimagesearch.com/2014/07/14/3-ways-compare-histograms-using-opencv-python/" class="post-summary--link"><header class="entry-header"><div class="entry-categories"><div class="entry-category">Image Descriptors</div><div class="entry-category">Image Search Engine Basics</div><div class="entry-category">Tutorials</div></div><h2 class="entry-title">How-To: 3 Ways to Compare Histograms using OpenCV and Python</h2><div class="entry-date">July 14, 2014</div></header><p class="entry-content-link"><svg class="svg-icon long-arrow" width="14" height="14" aria-hidden="true" role="img" focusable="false" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.8125 0.1875C6.875 0.125 6.96875 0.09375 7.09375 0.09375C7.1875 0.09375 7.28125 0.125 7.34375 0.1875L13.875 6.75C13.9375 6.8125 14 6.90625 14 7C14 7.125 13.9375 7.1875 13.875 7.25L7.34375 13.8125C7.28125 13.875 7.1875 13.9062 7.09375 13.9062C6.96875 13.9062 6.875 13.875 6.8125 13.8125L6.1875 13.1875C6.125 13.125 6.09375 13.0625 6.09375 12.9375C6.09375 12.8438 6.125 12.75 6.1875 12.6562L11.0312 7.8125H0.375C0.25 7.8125 0.15625 7.78125 0.09375 7.71875C0.03125 7.65625 0 7.5625 0 7.4375V6.5625C0 6.46875 0.03125 6.375 0.09375 6.3125C0.15625 6.25 0.25 6.1875 0.375 6.1875H11.0312L6.1875 1.34375C6.125 1.28125 6.09375 1.1875 6.09375 1.0625C6.09375 0.96875 6.125 0.875 6.1875 0.8125L6.8125 0.1875Z" fill="#169FE6"></path></svg></p></a></article><article class="post-summary"><a href="https://pyimagesearch.com/2021/09/06/whitelisting-and-blacklisting-characters-with-tesseract-and-python/" class="post-summary--link"><header class="entry-header"><div class="entry-categories"><div class="entry-category">Optical Character Recognition (OCR)</div><div class="entry-category">Tutorials</div></div><h2 class="entry-title">Whitelisting and Blacklisting Characters with Tesseract and Python</h2><div class="entry-date">September 6, 2021</div></header><p class="entry-content-link"><svg class="svg-icon long-arrow" width="14" height="14" aria-hidden="true" role="img" focusable="false" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.8125 0.1875C6.875 0.125 6.96875 0.09375 7.09375 0.09375C7.1875 0.09375 7.28125 0.125 7.34375 0.1875L13.875 6.75C13.9375 6.8125 14 6.90625 14 7C14 7.125 13.9375 7.1875 13.875 7.25L7.34375 13.8125C7.28125 13.875 7.1875 13.9062 7.09375 13.9062C6.96875 13.9062 6.875 13.875 6.8125 13.8125L6.1875 13.1875C6.125 13.125 6.09375 13.0625 6.09375 12.9375C6.09375 12.8438 6.125 12.75 6.1875 12.6562L11.0312 7.8125H0.375C0.25 7.8125 0.15625 7.78125 0.09375 7.71875C0.03125 7.65625 0 7.5625 0 7.4375V6.5625C0 6.46875 0.03125 6.375 0.09375 6.3125C0.15625 6.25 0.25 6.1875 0.375 6.1875H11.0312L6.1875 1.34375C6.125 1.28125 6.09375 1.1875 6.09375 1.0625C6.09375 0.96875 6.125 0.875 6.1875 0.8125L6.8125 0.1875Z" fill="#169FE6"></path></svg></p></a></article></div></div></div><div class="gpd-footer-cta"><div class="wrap"><div class="footer-cta-grid"><div class="footer-cta-image"><img width="932" height="833" data-savepage-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?lossy=1&strip=1&webp=1" src="" class="attachment-full size-full" alt="" data-savepage-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=126x113&lossy=1&strip=1&webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1-300x268.jpg?lossy=1&strip=1&webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=378x338&lossy=1&strip=1&webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=504x450&lossy=1&strip=1&webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=630x563&lossy=1&strip=1&webp=1 630w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1-768x686.jpg?lossy=1&strip=1&webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?lossy=1&strip=1&webp=1 932w" srcset="" sizes="(max-width: 932px) 100vw, 932px"></div><div class="footer-cta-title"><h3>You can learn Computer Vision, Deep Learning, and OpenCV.</h3></div><div class="footer-cta-content"><div class="footer-cta-content-desc"><p>Get your FREE 17 page Computer Vision, OpenCV, and Deep Learning Resource Guide PDF. Inside you’ll find our hand-picked tutorials, books, courses, and libraries to help you master CV and DL.</p>
</div><div class="footer-cta-content-action"><form class="footer-cta" action="https://www.getdrip.com/forms/657075648/submissions" method="post" target="_blank" data-drip-embedded-form="657075648">
	<input type="email" name="fields[email]" class="form-control" id="email" value="" placeholder="Your email address">
	<button type="submit" data-drip-attribute="sign-up-button">Download for free</button>
	<div style="display: none;" aria-hidden="true"><label for="website">Website</label><br><input type="text" id="website" name="website" tabindex="-1" autocomplete="false" value=""></div>
</form></div></div></div></div></div><div class="footer-widgets" id="genesis-footer-widgets"><h2 class="genesis-sidebar-title screen-reader-text">Footer</h2><div class="wrap"><div class="widget-area footer-widgets-1 footer-widget-area"><section id="custom_html-7" class="widget_text widget widget_custom_html"><div class="widget_text widget-wrap"><h3 class="widgettitle widget-title">Topics</h3>
<div class="textwidget custom-html-widget"><ul>
	<li><a href="https://pyimagesearch.com/category/deep-learning-2/">Deep Learning</a></li>
	<li><a href="https://pyimagesearch.com/category/dlib/">Dlib Library</a></li>
	<li><a href="https://pyimagesearch.com/category/embedded/">Embedded/IoT and Computer Vision</a></li>
	<li><a href="https://pyimagesearch.com/category/faces/">Face Applications</a></li>
	<li><a href="https://pyimagesearch.com/category/image-processing/">Image Processing</a></li>
	<li><a href="https://pyimagesearch.com/category/interviews/">Interviews</a></li>
	<li><a href="https://pyimagesearch.com/category/keras/">Keras</a></li>
</ul>
</div></div></section>
</div><div class="widget-area footer-widgets-2 footer-widget-area"><section id="custom_html-8" class="widget_text widget widget_custom_html"><div class="widget_text widget-wrap"><div class="textwidget custom-html-widget"><ul>
	<li><a href="https://pyimagesearch.com/category/machine-learning-2/">Machine Learning and Computer Vision</a></li>
	<li><a href="https://pyimagesearch.com/category/medical/">Medical Computer Vision</a></li>
	<li><a href="https://pyimagesearch.com/category/optical-character-recognition-ocr/">Optical Character Recognition (OCR)</a></li>
	<li><a href="https://pyimagesearch.com/category/object-detection/">Object Detection</a></li>
	<li><a href="https://pyimagesearch.com/category/object-tracking/">Object Tracking</a></li>
	<li><a href="https://pyimagesearch.com/category/opencv/">OpenCV Tutorials</a></li>
	<li><a href="https://pyimagesearch.com/category/raspberry-pi/">Raspberry Pi</a></li>
</ul></div></div></section>
</div><div class="widget-area footer-widgets-3 footer-widget-area"><section id="custom_html-9" class="widget_text widget widget_custom_html"><div class="widget_text widget-wrap"><h3 class="widgettitle widget-title">Books &amp; Courses</h3>
<div class="textwidget custom-html-widget"><ul>
<li><a href="https://pyimagesearch.com/pyimagesearch-university/">PyImageSearch University</a></li>
<li><a href="https://pyimagesearch.com/free-opencv-computer-vision-deep-learning-crash-course/">FREE CV, DL, and OpenCV Crash Course</a></li>
<li><a href="https://pyimagesearch.com/practical-python-opencv/">Practical Python and OpenCV</a></li>
<li><a href="https://pyimagesearch.com/deep-learning-computer-vision-python-book/">Deep Learning for Computer Vision with Python</a></li>
<li><a href="https://pyimagesearch.com/pyimagesearch-gurus/">PyImageSearch Gurus Course</a></li>
<li><a href="https://pyimagesearch.com/raspberry-pi-for-computer-vision/">Raspberry Pi for Computer Vision</a></li>
</ul></div></div></section>
</div><div class="widget-area footer-widgets-4 footer-widget-area"><section id="custom_html-10" class="widget_text widget widget_custom_html"><div class="widget_text widget-wrap"><h3 class="widgettitle widget-title">PyImageSearch</h3>
<div class="textwidget custom-html-widget"><ul>
		<li><a href="https://pyimagesearch.com/affiliates/">Affiliates</a></li>
	<li><a href="https://pyimagesearch.com/start-here/">Get Started</a></li>
	<li><a href="https://pyimagesearch.com/opencv-tutorials-resources-guides/">OpenCV Install Guides</a></li>
	<li><a href="https://pyimagesearch.com/about/">About</a></li>
	<li><a href="https://pyimagesearch.com/faqs/">FAQ</a></li>
	<li><a href="https://pyimagesearch.com/topics/">Blog</a></li>
	<li><a href="https://pyimagesearch.com/contact/">Contact</a></li>
	<li><a href="https://pyimagesearch.com/privacy-policy/">Privacy Policy</a></li>
</ul></div></div></section>
</div></div></div><footer class="site-footer"><div class="wrap"><div class="footer-logo"><p class="site-title"><a data-savepage-href="https://pyimagesearch.com" href="https://pyimagesearch.com/"></a></p></div><div class="footer-social"><a target="_blank" href="https://www.facebook.com/pyimagesearch"><svg class="svg-icon social-icon" width="18" height="18" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 264 512"><path d="M215.8 85H264V3.6C255.7 2.5 227.1 0 193.8 0 124.3 0 76.7 42.4 76.7 120.3V192H0v91h76.7v229h94V283h73.6l11.7-91h-85.3v-62.7c0-26.3 7.3-44.3 45.1-44.3z"></path></svg></a><a target="_blank" href="https://twitter.com/PyImageSearch"><svg class="svg-icon social-icon" width="18" height="18" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a target="_blank" href="http://www.linkedin.com/pub/adrian-rosebrock/2a/873/59b"><svg class="svg-icon social-icon" width="18" height="18" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a><a target="_blank" href="https://www.youtube.com/channel/UCoQK7OVcIVy-nV4m-SMCk_Q/videos"><svg class="svg-icon social-icon" width="18" height="18" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></div><div class="footer-info">© 2022 <a data-savepage-href="https://pyimagesearch.com" href="https://pyimagesearch.com/">PyImageSearch</a>. All Rights Reserved.</div></div></footer></div><!-- RightMessage WP -->


<div class="front-page-modal modal" id="pyis-cta-modal">

    <div class="modal-content">

        
<div class="optin-modal-content">

    <div style="text-align: center; font-size: 18px; padding-bottom: 20px;">
        <a target="_blank" href="https://pyimagesearch.mykajabi.com/login" style="font-weight: normal; color: #808080;">Already a member of PyImageSearch University? <strong>Click here to login.</strong></a>
    </div>

    <center>
        <img class="pyuni-logo" data-savepage-src="https://www.pyimagesearch.com/wp-content/uploads/2021/02/pyimagesearch_university_logo.png" src="" alt="PyImageSearch University Logo">
    </center>

    <div class="front-modal-top">
        <h3>Access the code to this tutorial and all other 500+ tutorials on PyImageSearch</h3>
    </div>

    <div class="front-modal-video first">
        <div class="front-modal-video-embed">
            <div class="wistia_responsive_padding" style="padding:56.25% 0 0 0;position:relative;"><div class="wistia_responsive_wrapper" style="height:100%;left:0;position:absolute;top:0;width:100%;"><div class="wistia_embed wistia_async_8ggk996ods videoFoam=true wistia_embed_initialized" style="height:100%;position:relative;width:100%" id="wistia-8ggk996ods-1"><div class="wistia_swatch" style="height: 100%; left: 0px; opacity: 1; overflow: hidden; position: absolute; top: 0px; transition: opacity 200ms ease 0s; width: 100%;"><img data-savepage-src="https://fast.wistia.com/embed/medias/8ggk996ods/swatch" src="" style="filter:blur(5px);height:100%;object-fit:contain;width:100%;" alt="" aria-hidden="true" onload="this.parentNode.style.opacity=1;"></div><div id="wistia_chrome_61" class="w-chrome" tabindex="-1" style="display: inline-block; height: 100%; line-height: normal; margin: 0px; padding: 0px; position: relative; vertical-align: top; width: 100%; zoom: 1; outline: none; overflow: hidden; box-sizing: content-box;"><div id="wistia_grid_110_wrapper" style="display: block;"><div id="wistia_grid_110_above"></div><div id="wistia_grid_110_main"><div id="wistia_grid_110_behind"></div><div id="wistia_grid_110_center"><div class="w-video-wrapper w-css-reset" style="clip: rect(0px, 0px, 0px, 0px); height: 100%; position: absolute; top: 0px; width: 100%; opacity: 1; background-color: rgb(0, 0, 0);"></div><div class="w-ui-container" style="height: 100%; left: 0px; position: absolute; top: 0px; width: 100%; opacity: 1;"></div></div><div id="wistia_grid_110_front"></div><div id="wistia_grid_110_top_inside"><div id="wistia_grid_110_top"></div></div><div id="wistia_grid_110_bottom_inside"><div id="wistia_grid_110_bottom"></div></div><div id="wistia_grid_110_left_inside"><div id="wistia_grid_110_left"></div></div><div id="wistia_grid_110_right_inside"><div id="wistia_grid_110_right"></div></div></div><div id="wistia_grid_110_below"></div><style id="wistia_111_style" type="text/css" class="wistia_injected_style">#wistia_grid_110_wrapper{-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box;font-family:Arial,sans-serif;font-size:14px;height:100%;position:relative;text-align:left;width:100%;}
#wistia_grid_110_wrapper *{-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box;}
#wistia_grid_110_above{position:relative;}
#wistia_grid_110_main{display:block;height:100%;position:relative;}
#wistia_grid_110_behind{height:100%;left:0;position:absolute;top:0;width:100%;}
#wistia_grid_110_center{height:100%;overflow:hidden;position:relative;width:100%;}
#wistia_grid_110_front{display:none;height:100%;left:0;position:absolute;top:0;width:100%;}
#wistia_grid_110_top_inside{position:absolute;left:0;top:0;width:100%;}
#wistia_grid_110_top{width:100%;position:absolute;bottom:0;left:0;}
#wistia_grid_110_bottom_inside{position:absolute;left:0;bottom:0;width:100%;}
#wistia_grid_110_bottom{width:100%;position:absolute;top:0;left:0;}
#wistia_grid_110_left_inside{height:100%;position:absolute;left:0;top:0;}
#wistia_grid_110_left{height:100%;position:absolute;right:0;top:0;}
#wistia_grid_110_right_inside{height:100%;right:0;position:absolute;top:0;}
#wistia_grid_110_right{height:100%;left:0;position:absolute;top:0;}
#wistia_grid_110_below{position:relative;}</style></div></div></div></div></div>
        </div>
        <div class="front-modal-action" style="margin-top: 20px;">
            <p><strong>Enter your email address below to learn more about PyImageSearch University</strong> (including how you can download the source code to this post):</p>
            <form class="footer-cta" action="https://www.getdrip.com/forms/857913265/submissions" method="post" target="_blank" data-drip-embedded-form="857913265" id="drip-ef-857913265">
                <input type="email" name="fields[email]" class="form-control" id="email" value="" placeholder="Your email address">
                <input id="code_submit_post_title" type="hidden" name="fields[code_submit_post_title]" value="">
                <button type="submit" data-drip-attribute="sign-up-button">Learn More</button>
                <div style="display: none;" aria-hidden="true"><label for="website">Website</label><br><input type="text" id="website" name="website" tabindex="-1" autocomplete="false" value=""></div>
            </form>
        </div>
    </div>

    <div class="front-modal-top">
        <h3>What's included in PyImageSearch University?</h3>
    </div>

    <div class="front-modal-video">
        <div class="front-modal-video-desc">
            <ul class="is-style-list-checks">
                <li><strong>Easy access to the code, datasets, and pre-trained models</strong> for all 500+ tutorials on the PyImageSearch blog</li>
                <li><strong>High-quality, well documented source code</strong> with line-by-line explanations (ensuring you know exactly what the code is doing)</li>
                <li><strong>Jupyter Notebooks</strong> that are pre-configured to run in <strong>Google Colab</strong> with a <em>single click</em></li>
                <li><strong>Run all code examples in your web browser</strong> — no dev environment configuration required!</li>
            </ul>
        </div>
        <div class="front-modal-video-desc">
            <ul class="is-style-list-checks">
                <li><strong>Support for all major operating systems</strong> (Windows, macOS, Linux, and Raspbian)</li>
                <li><strong>Full access to PyImageSearch University courses</strong></li>
                <li><strong>Detailed video tutorials</strong> for every lesson</li>
                <li><strong>Certificates of Completion</strong> for all courses</li>
                <li><strong>New courses added <em>every month!</em></strong> — stay on top of state-of-the-art trends in computer vision and deep learning</li>
            </ul>
        </div>
    </div>

    <div class="front-modal-testimonial">
        <blockquote><p>PyImageSearch University is really the best Computer Visions "Masters" Degree that I wish I had when starting out. <strong>Being able to access all of Adrian's tutorials in a single indexed page and being able to start playing around with the code without going through the nightmare of setting up everything is just amazing.</strong> 10/10 would recommend.</p><cite><span class="quote-name">Sanyam Bhutani</span><span class="cite-title">Machine Learning Engineer and 2x Kaggle Master</span></cite></blockquote>
    </div>

</div>
    </div>

    <a href="#close-modal" rel="modal:close" target="_self" class="close-modal">
        Close    </a>

</div><!-- Drip -->


<!-- facebook -->

<noscript><img height="1" width="1" style="display:none"
  src="https://www.facebook.com/tr?id=1465896023527386&ev=PageView&noscript=1"
/></noscript>

<!-- Global site tag (gtag.js) - Google Analytics -->



<!-- Start VWO Async SmartCode -->

<!-- End VWO Async SmartCode --><!-- This site is converting visitors into subscribers and customers with OptinMonster - https://optinmonster.com :: Campaign Title: PyUni Discount Wheel --><!-- / OptinMonster --><!-- This site is converting visitors into subscribers and customers with OptinMonster - https://optinmonster.com :: Campaign Title: Discount Wheel --><!-- / OptinMonster --><!-- This site is converting visitors into subscribers and customers with OptinMonster - https://optinmonster.com :: Campaign Title: PyImageConf Early Bird Inline --><div id="om-ecjnldox9dphdwckleif-holder"></div><!-- / OptinMonster --><!-- This site is converting visitors into subscribers and customers with OptinMonster - https://optinmonster.com :: Campaign Title: CS: Template --><!-- / OptinMonster --><!-- This site is converting visitors into subscribers and customers with OptinMonster - https://optinmonster.com :: Campaign Title: CVDL Resource Guide --><!-- / OptinMonster -->		
		












<script type="text/javascript" id="rocket-browser-checker-js-after"></script>
<script type="text/javascript" id="rocket-preload-links-js-extra"></script>
<script type="text/javascript" id="rocket-preload-links-js-after"></script>














		<script type="text/javascript"></script>
				<script type="text/javascript"></script>
		<script></script><script></script><noscript><link data-avlabs-exclude-css="1"  rel="stylesheet" href="https://pyimagesearch.com/wp-content/cache/min/1/803b014a2437c8bfad3d0b2990a1b1fe.css" media="all" data-minify="1" /></noscript><script></script><script></script><script></script><script></script>

<!-- This website is like a Rocket, isn't it? Performance optimized by WP Rocket. Learn more: https://wp-rocket.me - Debug: cached@1646912884 --><style id="wistia_22_style" type="text/css" class="wistia_injected_style">
@font-face {
font-family: 'WistiaPlayerInterNumbersSemiBold';
font-feature-settings: 'tnum' 1;
src: url(data:application/x-font-woff;charset=utf-8;base64,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);
}
</style><div><div class="grecaptcha-badge" data-style="bottomright" style="width: 256px; height: 60px; position: fixed; visibility: hidden; display: block; transition: right 0.3s ease 0s; bottom: 14px; right: -186px; box-shadow: gray 0px 0px 5px; border-radius: 2px; overflow: hidden;"><div class="grecaptcha-logo"><iframe srcdoc="<!DOCTYPE html><html dir=&quot;ltr&quot; lang=&quot;en&quot;><head><base href=&quot;https://www.google.com/recaptcha/api2/anchor?ar=2&amp;k=6LcSHsQUAAAAAIzvikURE5e1jZ-YAGgyhpZnfS6o&amp;co=aHR0cHM6Ly9weWltYWdlc2VhcmNoLmNvbTo0NDM.&amp;hl=en&amp;v=85AXn53af-oJBEtL2o2WpAjZ&amp;size=invisible&amp;cb=txxekicx383i&quot;><meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;>
<meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;>
<title>reCAPTCHA</title>
<style type=&quot;text/css&quot;>
/* cyrillic-ext */
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 400;
  src: /*savepage-url=//fonts.gstatic.com/s/roboto/v18/KFOmCnqEu92Fr1Mu72xKKTU1Kvnz.woff2*/ url() format('woff2');
  unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
}
/* cyrillic */
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 400;
  src: /*savepage-url=//fonts.gstatic.com/s/roboto/v18/KFOmCnqEu92Fr1Mu5mxKKTU1Kvnz.woff2*/ url() format('woff2');
  unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
}
/* greek-ext */
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 400;
  src: /*savepage-url=//fonts.gstatic.com/s/roboto/v18/KFOmCnqEu92Fr1Mu7mxKKTU1Kvnz.woff2*/ url() format('woff2');
  unicode-range: U+1F00-1FFF;
}
/* greek */
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 400;
  src: /*savepage-url=//fonts.gstatic.com/s/roboto/v18/KFOmCnqEu92Fr1Mu4WxKKTU1Kvnz.woff2*/ url() format('woff2');
  unicode-range: U+0370-03FF;
}
/* vietnamese */
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 400;
  src: /*savepage-url=//fonts.gstatic.com/s/roboto/v18/KFOmCnqEu92Fr1Mu7WxKKTU1Kvnz.woff2*/ url() format('woff2');
  unicode-range: U+0102-0103, U+0110-0111, U+0128-0129, U+0168-0169, U+01A0-01A1, U+01AF-01B0, U+1EA0-1EF9, U+20AB;
}
/* latin-ext */
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 400;
  src: /*savepage-url=//fonts.gstatic.com/s/roboto/v18/KFOmCnqEu92Fr1Mu7GxKKTU1Kvnz.woff2*/ url() format('woff2');
  unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}
/* latin */
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 400;
  src: /*savepage-url=//fonts.gstatic.com/s/roboto/v18/KFOmCnqEu92Fr1Mu4mxKKTU1Kg.woff2*/ url() format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
/* cyrillic-ext */
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 500;
  src: /*savepage-url=//fonts.gstatic.com/s/roboto/v18/KFOlCnqEu92Fr1MmEU9fCRc4AMP6lbBP.woff2*/ url() format('woff2');
  unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
}
/* cyrillic */
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 500;
  src: /*savepage-url=//fonts.gstatic.com/s/roboto/v18/KFOlCnqEu92Fr1MmEU9fABc4AMP6lbBP.woff2*/ url() format('woff2');
  unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
}
/* greek-ext */
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 500;
  src: /*savepage-url=//fonts.gstatic.com/s/roboto/v18/KFOlCnqEu92Fr1MmEU9fCBc4AMP6lbBP.woff2*/ url() format('woff2');
  unicode-range: U+1F00-1FFF;
}
/* greek */
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 500;
  src: /*savepage-url=//fonts.gstatic.com/s/roboto/v18/KFOlCnqEu92Fr1MmEU9fBxc4AMP6lbBP.woff2*/ url() format('woff2');
  unicode-range: U+0370-03FF;
}
/* vietnamese */
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 500;
  src: /*savepage-url=//fonts.gstatic.com/s/roboto/v18/KFOlCnqEu92Fr1MmEU9fCxc4AMP6lbBP.woff2*/ url() format('woff2');
  unicode-range: U+0102-0103, U+0110-0111, U+0128-0129, U+0168-0169, U+01A0-01A1, U+01AF-01B0, U+1EA0-1EF9, U+20AB;
}
/* latin-ext */
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 500;
  src: /*savepage-url=//fonts.gstatic.com/s/roboto/v18/KFOlCnqEu92Fr1MmEU9fChc4AMP6lbBP.woff2*/ url() format('woff2');
  unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}
/* latin */
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 500;
  src: /*savepage-url=//fonts.gstatic.com/s/roboto/v18/KFOlCnqEu92Fr1MmEU9fBBc4AMP6lQ.woff2*/ url() format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
/* cyrillic-ext */
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 900;
  src: /*savepage-url=//fonts.gstatic.com/s/roboto/v18/KFOlCnqEu92Fr1MmYUtfCRc4AMP6lbBP.woff2*/ url() format('woff2');
  unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
}
/* cyrillic */
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 900;
  src: /*savepage-url=//fonts.gstatic.com/s/roboto/v18/KFOlCnqEu92Fr1MmYUtfABc4AMP6lbBP.woff2*/ url() format('woff2');
  unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
}
/* greek-ext */
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 900;
  src: /*savepage-url=//fonts.gstatic.com/s/roboto/v18/KFOlCnqEu92Fr1MmYUtfCBc4AMP6lbBP.woff2*/ url() format('woff2');
  unicode-range: U+1F00-1FFF;
}
/* greek */
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 900;
  src: /*savepage-url=//fonts.gstatic.com/s/roboto/v18/KFOlCnqEu92Fr1MmYUtfBxc4AMP6lbBP.woff2*/ url() format('woff2');
  unicode-range: U+0370-03FF;
}
/* vietnamese */
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 900;
  src: /*savepage-url=//fonts.gstatic.com/s/roboto/v18/KFOlCnqEu92Fr1MmYUtfCxc4AMP6lbBP.woff2*/ url() format('woff2');
  unicode-range: U+0102-0103, U+0110-0111, U+0128-0129, U+0168-0169, U+01A0-01A1, U+01AF-01B0, U+1EA0-1EF9, U+20AB;
}
/* latin-ext */
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 900;
  src: /*savepage-url=//fonts.gstatic.com/s/roboto/v18/KFOlCnqEu92Fr1MmYUtfChc4AMP6lbBP.woff2*/ url() format('woff2');
  unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}
/* latin */
@font-face {
  font-family: 'Roboto';
  font-style: normal;
  font-weight: 900;
  src: /*savepage-url=//fonts.gstatic.com/s/roboto/v18/KFOlCnqEu92Fr1MmYUtfBBc4AMP6lQ.woff2*/ url() format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}

</style>
<link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://www.gstatic.com/recaptcha/releases/85AXn53af-oJBEtL2o2WpAjZ/styles__ltr.css&quot;>
<script nonce=&quot;&quot; type=&quot;text/javascript&quot;></script>
<script type=&quot;text/javascript&quot; data-savepage-src=&quot;https://www.gstatic.com/recaptcha/releases/85AXn53af-oJBEtL2o2WpAjZ/recaptcha__en.js&quot; nonce=&quot;&quot;></script>
<style id=&quot;savepage-cssvariables&quot;>
  :root {
  }
</style>
              </head>
<body><div id=&quot;rc-anchor-alert&quot; class=&quot;rc-anchor-alert&quot;></div>
<input type=&quot;hidden&quot; id=&quot;recaptcha-token&quot; value=&quot;03AGdBq251BZwyaQ9Vfi_rQAoW5lNYkS9xRw5vyQsnySyWWex9e51KN-2GUXe0HaJ9K130e4csL9L3LiwojbjrlIZ-Q-0EA6R4oNzQu7cJGZNH4yVVRw-TBWmP03B3Lr2zojzjudfwl_mQN2_Z7pCixDgyaghLwWnFXXrSsaQACy9O0HgonL5i4oe4Y5LOGTyNnsrSJyFbdLb53QTHey2g9dQY1O_-S7wwt0igtH8sjjWCt-n92v_HP9EkQPDJpfAiIMjs9c7SrPsGeac6Q2513TEjXNnX11d6M5ScgNkryOlzphBf3zEWroLpkmWuy_0eg5SrtsYzh_mtw2COCOGsJDdMU-H2IEYtaT8YAC9YogsWgo-BSktINoqEuDF3ZGqCKIkps4vnO6HMFp3Y1mGqZW8JBabEnUyo_kZF5VdsRjoZ0SAtf5QJ-9ehhBKouwfBQxo2umDu8Br_SISM9cOvioq8XLgZ5IIR9zjt20y0femyHO2qQbLVdKaNzFqW3_MNipqOoXU5gKQB9E-g9V_05T1h5GlnzKeo5wyosqepuhe9k15k0Pf-9Q35Z1VrzjfJufa_7bc0K4uezJmqJumQvxnxofg4ax68JChF2sl-Dvv0S3lDbPOsrQnxZE_02gUshyPKtyxdbQjZEUmVdw4MVKMxkgWq-RekVN3W8UmHPv4CgSTlFHJUxt6Oy4a0MScf2Qu2JJcfFsOmfQ6jLZHoylKr_BVIBGWtRIgJUj8PSvGyDfSWR89crrIDAor157rMlMvnpuR0aWqhH_gnco0FdgeZmq43lbaP_urlF1-c50ktFV-gjCIrITDAf_ECvPBLneAjEsq0toa1QuD3MRd8K0CFgAMuyqgKRd1KIKqosRpEl_XPID2syWSFwWgKQ_YkqBQ2_DaFe7qqMjQbcNY9uhXtfMV-tHpr4Io0immLp8b_TK6lcZ4RX6kGbvBzVnwwfNuPhhAvTMGwirpxskhhuWEBH-MPBZhab0YQPAUzlgoQGiPPHxZFAFLw3V0KAWJVfVZE4IS_REo1D11Uaox8SWOoqUsL2f863Y-CJRZ0KIfXFeY5lr_CHd4VDTKVJPuE0Gq75HfT9PeUJSVc-lgSf6rQ6PYXsEPigIld4JDBxojTyJTMytxk2DTptUBq-g0Cx9nYlCdBarSn4JkeCmqWSUFbOmDH3Q5E2w&quot;>
<script type=&quot;text/javascript&quot; nonce=&quot;&quot;></script><div class=&quot;rc-anchor rc-anchor-invisible rc-anchor-light  rc-anchor-invisible-hover&quot;><div id=&quot;recaptcha-accessible-status&quot; class=&quot;rc-anchor-aria-status&quot; aria-hidden=&quot;true&quot;>Recaptcha requires verification. </div><div class=&quot;rc-anchor-error-msg-container&quot; style=&quot;display:none&quot;><span class=&quot;rc-anchor-error-msg&quot; aria-hidden=&quot;true&quot;></span></div><div class=&quot;rc-anchor-normal-footer&quot;><div class=&quot;rc-anchor-logo-large&quot; role=&quot;presentation&quot;><div class=&quot;rc-anchor-logo-img rc-anchor-logo-img-large&quot;></div></div><div class=&quot;rc-anchor-pt&quot;><a href=&quot;https://www.google.com/intl/en/policies/privacy/&quot; target=&quot;_blank&quot;>Privacy</a><span aria-hidden=&quot;true&quot; role=&quot;presentation&quot;> - </span><a href=&quot;https://www.google.com/intl/en/policies/terms/&quot; target=&quot;_blank&quot;>Terms</a></div></div><div class=&quot;rc-anchor-invisible-text&quot;><span>protected by <strong>reCAPTCHA</strong></span><div class=&quot;rc-anchor-pt&quot;><a href=&quot;https://www.google.com/intl/en/policies/privacy/&quot; target=&quot;_blank&quot; style=&quot;&quot;>Privacy</a><span aria-hidden=&quot;true&quot; role=&quot;presentation&quot;> - </span><a href=&quot;https://www.google.com/intl/en/policies/terms/&quot; target=&quot;_blank&quot; style=&quot;&quot;>Terms</a></div></div></div><iframe data-savepage-key=&quot;0-0-0&quot; style=&quot;display: none;&quot;></iframe></body></html>" data-savepage-crossorigin="" title="reCAPTCHA" data-savepage-src="https://www.google.com/recaptcha/api2/anchor?ar=2&k=6LcSHsQUAAAAAIzvikURE5e1jZ-YAGgyhpZnfS6o&co=aHR0cHM6Ly9weWltYWdlc2VhcmNoLmNvbTo0NDM.&hl=en&v=85AXn53af-oJBEtL2o2WpAjZ&size=invisible&cb=txxekicx383i" src="" width="256" height="60" role="presentation" name="a-o0mmsa3xke54" frameborder="0" scrolling="no" data-savepage-sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-top-navigation allow-modals allow-popups-to-escape-sandbox" sandbox="" data-savepage-key="0-0"></iframe></div><div class="grecaptcha-error"></div><textarea id="g-recaptcha-response-100000" name="g-recaptcha-response" class="g-recaptcha-response" style="width: 250px; height: 40px; border: 1px solid rgb(193, 193, 193); margin: 10px 25px; padding: 0px; resize: none; display: none;"></textarea></div><iframe srcdoc="<html><head>
<style id=&quot;savepage-cssvariables&quot;>
  :root {
  }
</style>
          </head><body></body></html>" data-savepage-sameorigin="" data-savepage-key="0-1" style="display: none;"></iframe></div></body></html>